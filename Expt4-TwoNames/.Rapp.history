lines(1:20,table(perm$Marginal))
plot(1:20,table(perm$Marginal))
?plot
plot(1:20,table(perm$Marginal), type = "n")
plot(1:20,table(perm$Marginal))
plot(table(perm$Marginal), type = "n")
a = data.frame(c("a","b","c"),2,2)
a
a = data.frame(rep(c("a","b","c",2),2,3)
a
a = data.frame(rep(c("a","b","c",2),2,3))
a
a = matrix(rep(c("a","b","c",2),2,3))
a
?matrix
a = matrix(rep(c("a","b","c"),2),2,3)
a
a = matrix(rep(c("a","b","c"),2),3,2)
a
a = matrix(rep(c("a","b","c","a","b"),2),5,2)
a
a[a[1,] == a,]
a[a[1,] == a]
a[,a[1,] == a]
a[,a[,1] == a]
a[a[,1] == a,]
a[,1] == a
?Data.frame
?data.frame
a = data.frame(a)
a
a[a$X1 == "a",]
a[a$X1 == "a",1]
a[a$X1 == "b",1]
a = data.frame(rep(c("a","b","c","a","b"),2),5,2)
a
a = data.frame(matrix(rep(c("a","b","c","a","b"),2),5,2))
a
a$Test = 0
a[a$X1 == "b",1]
a
a[a$X1 == "b",]
a[a$X1 == "b",1]
a[a$X1 == "b",1]$Test
a[a$X1 == "b",][1,]
print(a)
a[a$X1 == "b",][1,]$Test
a[a$X1 == "b",][1,]$Test <- a[a$X1 == "b",][1,]$X2
a
a[a$X1 == "b",][1,]$Test <- as.character(a[a$X1 == "b",][1,]$X2)
a
library(pwer)
library(pwr)
pwr.t.test(d = 0.3, sig.level = 0.01, power = 0.8)
pwr.t.test(d = 0.3, sig.level = 0.05, power = 0.8)
pwr.t.test(d = 0.5, sig.level = 0.05, power = 0.8)
5.357543e+300
2^999
a = data.frame(c(a,b,a,a))
a = data.frame(c(1,2,1,1))
a
a = data.frame(d1 = c(1,2,1),d2 = c(2,1,1),d3 = c(1,1,1))
a
which(a==2)
a[which(a==2)]
a[which(a==2),]
which(a==2, arr.ind = T)
a[which(a==2, arr.ind = T),]
a[arrayInd(a==2),]
a[arrayInd(a==2)]
arrayInd(a==2)
arrayInd(a,2)
which(a==2, arr.ind = T)
which(a>2, arr.ind = T)
which(a12, arr.ind = T)
which(a>1, arr.ind = T)
which(a>1, arr.ind = T) -> k
a[k]
a[!k]
Data Analysis Scripts for analysis of population alone#
			calculate.statistics.within = function(data_file,StartTime,EndTime,StepSize){#
			#Load the relevant libraries#
			#Load the relevant libraries#
			require("lme4") #
			require(multicore)#
			require(doMC)#
			require(foreach)#
			require(plyr)#
			#Start the multicore machine!#
#
			#Split the data frame into a list for each timepoint#
			a = split(data_file[data_file$Time >= StartTime & data_file$Time <= EndTime,],data_file[data_file$Time >= StartTime & data_file$Time <= EndTime,]$Time)#
			#Parallel application of lmer and coefficient extraction, outputs another list as above#
			mclapply(a,function(x) coef(summary(lmer(Score~Cond*Strength + (1+Cond*Strength|Subj) , data = x)))[2:4,1:3]) -> a.co#
			# Evaluate the list to see whether t value meets a threshold (hard coded)#
			lapply(a.co,function(x) data.frame(x,pv = ifelse(abs(x[,3]) > 1.6,0.04,0.06), co = rownames(x))) -> k#
			# plyr that list into a dataframe#
			k.df = ldply(k)#
			k.df$.id = as.numeric(k.df$.id)#
			colnames(k.df) <- c("Time", "Estimate","SE", "Stat", "pval","Coef")#
			k.df$Coef = ordered(k.df$Coef,levels = c("CondU","Strengthweak","CondU:Strengthweak"))#
			#Split that dataframe into a list based on the regression coefficients#
			stats.sample = split(k.df,k.df$Coef)#
			return(stats.sample)#
#
			}#
# Function to shuffle condition labels assuming that we hold groups of trials constant. i.e., does the same as shuffling averaged data.#
			# Function to shuffle the condition label then compute the same stats as above#
			# This does the resampling on your data.#
			resample.within = function(data_file,StartTime,EndTime,StepSize){#
#
				summaryBy(Trial~Subj+Trial+Cond+Strength, data = data_file ) -> Trials#
				shuf.fnc <- function(x){#
				NewCond <- x$Cond[sample.int(length(x$Cond))]#
				NewStrength <- x$Strength[sample.int(length(x$Strength))]#
				return(data.frame(x,NewCond,NewStrength))#
					}#
				Trials = ddply(Trials, .(Subj), shuf.fnc)#
				for (i in unique(data_file$Subj)){#
					data_file_S = data_file[data_file$Subj == i,]#
                                        data_file_S.prac = data_file_S#
					for (j in unique(data_file_S.prac$Trial)){#
                                           data_file_S[ data_file_S.prac$Trial == j,]$Cond =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewCond),length(data_file_S[ data_file_S.prac$Trial == j,]$Cond))#
                                          data_file_S[ data_file_S.prac$Trial == j,]$Strength =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewStrength),length(data_file_S[ data_file_S.prac$Trial == j,]$Strength))#
                                        }#
					data_file[data_file$Subj == i,] = data_file_S#
                                      }#
				data_file$Cond = as.factor(data_file$Cond)#
				data_file$Strength = as.factor(data_file$Strength)#
				contrasts(data_file$Cond)[1] <- -1#
				contrasts(data_file$Cond)[2] <- 1#
				contrasts(data_file$Strength)[2] <- 1#
				contrasts(data_file$Strength)[1] <- -1#
			#	print(data_file[data_file$Subj == i,]$Pop[1:30])#
                        #       print(data_file[data_file$Subj == i,]$Trial[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Cond[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Strength[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Score[seq(300,1000, by = 25)])#
				stats.resample = calculate.statistics.within(data_file,StartTime,EndTime,StepSize)#
				return(stats.resample)#
				}#
			StartTime = 0#
			EndTime = 1500#
			StepSize = 100#
			# Get the relevant stats for your data file.#
			registerDoMC();#
			stats.sample = calculate.statistics.within(ET,StartTime,EndTime,StepSize)#
			sample.cluster1 = find.clusters(stats.sample[[1]]$pval,stats.sample[[1]]$Stat,stats.sample[[1]]$Time,cluster.size = 1)#
			sample.cluster2 = find.clusters(stats.sample[[2]]$pval,stats.sample[[2]]$Stat,stats.sample[[2]]$Time,cluster.size = 1)#
			sample.cluster3 = find.clusters(stats.sample[[3]]$pval,stats.sample[[3]]$Stat,stats.sample[[3]]$Time,cluster.size = 1)#
			#do the resampling#
			Resamples_N = 2500 # Number of samples (it will take 5-10 minutes to do 1000, so set this to 10 your first time to make sure the script works)#
			resample1.large.cluster = rep(NA,Resamples_N) #Preallocate your resample datafile #
			resample2.large.cluster = rep(NA,Resamples_N) #Preallocate your resample datafile #
			resample3.large.cluster = rep(NA,Resamples_N) #Preallocate your resample datafile #
			for (i in 1:Resamples_N){#
				print(i)#
			stats.resample = resample.within(ET,StartTime,EndTime,StepSize)#
			recluster1 = find.clusters(stats.resample[[1]]$pval,stats.resample[[1]]$Stat,stats.resample[[1]]$Time,cluster.size = 1)#
			recluster2 = find.clusters(stats.resample[[2]]$pval,stats.resample[[2]]$Stat,stats.resample[[2]]$Time,cluster.size = 1)#
			recluster3 = find.clusters(stats.resample[[3]]$pval,stats.resample[[3]]$Stat,stats.resample[[3]]$Time,cluster.size = 1)#
			resample1.max = ifelse(is.numeric(recluster1$cluster.stat),max(recluster1$cluster.stat),0)#
			resample2.max = ifelse(is.numeric(recluster2$cluster.stat),max(recluster2$cluster.stat),0)#
			resample3.max = ifelse(is.numeric(recluster3$cluster.stat),max(recluster3$cluster.stat),0)#
#
			 #Find the largest cluster (this is what you will be comparing against - is your cluster > 95% of largest clusters)#
			print(resample1.max)#
			print(resample3.max)#
			resample1.large.cluster[i] = ifelse(resample1.max>0,resample1.max,0)#
			resample2.large.cluster[i] = ifelse(resample2.max>0,resample2.max,0)#
			resample3.large.cluster[i] = ifelse(resample3.max>0,resample3.max,0)#
			}#
#
			sample.cluster1 = pval(sample.cluster1,resample1.large.cluster)#
			sample.cluster2 = pval(sample.cluster2,resample2.large.cluster)#
			sample.cluster3 = pval(sample.cluster3,resample3.large.cluster)#
			Within.Resamples = list(resample1.large.cluster,resample2.large.cluster,resample3.large.cluster, paste(Resamples_N, "Samples on date ", date()))#
			Within.Clusters = list(sample.cluster1,sample.cluster2,sample.cluster3)#
			save(Within.Clusters,within.Resamples,file =paste("WithinStats",substr(date(),5,7),substr(date(),22,23),".RDATA", sep = ""))
library(doBy)
Data Analysis Scripts for analysis of population alone#
			calculate.statistics.within = function(data_file,StartTime,EndTime,StepSize){#
			#Load the relevant libraries#
			#Load the relevant libraries#
			require("lme4") #
			require(multicore)#
			require(doMC)#
			require(foreach)#
			require(plyr)#
			#Start the multicore machine!#
#
			#Split the data frame into a list for each timepoint#
			a = split(data_file[data_file$Time >= StartTime & data_file$Time <= EndTime,],data_file[data_file$Time >= StartTime & data_file$Time <= EndTime,]$Time)#
			#Parallel application of lmer and coefficient extraction, outputs another list as above#
			mclapply(a,function(x) coef(summary(lmer(Score~Cond*Strength + (1+Cond*Strength|Subj) , data = x)))[2:4,1:3]) -> a.co#
			# Evaluate the list to see whether t value meets a threshold (hard coded)#
			lapply(a.co,function(x) data.frame(x,pv = ifelse(abs(x[,3]) > 1.6,0.04,0.06), co = rownames(x))) -> k#
			# plyr that list into a dataframe#
			k.df = ldply(k)#
			k.df$.id = as.numeric(k.df$.id)#
			colnames(k.df) <- c("Time", "Estimate","SE", "Stat", "pval","Coef")#
			k.df$Coef = ordered(k.df$Coef,levels = c("CondU","Strengthweak","CondU:Strengthweak"))#
			#Split that dataframe into a list based on the regression coefficients#
			stats.sample = split(k.df,k.df$Coef)#
			return(stats.sample)#
#
			}#
# Function to shuffle condition labels assuming that we hold groups of trials constant. i.e., does the same as shuffling averaged data.#
			# Function to shuffle the condition label then compute the same stats as above#
			# This does the resampling on your data.#
			resample.within = function(data_file,StartTime,EndTime,StepSize){#
#
				summaryBy(Trial~Subj+Trial+Cond+Strength, data = data_file ) -> Trials#
				shuf.fnc <- function(x){#
				NewCond <- x$Cond[sample.int(length(x$Cond))]#
				NewStrength <- x$Strength[sample.int(length(x$Strength))]#
				return(data.frame(x,NewCond,NewStrength))#
					}#
				Trials = ddply(Trials, .(Subj), shuf.fnc)#
				for (i in unique(data_file$Subj)){#
					data_file_S = data_file[data_file$Subj == i,]#
                                        data_file_S.prac = data_file_S#
					for (j in unique(data_file_S.prac$Trial)){#
                                           data_file_S[ data_file_S.prac$Trial == j,]$Cond =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewCond),length(data_file_S[ data_file_S.prac$Trial == j,]$Cond))#
                                          data_file_S[ data_file_S.prac$Trial == j,]$Strength =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewStrength),length(data_file_S[ data_file_S.prac$Trial == j,]$Strength))#
                                        }#
					data_file[data_file$Subj == i,] = data_file_S#
                                      }#
				data_file$Cond = as.factor(data_file$Cond)#
				data_file$Strength = as.factor(data_file$Strength)#
				contrasts(data_file$Cond)[1] <- -1#
				contrasts(data_file$Cond)[2] <- 1#
				contrasts(data_file$Strength)[2] <- 1#
				contrasts(data_file$Strength)[1] <- -1#
			#	print(data_file[data_file$Subj == i,]$Pop[1:30])#
                        #       print(data_file[data_file$Subj == i,]$Trial[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Cond[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Strength[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Score[seq(300,1000, by = 25)])#
				stats.resample = calculate.statistics.within(data_file,StartTime,EndTime,StepSize)#
				return(stats.resample)#
				}#
			StartTime = 0#
			EndTime = 1500#
			StepSize = 100#
			# Get the relevant stats for your data file.#
			registerDoMC();#
			stats.sample = calculate.statistics.within(ET,StartTime,EndTime,StepSize)#
			sample.cluster1 = find.clusters(stats.sample[[1]]$pval,stats.sample[[1]]$Stat,stats.sample[[1]]$Time,cluster.size = 1)#
			sample.cluster2 = find.clusters(stats.sample[[2]]$pval,stats.sample[[2]]$Stat,stats.sample[[2]]$Time,cluster.size = 1)#
			sample.cluster3 = find.clusters(stats.sample[[3]]$pval,stats.sample[[3]]$Stat,stats.sample[[3]]$Time,cluster.size = 1)#
			#do the resampling#
			Resamples_N = 2500 # Number of samples (it will take 5-10 minutes to do 1000, so set this to 10 your first time to make sure the script works)#
			resample1.large.cluster = rep(NA,Resamples_N) #Preallocate your resample datafile #
			resample2.large.cluster = rep(NA,Resamples_N) #Preallocate your resample datafile #
			resample3.large.cluster = rep(NA,Resamples_N) #Preallocate your resample datafile #
			for (i in 1:Resamples_N){#
				print(i)#
			stats.resample = resample.within(ET,StartTime,EndTime,StepSize)#
			recluster1 = find.clusters(stats.resample[[1]]$pval,stats.resample[[1]]$Stat,stats.resample[[1]]$Time,cluster.size = 1)#
			recluster2 = find.clusters(stats.resample[[2]]$pval,stats.resample[[2]]$Stat,stats.resample[[2]]$Time,cluster.size = 1)#
			recluster3 = find.clusters(stats.resample[[3]]$pval,stats.resample[[3]]$Stat,stats.resample[[3]]$Time,cluster.size = 1)#
			resample1.max = ifelse(is.numeric(recluster1$cluster.stat),max(recluster1$cluster.stat),0)#
			resample2.max = ifelse(is.numeric(recluster2$cluster.stat),max(recluster2$cluster.stat),0)#
			resample3.max = ifelse(is.numeric(recluster3$cluster.stat),max(recluster3$cluster.stat),0)#
#
			 #Find the largest cluster (this is what you will be comparing against - is your cluster > 95% of largest clusters)#
			print(resample1.max)#
			print(resample3.max)#
			resample1.large.cluster[i] = ifelse(resample1.max>0,resample1.max,0)#
			resample2.large.cluster[i] = ifelse(resample2.max>0,resample2.max,0)#
			resample3.large.cluster[i] = ifelse(resample3.max>0,resample3.max,0)#
			}#
#
			sample.cluster1 = pval(sample.cluster1,resample1.large.cluster)#
			sample.cluster2 = pval(sample.cluster2,resample2.large.cluster)#
			sample.cluster3 = pval(sample.cluster3,resample3.large.cluster)#
			Within.Resamples = list(resample1.large.cluster,resample2.large.cluster,resample3.large.cluster, paste(Resamples_N, "Samples on date ", date()))#
			Within.Clusters = list(sample.cluster1,sample.cluster2,sample.cluster3)#
			save(Within.Clusters,within.Resamples,file =paste("WithinStats",substr(date(),5,7),substr(date(),22,23),".RDATA", sep = ""))
sample.cluster3
sample.cluster1
Data Analysis Scripts for analysis of population alone#
			calculate.statistics.within = function(data_file,StartTime,EndTime,StepSize){#
			#Load the relevant libraries#
			#Load the relevant libraries#
			require("lme4") #
			require(multicore)#
			require(doMC)#
			require(foreach)#
			require(plyr)#
			#Start the multicore machine!#
#
			#Split the data frame into a list for each timepoint#
			a = split(data_file[data_file$Time >= StartTime & data_file$Time <= EndTime,],data_file[data_file$Time >= StartTime & data_file$Time <= EndTime,]$Time)#
			#Parallel application of lmer and coefficient extraction, outputs another list as above#
			mclapply(a,function(x) coef(summary(lmer(Score~Cond*Strength + (1+Cond*Strength|Subj) , data = x)))[2:4,1:3]) -> a.co#
			# Evaluate the list to see whether t value meets a threshold (hard coded)#
			lapply(a.co,function(x) data.frame(x,pv = ifelse(abs(x[,3]) > 1.6,0.04,0.06), co = rownames(x))) -> k#
			# plyr that list into a dataframe#
			k.df = ldply(k)#
			k.df$.id = as.numeric(k.df$.id)#
			colnames(k.df) <- c("Time", "Estimate","SE", "Stat", "pval","Coef")#
			k.df$Coef = ordered(k.df$Coef,levels = c("CondU","Strengthweak","CondU:Strengthweak"))#
			#Split that dataframe into a list based on the regression coefficients#
			stats.sample = split(k.df,k.df$Coef)#
			return(stats.sample)#
#
			}#
# Function to shuffle condition labels assuming that we hold groups of trials constant. i.e., does the same as shuffling averaged data.#
			# Function to shuffle the condition label then compute the same stats as above#
			# This does the resampling on your data.#
			resample.within = function(data_file,StartTime,EndTime,StepSize){#
#
				summaryBy(Trial~Subj+Trial+Cond+Strength, data = data_file ) -> Trials#
				shuf.fnc <- function(x){#
				NewCond <- x$Cond[sample.int(length(x$Cond))]#
				NewStrength <- x$Strength[sample.int(length(x$Strength))]#
				return(data.frame(x,NewCond,NewStrength))#
					}#
				Trials = ddply(Trials, .(Subj), shuf.fnc)#
				for (i in unique(data_file$Subj)){#
					data_file_S = data_file[data_file$Subj == i,]#
                                        data_file_S.prac = data_file_S#
					for (j in unique(data_file_S.prac$Trial)){#
                                           data_file_S[ data_file_S.prac$Trial == j,]$Cond =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewCond),length(data_file_S[ data_file_S.prac$Trial == j,]$Cond))#
                                          data_file_S[ data_file_S.prac$Trial == j,]$Strength =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewStrength),length(data_file_S[ data_file_S.prac$Trial == j,]$Strength))#
                                        }#
					data_file[data_file$Subj == i,] = data_file_S#
                                      }#
				data_file$Cond = as.factor(data_file$Cond)#
				data_file$Strength = as.factor(data_file$Strength)#
				contrasts(data_file$Cond)[1] <- -1#
				contrasts(data_file$Cond)[2] <- 1#
				contrasts(data_file$Strength)[2] <- 1#
				contrasts(data_file$Strength)[1] <- -1#
			#	print(data_file[data_file$Subj == i,]$Pop[1:30])#
                        #       print(data_file[data_file$Subj == i,]$Trial[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Cond[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Strength[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Score[seq(300,1000, by = 25)])#
				stats.resample = calculate.statistics.within(data_file,StartTime,EndTime,StepSize)#
				return(stats.resample)#
				}#
			StartTime = 0#
			EndTime = 1500#
			StepSize = 100#
			# Get the relevant stats for your data file.#
			registerDoMC();#
			stats.sample = calculate.statistics.within(ET,StartTime,EndTime,StepSize)#
			sample.cluster1 = find.clusters(stats.sample[[1]]$pval,stats.sample[[1]]$Stat,stats.sample[[1]]$Time,cluster.size = 1)#
			sample.cluster2 = find.clusters(stats.sample[[2]]$pval,stats.sample[[2]]$Stat,stats.sample[[2]]$Time,cluster.size = 1)#
			sample.cluster3 = find.clusters(stats.sample[[3]]$pval,stats.sample[[3]]$Stat,stats.sample[[3]]$Time,cluster.size = 1)#
			#do the resampling#
			Resamples_N = 250 # Number of samples (it will take 5-10 minutes to do 1000, so set this to 10 your first time to make sure the script works)#
			resample1.large.cluster = rep(NA,Resamples_N) #Preallocate your resample datafile #
			resample2.large.cluster = rep(NA,Resamples_N) #Preallocate your resample datafile #
			resample3.large.cluster = rep(NA,Resamples_N) #Preallocate your resample datafile #
			for (i in 1:Resamples_N){#
				print(i)#
			stats.resample = resample.within(ET,StartTime,EndTime,StepSize)#
			recluster1 = find.clusters(stats.resample[[1]]$pval,stats.resample[[1]]$Stat,stats.resample[[1]]$Time,cluster.size = 1)#
			recluster2 = find.clusters(stats.resample[[2]]$pval,stats.resample[[2]]$Stat,stats.resample[[2]]$Time,cluster.size = 1)#
			recluster3 = find.clusters(stats.resample[[3]]$pval,stats.resample[[3]]$Stat,stats.resample[[3]]$Time,cluster.size = 1)#
			resample1.max = ifelse(is.numeric(recluster1$cluster.stat),max(recluster1$cluster.stat),0)#
			resample2.max = ifelse(is.numeric(recluster2$cluster.stat),max(recluster2$cluster.stat),0)#
			resample3.max = ifelse(is.numeric(recluster3$cluster.stat),max(recluster3$cluster.stat),0)#
#
			 #Find the largest cluster (this is what you will be comparing against - is your cluster > 95% of largest clusters)#
			print(resample1.max)#
			print(resample3.max)#
			resample1.large.cluster[i] = ifelse(resample1.max>0,resample1.max,0)#
			resample2.large.cluster[i] = ifelse(resample2.max>0,resample2.max,0)#
			resample3.large.cluster[i] = ifelse(resample3.max>0,resample3.max,0)#
			}#
#
			sample.cluster1 = pval(sample.cluster1,resample1.large.cluster)#
			sample.cluster2 = pval(sample.cluster2,resample2.large.cluster)#
			sample.cluster3 = pval(sample.cluster3,resample3.large.cluster)#
			Within.Resamples = list(resample1.large.cluster,resample2.large.cluster,resample3.large.cluster, paste(Resamples_N, "Samples on date ", date()))#
			Within.Clusters = list(sample.cluster1,sample.cluster2,sample.cluster3)#
			save(Within.Clusters,within.Resamples,file =paste("WithinStats",substr(date(),5,7),substr(date(),22,23),".RDATA", sep = ""))
library(lme4)
summary(lmer(Score~Cond*Strength*Pop +(1+Cond*Strength|Subj) , data = subset(ET, Time == 400)))
summary(lmer(Score~Cond*Strength*Pop +(1+Cond*Strength|Subj) , data = subset(ET, Time == 500)))
summary(lmer(Score~Cond*Strength*Pop +(1+Cond*Strength|Subj) , data = subset(ET, Time == 900)))
summary(lmer(Score~Cond*Strength*Pop +(1+Cond+Strength|Subj) , data = subset(ET, Time == 900)))
summary(subset(ET, Time == 900)
)
summary(subset(ET, Time == 800))
ET$Score <- ifelse(ET$Score <= -3.66, 0,1)
summary(lmer(Score~Cond*Strength*Pop +(1+Cond+Strength|Subj) , data = subset(ET, Time == 900), family = "binomial"))
Data Analysis Scripts#
#
# Function to shuffle condition labels assuming that we hold groups of trials constant. i.e., does the same as shuffling averaged data.#
			# Function to shuffle the condition label then compute the same stats as above#
			# This does the resampling on your data.#
			resample = function(data_file,StartTime,EndTime,StepSize){#
#
				summaryBy(Trial~Subj+Trial+Cond+Strength+Pop, data = data_file ) -> Trials#
				shuf.fnc <- function(x){#
				NewCond <- x$Cond[sample.int(length(x$Cond))]#
				NewStrength <- x$Strength[sample.int(length(x$Strength))]#
				return(data.frame(x,NewCond,NewStrength))#
					}#
				Trials = ddply(Trials, .(Subj), shuf.fnc)#
				for (i in unique(data_file$Subj)){#
					data_file_S = data_file[data_file$Subj == i,]#
                                        data_file_S.prac = data_file_S#
					for (j in unique(data_file_S.prac$Trial)){#
                                           data_file_S[ data_file_S.prac$Trial == j,]$Cond =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewCond),length(data_file_S[ data_file_S.prac$Trial == j,]$Cond))#
                                          data_file_S[ data_file_S.prac$Trial == j,]$Strength =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewStrength),length(data_file_S[ data_file_S.prac$Trial == j,]$Strength))#
                                        }#
					data_file[data_file$Subj == i,] = data_file_S#
                                      }#
                                Trials <- summaryBy(Subj~Subj+Pop, data = Trials)#
                                Trials$Order = NA#
                                Trials$Order = sample.int(length(Trials$Order),length(Trials$Order))#
                                Trials$Pop = Trials[order(Trials$Order),]$Pop#
                                #print(Trials$Pop)#
#
                                for (i in unique(data_file$Subj)){ #
                                data_file[data_file$Subj == i,]$Pop = Trials[Trials$Subj == i,]$Pop#
                              }#
				data_file$Cond = as.factor(data_file$Cond)#
				data_file$Strength = as.factor(data_file$Strength)#
                                data_file$Pop = as.factor(data_file$Pop)#
				contrasts(data_file$Cond)[1] <- -1#
				contrasts(data_file$Cond)[2] <- 1#
				contrasts(data_file$Strength)[2] <- 1#
				contrasts(data_file$Strength)[1] <- -1#
				contrasts(data_file$Pop)[2] <- 1#
				contrasts(data_file$Pop)[1] <- -1#
			#	print(data_file[data_file$Subj == i,]$Pop[1:30])#
                        #       print(data_file[data_file$Subj == i,]$Trial[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Cond[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Strength[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Score[seq(300,1000, by = 25)])#
				stats.resample = calculate.statistics(data_file,StartTime,EndTime,StepSize)#
				return(stats.resample)#
				}#
# Cluster finding function and pval finding function#
			# Cluster finding script (written by Jon Brennan )#
			find.clusters <- function(pval.vector, tval.vector, latencies, alpha=.05, cluster.size=5,signed =FALSE, sign = "pos") {#
				binary.stat <- as.numeric(pval.vector < alpha)#
				tval.stat <- rep(0,length(binary.stat))#
				tval.stat[2:length(binary.stat)] = ((tval.vector[2:length(binary.stat)] * tval.vector[1:(length(binary.stat)-1)]) <0)#
				cluster.start <- c()#
				cluster.end <- c()#
				cluster.stat <- c()#
				in.cluster <- 0#
				found.clusters <- 0#
				new.end <- 0#
				new.start <- 0#
				end.cluster <- 0#
				for (n in 1:length(binary.stat)) {#
					if (signed == FALSE){#
						if (in.cluster == 0 && binary.stat[n] == 1 ) {#
							new.start = n#
							in.cluster = 1#
							}#
					}else#
					if (sign == "pos"){#
						if (in.cluster == 0 && binary.stat[n] == 1 && tval.vector[n] >= 0) {#
							new.start = n#
							in.cluster = 1#
							}#
					}else#
						if (in.cluster == 0 && binary.stat[n] == 1 && tval.vector[n] <= 0) {#
							new.start = n#
							in.cluster = 1#
								}#
					if (in.cluster == 1 && binary.stat[n] == 0) {#
						new.end = n#
						end.cluster = 1#
						in.cluster = 0			#
						}#
					if (in.cluster == 1 && tval.stat[n] == 1) {#
						new.end = n#
						end.cluster = 1#
						in.cluster = 0			#
						}				#
					# in case we reach the end and we are still "in" a cluster...#
					if (in.cluster == 1 && binary.stat[n] == 1 && n == length(binary.stat)) {#
						new.end = n#
						end.cluster = 1#
						in.cluster = 1#
						}		#
					if (end.cluster) {	#
						if ((new.end - new.start) >= cluster.size) {#
							found.clusters <- found.clusters + 1#
							cluster.start<- c(cluster.start, latencies[new.start])#
							cluster.end <- c(cluster.end, latencies[new.end])#
							cluster.stat <- c(cluster.stat, sum(abs(tval.vector[new.start:(new.end-1)])))#
							}#
						end.cluster = 0#
						}#
					}#
				cluster.out <- data.frame(start = cluster.start, end = cluster.end, cluster.stat = cluster.stat)#
				return(cluster.out)	#
				}#
			# Script for assigning pvals to clusters	#
			pval = function(sample.cluster,resample.large.cluster){#
			sample.cluster$pval = 1#
			for (i in 1:length(sample.cluster$cluster.stat)){#
				print(i)#
				sample.cluster$pval[i] = 1 - sum(as.numeric(sample.cluster$cluster.stat[i]>resample.large.cluster)/Resamples_N)#
					}#
					return(sample.cluster)#
			}#
# What analysis will we be doing at each time point?#
#
			calculate.statistics = function(data_file,StartTime,EndTime,StepSize){#
			#Load the relevant libraries#
			require("lme4") #
			require(multicore)#
			require(doMC)#
			require(foreach)#
			require(plyr)#
			#Start the multicore machine!#
#
			#Split the data frame into a list for each timepoint#
			a = split(data_file[data_file$Time >= StartTime & data_file$Time <= EndTime,],data_file[data_file$Time >= StartTime & data_file$Time <= EndTime,]$Time)#
			#Parallel application of lmer and coefficient extraction, outputs another list as above#
			mclapply(a,function(x) coef(summary(lmer(Score~Cond*Strength*Pop +(1+Cond*Strength|Subj) , data = x, family = "binomial")))[2:8,1:3]) -> a.co#
			# Evaluate the list to see whether t value meets a threshold (hard coded)#
			lapply(a.co,function(x) data.frame(x,pv = ifelse(abs(x[,3]) > 1.6,0.04,0.06), co = rownames(x))) -> k#
			# plyr that list into a dataframe#
			k.df = ldply(k)#
			k.df$.id = as.numeric(k.df$.id)#
			colnames(k.df) <- c("Time", "Estimate","SE", "Stat", "pval","Coef")#
			k.df$Coef = ordered(k.df$Coef,levels = c("CondU","Strengthweak","PopControl","CondU:Strengthweak","CondU:PopControl","Strengthweak:PopControl", "CondU:Strengthweak:PopControl"))#
			#Split that dataframe into a list based on the regression coefficients#
			stats.sample = split(k.df,k.df$Coef)#
			return(stats.sample)#
			}#
# What analysis will we be doing at each time point?#
#
			calculate.statistics.nopop = function(data_file,StartTime,EndTime,StepSize){#
			require("lme4") #
			require(multicore)#
			require(doMC)#
			require(foreach)#
			require(plyr)			#
			a = split(data_file[data_file$Time >= StartTime & data_file$Time <= EndTime,],data_file[data_file$Time >= 0 & data_file$Time <= 1500,]$Time)#
			mclapply(a,function(x) coef(summary(lmer(Score~Cond*Strength +(1+Cond+Strength|Subj) + (1+Cond+Strength|Trial), data = x)))[2:4,1:3]) -> a.co#
			lapply(a.co,function(x) data.frame(x,pv = ifelse(abs(x[,3]) > 1.6,0.04,0.06), co = rownames(x))) -> k#
			k.df = ldply(k)#
			k.df$.id = as.numeric(k.df$.id)#
			colnames(k.df) <- c("Time", "Estimate","SE", "Stat", "pval","Coef")#
			k.df$Coef = ordered(k.df$Coef,levels = c("CondU","Strengthweak","CondU:Strengthweak"))#
			stats.sample = split(k.df,k.df$Coef)#
			return(stats.sample)#
			}#
pval = function(sample.cluster,resample.large.cluster){#
			sample.cluster$pval = 1#
			for (i in 1:length(sample.cluster$cluster.stat)){#
				print(i)#
				sample.cluster$pval[i] = 1 - sum(as.numeric(sample.cluster$cluster.stat[i]>resample.large.cluster)/Resamples_N)#
					}#
					return(sample.cluster)#
			}#
#
# Data Analysis Scripts#
#
# Function to shuffle condition labels assuming that we hold groups of trials constant. i.e., does the same as shuffling averaged data.#
			# Function to shuffle the condition label then compute the same stats as above#
			# This does the resampling on your data.#
			resample.nopop = function(data_file,StartTime,EndTime,StepSize){#
				summaryBy(Trial~Subj+Trial+Cond+Strength+Pop, data = data_file ) -> Trials#
				Trials$Order = NA#
                                Trials$NewCond = Trials$Cond#
                                Trials$NewStrength = Trials$Strength#
                                Trials$NewPop = Trials$Pop#
			for (i in unique(Trials$Subj)){#
				Trials[Trials$Subj == i,]$Order = sample.int(length(Trials[Trials$Subj == i,]$Cond),length(Trials[Trials$Subj == i,]$Cond))	#
				Trials[Trials$Subj == i,]$NewCond = Trials[ order(Trials[Trials$Subj == i,]$Order),]$Cond#
                                #Trials[Trials$Subj == i,]$NewOrder = sample.int(length(Trials[Trials$Subj == i,]$Cond),length(Trials[Trials$Subj == i,]$Cond))	#
				Trials[Trials$Subj == i,]$NewStrength = Trials[ order(Trials[Trials$Subj == i,]$Order),]$Strength                                #
			}#
				for (i in unique(data_file$Subj)){#
					data_file_S = data_file[data_file$Subj == i,]#
                                        data_file_S.prac = data_file_S#
					for (j in unique(data_file_S.prac$Trial)){#
                                           data_file_S[ data_file_S.prac$Trial == j,]$Cond =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewCond),length(data_file_S[ data_file_S.prac$Trial == j,]$Cond))#
                                          data_file_S[ data_file_S.prac$Trial == j,]$Strength =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewStrength),length(data_file_S[ data_file_S.prac$Trial == j,]$Strength))#
                                        }#
					data_file[data_file$Subj == i,] = data_file_S#
                                      }#
                                Trials <- summaryBy(Subj~Subj+Pop, data = Trials)#
                                Trials$Order = NA#
                                Trials$Order = sample.int(length(Trials$Order),length(Trials$Order))#
                                Trials$Pop = Trials[order(Trials$Order),]$Pop#
                                #print(Trials$Pop)#
#
                                for (i in unique(data_file$Subj)){ #
                                data_file[data_file$Subj == i,]$Pop = Trials[Trials$Subj == i,]$Pop#
                              }#
				data_file$Cond = as.factor(data_file$Cond)#
				data_file$Strength = as.factor(data_file$Strength)#
                                data_file$Pop = as.factor(data_file$Pop)#
				contrasts(data_file$Cond)[1] <- -1#
				contrasts(data_file$Cond)[2] <- 1#
				contrasts(data_file$Strength)[2] <- 1#
				contrasts(data_file$Strength)[1] <- -1#
				#contrasts(data_file$Pop)[2] <- 1#
				#contrasts(data_file$Pop)[1] <- -1#
			#	print(data_file[data_file$Subj == i,]$Pop[1:30])#
                        #       print(data_file[data_file$Subj == i,]$Trial[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Cond[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Strength[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Score[seq(300,1000, by = 25)])#
				stats.resample = calculate.statistics.nopop(data_file,StartTime,EndTime,StepSize)#
				return(stats.resample)#
				}
StartTime = 0#
			EndTime = 1500#
			StepSize = 100#
			# Get the relevant stats for your data file.#
			registerDoMC();#
#
			stats.sample = calculate.statistics(ET,StartTime,EndTime,StepSize)
stats.sample
Data Analysis Scripts#
#
# Function to shuffle condition labels assuming that we hold groups of trials constant. i.e., does the same as shuffling averaged data.#
			# Function to shuffle the condition label then compute the same stats as above#
			# This does the resampling on your data.#
			resample = function(data_file,StartTime,EndTime,StepSize){#
#
				summaryBy(Trial~Subj+Trial+Cond+Strength+Pop, data = data_file ) -> Trials#
				shuf.fnc <- function(x){#
				NewCond <- x$Cond[sample.int(length(x$Cond))]#
				NewStrength <- x$Strength[sample.int(length(x$Strength))]#
				return(data.frame(x,NewCond,NewStrength))#
					}#
				Trials = ddply(Trials, .(Subj), shuf.fnc)#
				for (i in unique(data_file$Subj)){#
					data_file_S = data_file[data_file$Subj == i,]#
                                        data_file_S.prac = data_file_S#
					for (j in unique(data_file_S.prac$Trial)){#
                                           data_file_S[ data_file_S.prac$Trial == j,]$Cond =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewCond),length(data_file_S[ data_file_S.prac$Trial == j,]$Cond))#
                                          data_file_S[ data_file_S.prac$Trial == j,]$Strength =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewStrength),length(data_file_S[ data_file_S.prac$Trial == j,]$Strength))#
                                        }#
					data_file[data_file$Subj == i,] = data_file_S#
                                      }#
                                Trials <- summaryBy(Subj~Subj+Pop, data = Trials)#
                                Trials$Order = NA#
                                Trials$Order = sample.int(length(Trials$Order),length(Trials$Order))#
                                Trials$Pop = Trials[order(Trials$Order),]$Pop#
                                #print(Trials$Pop)#
#
                                for (i in unique(data_file$Subj)){ #
                                data_file[data_file$Subj == i,]$Pop = Trials[Trials$Subj == i,]$Pop#
                              }#
				data_file$Cond = as.factor(data_file$Cond)#
				data_file$Strength = as.factor(data_file$Strength)#
                                data_file$Pop = as.factor(data_file$Pop)#
				contrasts(data_file$Cond)[1] <- -1#
				contrasts(data_file$Cond)[2] <- 1#
				contrasts(data_file$Strength)[2] <- 1#
				contrasts(data_file$Strength)[1] <- -1#
				contrasts(data_file$Pop)[2] <- 1#
				contrasts(data_file$Pop)[1] <- -1#
			#	print(data_file[data_file$Subj == i,]$Pop[1:30])#
                        #       print(data_file[data_file$Subj == i,]$Trial[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Cond[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Strength[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Score[seq(300,1000, by = 25)])#
				stats.resample = calculate.statistics(data_file,StartTime,EndTime,StepSize)#
				return(stats.resample)#
				}#
# Cluster finding function and pval finding function#
			# Cluster finding script (written by Jon Brennan )#
			find.clusters <- function(pval.vector, tval.vector, latencies, alpha=.05, cluster.size=5,signed =FALSE, sign = "pos") {#
				binary.stat <- as.numeric(pval.vector < alpha)#
				tval.stat <- rep(0,length(binary.stat))#
				tval.stat[2:length(binary.stat)] = ((tval.vector[2:length(binary.stat)] * tval.vector[1:(length(binary.stat)-1)]) <0)#
				cluster.start <- c()#
				cluster.end <- c()#
				cluster.stat <- c()#
				in.cluster <- 0#
				found.clusters <- 0#
				new.end <- 0#
				new.start <- 0#
				end.cluster <- 0#
				for (n in 1:length(binary.stat)) {#
					if (signed == FALSE){#
						if (in.cluster == 0 && binary.stat[n] == 1 ) {#
							new.start = n#
							in.cluster = 1#
							}#
					}else#
					if (sign == "pos"){#
						if (in.cluster == 0 && binary.stat[n] == 1 && tval.vector[n] >= 0) {#
							new.start = n#
							in.cluster = 1#
							}#
					}else#
						if (in.cluster == 0 && binary.stat[n] == 1 && tval.vector[n] <= 0) {#
							new.start = n#
							in.cluster = 1#
								}#
					if (in.cluster == 1 && binary.stat[n] == 0) {#
						new.end = n#
						end.cluster = 1#
						in.cluster = 0			#
						}#
					if (in.cluster == 1 && tval.stat[n] == 1) {#
						new.end = n#
						end.cluster = 1#
						in.cluster = 0			#
						}				#
					# in case we reach the end and we are still "in" a cluster...#
					if (in.cluster == 1 && binary.stat[n] == 1 && n == length(binary.stat)) {#
						new.end = n#
						end.cluster = 1#
						in.cluster = 1#
						}		#
					if (end.cluster) {	#
						if ((new.end - new.start) >= cluster.size) {#
							found.clusters <- found.clusters + 1#
							cluster.start<- c(cluster.start, latencies[new.start])#
							cluster.end <- c(cluster.end, latencies[new.end])#
							cluster.stat <- c(cluster.stat, sum(abs(tval.vector[new.start:(new.end-1)])))#
							}#
						end.cluster = 0#
						}#
					}#
				cluster.out <- data.frame(start = cluster.start, end = cluster.end, cluster.stat = cluster.stat)#
				return(cluster.out)	#
				}#
			# Script for assigning pvals to clusters	#
			pval = function(sample.cluster,resample.large.cluster){#
			sample.cluster$pval = 1#
			for (i in 1:length(sample.cluster$cluster.stat)){#
				print(i)#
				sample.cluster$pval[i] = 1 - sum(as.numeric(sample.cluster$cluster.stat[i]>resample.large.cluster)/Resamples_N)#
					}#
					return(sample.cluster)#
			}#
# What analysis will we be doing at each time point?#
#
			calculate.statistics = function(data_file,StartTime,EndTime,StepSize){#
			#Load the relevant libraries#
			require("lme4") #
			require(multicore)#
			require(doMC)#
			require(foreach)#
			require(plyr)#
			#Start the multicore machine!#
#
			#Split the data frame into a list for each timepoint#
			a = split(data_file[data_file$Time >= StartTime & data_file$Time <= EndTime,],data_file[data_file$Time >= StartTime & data_file$Time <= EndTime,]$Time)#
			#Parallel application of lmer and coefficient extraction, outputs another list as above#
			mclapply(a,function(x) coef(summary(lmer(Score~Cond*Strength*Pop +(1+Cond+Strength|Subj) , data = x, family = "binomial")))[2:8,1:3]) -> a.co#
			# Evaluate the list to see whether t value meets a threshold (hard coded)#
			lapply(a.co,function(x) data.frame(x,pv = ifelse(abs(x[,3]) > 1.6,0.04,0.06), co = rownames(x))) -> k#
			# plyr that list into a dataframe#
			k.df = ldply(k)#
			k.df$.id = as.numeric(k.df$.id)#
			colnames(k.df) <- c("Time", "Estimate","SE", "Stat", "pval","Coef")#
			k.df$Coef = ordered(k.df$Coef,levels = c("CondU","Strengthweak","PopControl","CondU:Strengthweak","CondU:PopControl","Strengthweak:PopControl", "CondU:Strengthweak:PopControl"))#
			#Split that dataframe into a list based on the regression coefficients#
			stats.sample = split(k.df,k.df$Coef)#
			return(stats.sample)#
			}#
# What analysis will we be doing at each time point?#
#
			calculate.statistics.nopop = function(data_file,StartTime,EndTime,StepSize){#
			require("lme4") #
			require(multicore)#
			require(doMC)#
			require(foreach)#
			require(plyr)			#
			a = split(data_file[data_file$Time >= StartTime & data_file$Time <= EndTime,],data_file[data_file$Time >= 0 & data_file$Time <= 1500,]$Time)#
			mclapply(a,function(x) coef(summary(lmer(Score~Cond*Strength +(1+Cond+Strength|Subj) + (1+Cond+Strength|Trial), data = x)))[2:4,1:3]) -> a.co#
			lapply(a.co,function(x) data.frame(x,pv = ifelse(abs(x[,3]) > 1.6,0.04,0.06), co = rownames(x))) -> k#
			k.df = ldply(k)#
			k.df$.id = as.numeric(k.df$.id)#
			colnames(k.df) <- c("Time", "Estimate","SE", "Stat", "pval","Coef")#
			k.df$Coef = ordered(k.df$Coef,levels = c("CondU","Strengthweak","CondU:Strengthweak"))#
			stats.sample = split(k.df,k.df$Coef)#
			return(stats.sample)#
			}#
pval = function(sample.cluster,resample.large.cluster){#
			sample.cluster$pval = 1#
			for (i in 1:length(sample.cluster$cluster.stat)){#
				print(i)#
				sample.cluster$pval[i] = 1 - sum(as.numeric(sample.cluster$cluster.stat[i]>resample.large.cluster)/Resamples_N)#
					}#
					return(sample.cluster)#
			}#
#
# Data Analysis Scripts#
#
# Function to shuffle condition labels assuming that we hold groups of trials constant. i.e., does the same as shuffling averaged data.#
			# Function to shuffle the condition label then compute the same stats as above#
			# This does the resampling on your data.#
			resample.nopop = function(data_file,StartTime,EndTime,StepSize){#
				summaryBy(Trial~Subj+Trial+Cond+Strength+Pop, data = data_file ) -> Trials#
				Trials$Order = NA#
                                Trials$NewCond = Trials$Cond#
                                Trials$NewStrength = Trials$Strength#
                                Trials$NewPop = Trials$Pop#
			for (i in unique(Trials$Subj)){#
				Trials[Trials$Subj == i,]$Order = sample.int(length(Trials[Trials$Subj == i,]$Cond),length(Trials[Trials$Subj == i,]$Cond))	#
				Trials[Trials$Subj == i,]$NewCond = Trials[ order(Trials[Trials$Subj == i,]$Order),]$Cond#
                                #Trials[Trials$Subj == i,]$NewOrder = sample.int(length(Trials[Trials$Subj == i,]$Cond),length(Trials[Trials$Subj == i,]$Cond))	#
				Trials[Trials$Subj == i,]$NewStrength = Trials[ order(Trials[Trials$Subj == i,]$Order),]$Strength                                #
			}#
				for (i in unique(data_file$Subj)){#
					data_file_S = data_file[data_file$Subj == i,]#
                                        data_file_S.prac = data_file_S#
					for (j in unique(data_file_S.prac$Trial)){#
                                           data_file_S[ data_file_S.prac$Trial == j,]$Cond =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewCond),length(data_file_S[ data_file_S.prac$Trial == j,]$Cond))#
                                          data_file_S[ data_file_S.prac$Trial == j,]$Strength =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewStrength),length(data_file_S[ data_file_S.prac$Trial == j,]$Strength))#
                                        }#
					data_file[data_file$Subj == i,] = data_file_S#
                                      }#
                                Trials <- summaryBy(Subj~Subj+Pop, data = Trials)#
                                Trials$Order = NA#
                                Trials$Order = sample.int(length(Trials$Order),length(Trials$Order))#
                                Trials$Pop = Trials[order(Trials$Order),]$Pop#
                                #print(Trials$Pop)#
#
                                for (i in unique(data_file$Subj)){ #
                                data_file[data_file$Subj == i,]$Pop = Trials[Trials$Subj == i,]$Pop#
                              }#
				data_file$Cond = as.factor(data_file$Cond)#
				data_file$Strength = as.factor(data_file$Strength)#
                                data_file$Pop = as.factor(data_file$Pop)#
				contrasts(data_file$Cond)[1] <- -1#
				contrasts(data_file$Cond)[2] <- 1#
				contrasts(data_file$Strength)[2] <- 1#
				contrasts(data_file$Strength)[1] <- -1#
				#contrasts(data_file$Pop)[2] <- 1#
				#contrasts(data_file$Pop)[1] <- -1#
			#	print(data_file[data_file$Subj == i,]$Pop[1:30])#
                        #       print(data_file[data_file$Subj == i,]$Trial[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Cond[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Strength[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Score[seq(300,1000, by = 25)])#
				stats.resample = calculate.statistics.nopop(data_file,StartTime,EndTime,StepSize)#
				return(stats.resample)#
				}
StartTime = 0#
			EndTime = 1500#
			StepSize = 100#
			# Get the relevant stats for your data file.#
			registerDoMC();#
#
			stats.sample = calculate.statistics(ET,StartTime,EndTime,StepSize)
stats.sample
Data Analysis Scripts#
#
# Function to shuffle condition labels assuming that we hold groups of trials constant. i.e., does the same as shuffling averaged data.#
			# Function to shuffle the condition label then compute the same stats as above#
			# This does the resampling on your data.#
			resample = function(data_file,StartTime,EndTime,StepSize){#
#
				summaryBy(Trial~Subj+Trial+Cond+Strength+Pop, data = data_file ) -> Trials#
				shuf.fnc <- function(x){#
				NewCond <- x$Cond[sample.int(length(x$Cond))]#
				NewStrength <- x$Strength[sample.int(length(x$Strength))]#
				return(data.frame(x,NewCond,NewStrength))#
					}#
				Trials = ddply(Trials, .(Subj), shuf.fnc)#
				for (i in unique(data_file$Subj)){#
					data_file_S = data_file[data_file$Subj == i,]#
                                        data_file_S.prac = data_file_S#
					for (j in unique(data_file_S.prac$Trial)){#
                                           data_file_S[ data_file_S.prac$Trial == j,]$Cond =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewCond),length(data_file_S[ data_file_S.prac$Trial == j,]$Cond))#
                                          data_file_S[ data_file_S.prac$Trial == j,]$Strength =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewStrength),length(data_file_S[ data_file_S.prac$Trial == j,]$Strength))#
                                        }#
					data_file[data_file$Subj == i,] = data_file_S#
                                      }#
                                Trials <- summaryBy(Subj~Subj+Pop, data = Trials)#
                                Trials$Order = NA#
                                Trials$Order = sample.int(length(Trials$Order),length(Trials$Order))#
                                Trials$Pop = Trials[order(Trials$Order),]$Pop#
                                #print(Trials$Pop)#
#
                                for (i in unique(data_file$Subj)){ #
                                data_file[data_file$Subj == i,]$Pop = Trials[Trials$Subj == i,]$Pop#
                              }#
				data_file$Cond = as.factor(data_file$Cond)#
				data_file$Strength = as.factor(data_file$Strength)#
                                data_file$Pop = as.factor(data_file$Pop)#
				contrasts(data_file$Cond)[1] <- -1#
				contrasts(data_file$Cond)[2] <- 1#
				contrasts(data_file$Strength)[2] <- 1#
				contrasts(data_file$Strength)[1] <- -1#
				contrasts(data_file$Pop)[2] <- 1#
				contrasts(data_file$Pop)[1] <- -1#
			#	print(data_file[data_file$Subj == i,]$Pop[1:30])#
                        #       print(data_file[data_file$Subj == i,]$Trial[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Cond[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Strength[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Score[seq(300,1000, by = 25)])#
				stats.resample = calculate.statistics(data_file,StartTime,EndTime,StepSize)#
				return(stats.resample)#
				}#
# Cluster finding function and pval finding function#
			# Cluster finding script (written by Jon Brennan )#
			find.clusters <- function(pval.vector, tval.vector, latencies, alpha=.05, cluster.size=5,signed =FALSE, sign = "pos") {#
				binary.stat <- as.numeric(pval.vector < alpha)#
				tval.stat <- rep(0,length(binary.stat))#
				tval.stat[2:length(binary.stat)] = ((tval.vector[2:length(binary.stat)] * tval.vector[1:(length(binary.stat)-1)]) <0)#
				cluster.start <- c()#
				cluster.end <- c()#
				cluster.stat <- c()#
				in.cluster <- 0#
				found.clusters <- 0#
				new.end <- 0#
				new.start <- 0#
				end.cluster <- 0#
				for (n in 1:length(binary.stat)) {#
					if (signed == FALSE){#
						if (in.cluster == 0 && binary.stat[n] == 1 ) {#
							new.start = n#
							in.cluster = 1#
							}#
					}else#
					if (sign == "pos"){#
						if (in.cluster == 0 && binary.stat[n] == 1 && tval.vector[n] >= 0) {#
							new.start = n#
							in.cluster = 1#
							}#
					}else#
						if (in.cluster == 0 && binary.stat[n] == 1 && tval.vector[n] <= 0) {#
							new.start = n#
							in.cluster = 1#
								}#
					if (in.cluster == 1 && binary.stat[n] == 0) {#
						new.end = n#
						end.cluster = 1#
						in.cluster = 0			#
						}#
					if (in.cluster == 1 && tval.stat[n] == 1) {#
						new.end = n#
						end.cluster = 1#
						in.cluster = 0			#
						}				#
					# in case we reach the end and we are still "in" a cluster...#
					if (in.cluster == 1 && binary.stat[n] == 1 && n == length(binary.stat)) {#
						new.end = n#
						end.cluster = 1#
						in.cluster = 1#
						}		#
					if (end.cluster) {	#
						if ((new.end - new.start) >= cluster.size) {#
							found.clusters <- found.clusters + 1#
							cluster.start<- c(cluster.start, latencies[new.start])#
							cluster.end <- c(cluster.end, latencies[new.end])#
							cluster.stat <- c(cluster.stat, sum(abs(tval.vector[new.start:(new.end-1)])))#
							}#
						end.cluster = 0#
						}#
					}#
				cluster.out <- data.frame(start = cluster.start, end = cluster.end, cluster.stat = cluster.stat)#
				return(cluster.out)	#
				}#
			# Script for assigning pvals to clusters	#
			pval = function(sample.cluster,resample.large.cluster){#
			sample.cluster$pval = 1#
			for (i in 1:length(sample.cluster$cluster.stat)){#
				print(i)#
				sample.cluster$pval[i] = 1 - sum(as.numeric(sample.cluster$cluster.stat[i]>resample.large.cluster)/Resamples_N)#
					}#
					return(sample.cluster)#
			}#
# What analysis will we be doing at each time point?#
#
			calculate.statistics = function(data_file,StartTime,EndTime,StepSize){#
			#Load the relevant libraries#
			require("lme4") #
			require(multicore)#
			require(doMC)#
			require(foreach)#
			require(plyr)#
			#Start the multicore machine!#
#
			#Split the data frame into a list for each timepoint#
			a = split(data_file[data_file$Time >= StartTime & data_file$Time <= EndTime,],data_file[data_file$Time >= StartTime & data_file$Time <= EndTime,]$Time)#
			#Parallel application of lmer and coefficient extraction, outputs another list as above#
			mclapply(a,function(x) coef(summary(lmer(Score~Cond*Strength*Pop +(1+Cond*Strength|Subj) , data = x, family = "binomial")))[2:8,1:3]) -> a.co#
			# Evaluate the list to see whether t value meets a threshold (hard coded)#
			lapply(a.co,function(x) data.frame(x,pv = ifelse(abs(x[,3]) > 1.6,0.04,0.06), co = rownames(x))) -> k#
			# plyr that list into a dataframe#
			k.df = ldply(k)#
			k.df$.id = as.numeric(k.df$.id)#
			colnames(k.df) <- c("Time", "Estimate","SE", "Stat", "pval","Coef")#
			k.df$Coef = ordered(k.df$Coef,levels = c("CondU","Strengthweak","PopControl","CondU:Strengthweak","CondU:PopControl","Strengthweak:PopControl", "CondU:Strengthweak:PopControl"))#
			#Split that dataframe into a list based on the regression coefficients#
			stats.sample = split(k.df,k.df$Coef)#
			return(stats.sample)#
			}#
# What analysis will we be doing at each time point?#
#
			calculate.statistics.nopop = function(data_file,StartTime,EndTime,StepSize){#
			require("lme4") #
			require(multicore)#
			require(doMC)#
			require(foreach)#
			require(plyr)			#
			a = split(data_file[data_file$Time >= StartTime & data_file$Time <= EndTime,],data_file[data_file$Time >= 0 & data_file$Time <= 1500,]$Time)#
			mclapply(a,function(x) coef(summary(lmer(Score~Cond*Strength +(1+Cond+Strength|Subj) + (1+Cond+Strength|Trial), data = x)))[2:4,1:3]) -> a.co#
			lapply(a.co,function(x) data.frame(x,pv = ifelse(abs(x[,3]) > 1.6,0.04,0.06), co = rownames(x))) -> k#
			k.df = ldply(k)#
			k.df$.id = as.numeric(k.df$.id)#
			colnames(k.df) <- c("Time", "Estimate","SE", "Stat", "pval","Coef")#
			k.df$Coef = ordered(k.df$Coef,levels = c("CondU","Strengthweak","CondU:Strengthweak"))#
			stats.sample = split(k.df,k.df$Coef)#
			return(stats.sample)#
			}#
pval = function(sample.cluster,resample.large.cluster){#
			sample.cluster$pval = 1#
			for (i in 1:length(sample.cluster$cluster.stat)){#
				print(i)#
				sample.cluster$pval[i] = 1 - sum(as.numeric(sample.cluster$cluster.stat[i]>resample.large.cluster)/Resamples_N)#
					}#
					return(sample.cluster)#
			}#
#
# Data Analysis Scripts#
#
# Function to shuffle condition labels assuming that we hold groups of trials constant. i.e., does the same as shuffling averaged data.#
			# Function to shuffle the condition label then compute the same stats as above#
			# This does the resampling on your data.#
			resample.nopop = function(data_file,StartTime,EndTime,StepSize){#
				summaryBy(Trial~Subj+Trial+Cond+Strength+Pop, data = data_file ) -> Trials#
				Trials$Order = NA#
                                Trials$NewCond = Trials$Cond#
                                Trials$NewStrength = Trials$Strength#
                                Trials$NewPop = Trials$Pop#
			for (i in unique(Trials$Subj)){#
				Trials[Trials$Subj == i,]$Order = sample.int(length(Trials[Trials$Subj == i,]$Cond),length(Trials[Trials$Subj == i,]$Cond))	#
				Trials[Trials$Subj == i,]$NewCond = Trials[ order(Trials[Trials$Subj == i,]$Order),]$Cond#
                                #Trials[Trials$Subj == i,]$NewOrder = sample.int(length(Trials[Trials$Subj == i,]$Cond),length(Trials[Trials$Subj == i,]$Cond))	#
				Trials[Trials$Subj == i,]$NewStrength = Trials[ order(Trials[Trials$Subj == i,]$Order),]$Strength                                #
			}#
				for (i in unique(data_file$Subj)){#
					data_file_S = data_file[data_file$Subj == i,]#
                                        data_file_S.prac = data_file_S#
					for (j in unique(data_file_S.prac$Trial)){#
                                           data_file_S[ data_file_S.prac$Trial == j,]$Cond =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewCond),length(data_file_S[ data_file_S.prac$Trial == j,]$Cond))#
                                          data_file_S[ data_file_S.prac$Trial == j,]$Strength =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewStrength),length(data_file_S[ data_file_S.prac$Trial == j,]$Strength))#
                                        }#
					data_file[data_file$Subj == i,] = data_file_S#
                                      }#
                                Trials <- summaryBy(Subj~Subj+Pop, data = Trials)#
                                Trials$Order = NA#
                                Trials$Order = sample.int(length(Trials$Order),length(Trials$Order))#
                                Trials$Pop = Trials[order(Trials$Order),]$Pop#
                                #print(Trials$Pop)#
#
                                for (i in unique(data_file$Subj)){ #
                                data_file[data_file$Subj == i,]$Pop = Trials[Trials$Subj == i,]$Pop#
                              }#
				data_file$Cond = as.factor(data_file$Cond)#
				data_file$Strength = as.factor(data_file$Strength)#
                                data_file$Pop = as.factor(data_file$Pop)#
				contrasts(data_file$Cond)[1] <- -1#
				contrasts(data_file$Cond)[2] <- 1#
				contrasts(data_file$Strength)[2] <- 1#
				contrasts(data_file$Strength)[1] <- -1#
				#contrasts(data_file$Pop)[2] <- 1#
				#contrasts(data_file$Pop)[1] <- -1#
			#	print(data_file[data_file$Subj == i,]$Pop[1:30])#
                        #       print(data_file[data_file$Subj == i,]$Trial[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Cond[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Strength[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Score[seq(300,1000, by = 25)])#
				stats.resample = calculate.statistics.nopop(data_file,StartTime,EndTime,StepSize)#
				return(stats.resample)#
				}
StartTime = 0#
			EndTime = 1500#
			StepSize = 100#
			# Get the relevant stats for your data file.#
			registerDoMC();#
#
			stats.sample = calculate.statistics(ET,StartTime,EndTime,StepSize)#
			sample.cluster1 = find.clusters(stats.sample[[1]]$pval,stats.sample[[1]]$Stat,stats.sample[[1]]$Time,cluster.size = 1)#
			sample.cluster2 = find.clusters(stats.sample[[2]]$pval,stats.sample[[2]]$Stat,stats.sample[[2]]$Time,cluster.size = 1)#
			sample.cluster3 = find.clusters(stats.sample[[3]]$pval,stats.sample[[3]]$Stat,stats.sample[[3]]$Time,cluster.size = 1)#
			sample.cluster4 = find.clusters(stats.sample[[4]]$pval,stats.sample[[4]]$Stat,stats.sample[[4]]$Time,cluster.size = 1)#
			sample.cluster5 = find.clusters(stats.sample[[5]]$pval,stats.sample[[5]]$Stat,stats.sample[[5]]$Time,cluster.size = 1)#
			sample.cluster6 = find.clusters(stats.sample[[6]]$pval,stats.sample[[6]]$Stat,stats.sample[[6]]$Time,cluster.size = 1)#
			sample.cluster7 = find.clusters(stats.sample[[7]]$pval,stats.sample[[7]]$Stat,stats.sample[[7]]$Time,cluster.size = 1)#
			#do the resampling#
			Resamples_N = 25 # Number of samples (it will take a long time to do 1000, so set this to 10 your first time to make sure the script works)#
			resample1.large.cluster = rep(NA,Resamples_N) #Preallocate your resample datafile #
			resample2.large.cluster = rep(NA,Resamples_N) #Preallocate your resample datafile #
			resample3.large.cluster = rep(NA,Resamples_N) #Preallocate your resample datafile #
			resample4.large.cluster = rep(NA,Resamples_N) #Preallocate your resample datafile #
			resample5.large.cluster = rep(NA,Resamples_N) #Preallocate your resample datafile #
			resample6.large.cluster = rep(NA,Resamples_N) #Preallocate your resample datafile #
			resample7.large.cluster = rep(NA,Resamples_N) #Preallocate your resample datafile #
			for (i in 1:Resamples_N){#
				print(i)#
			stats.resample = resample(ET,StartTime,EndTime,StepSize)#
			recluster1 = find.clusters(stats.resample[[1]]$pval,stats.resample[[1]]$Stat,stats.resample[[1]]$Time,cluster.size = 1)#
			recluster2 = find.clusters(stats.resample[[2]]$pval,stats.resample[[2]]$Stat,stats.resample[[2]]$Time,cluster.size = 1)#
			recluster3 = find.clusters(stats.resample[[3]]$pval,stats.resample[[3]]$Stat,stats.resample[[3]]$Time,cluster.size = 1)#
			recluster4 = find.clusters(stats.resample[[4]]$pval,stats.resample[[4]]$Stat,stats.resample[[4]]$Time,cluster.size = 1)#
			recluster5 = find.clusters(stats.resample[[5]]$pval,stats.resample[[5]]$Stat,stats.resample[[5]]$Time,cluster.size = 1)#
			recluster6 = find.clusters(stats.resample[[6]]$pval,stats.resample[[6]]$Stat,stats.resample[[6]]$Time,cluster.size = 1)#
			recluster7 = find.clusters(stats.resample[[7]]$pval,stats.resample[[7]]$Stat,stats.resample[[7]]$Time,cluster.size = 1)#
			resample1.max = ifelse(is.numeric(recluster1$cluster.stat),max(recluster1$cluster.stat),0)#
			resample2.max = ifelse(is.numeric(recluster2$cluster.stat),max(recluster2$cluster.stat),0)#
			resample3.max = ifelse(is.numeric(recluster3$cluster.stat),max(recluster3$cluster.stat),0)#
			resample4.max = ifelse(is.numeric(recluster4$cluster.stat),max(recluster4$cluster.stat),0)#
			resample5.max = ifelse(is.numeric(recluster5$cluster.stat),max(recluster5$cluster.stat),0)#
			resample6.max = ifelse(is.numeric(recluster6$cluster.stat),max(recluster6$cluster.stat),0)#
			resample7.max = ifelse(is.numeric(recluster7$cluster.stat),max(recluster7$cluster.stat),0)#
			 #Find the largest cluster (this is what you will be comparing against - is your cluster > 95% of largest clusters)#
			print(resample1.max)#
			print(resample3.max)#
		#	print(recluster1[recluster1$cluster.stat == max(recluster1$cluster.stat),]$start)#
		#	print(recluster3[recluster3$cluster.stat == max(recluster3$cluster.stat),]$start )#
			resample1.large.cluster[i] = ifelse(resample1.max>0,resample1.max,0)#
			resample2.large.cluster[i] = ifelse(resample2.max>0,resample2.max,0)#
			print(resample3.max)#
			resample3.large.cluster[i] = ifelse(resample3.max>0,resample3.max,0)#
			resample4.large.cluster[i] = ifelse(resample4.max>0,resample3.max,0)#
			resample5.large.cluster[i] = ifelse(resample5.max>0,resample3.max,0)#
			resample6.large.cluster[i] = ifelse(resample6.max>0,resample3.max,0)#
			resample7.large.cluster[i] = ifelse(resample7.max>0,resample3.max,0)#
#
			}#
#
			sample.cluster1 = pval(sample.cluster1,resample1.large.cluster)#
			sample.cluster2 = pval(sample.cluster2,resample2.large.cluster)#
			sample.cluster3 = pval(sample.cluster3,resample3.large.cluster)#
			sample.cluster4 = pval(sample.cluster4,resample4.large.cluster)#
			sample.cluster5 = pval(sample.cluster5,resample5.large.cluster)#
			sample.cluster6 = pval(sample.cluster6,resample6.large.cluster)#
			sample.cluster7 = pval(sample.cluster7,resample7.large.cluster)
library(doBy)
Resamples_N = 25 # Number of samples (it will take a long time to do 1000, so set this to 10 your first time to make sure the script works)#
			resample1.large.cluster = rep(NA,Resamples_N) #Preallocate your resample datafile #
			resample2.large.cluster = rep(NA,Resamples_N) #Preallocate your resample datafile #
			resample3.large.cluster = rep(NA,Resamples_N) #Preallocate your resample datafile #
			resample4.large.cluster = rep(NA,Resamples_N) #Preallocate your resample datafile #
			resample5.large.cluster = rep(NA,Resamples_N) #Preallocate your resample datafile #
			resample6.large.cluster = rep(NA,Resamples_N) #Preallocate your resample datafile #
			resample7.large.cluster = rep(NA,Resamples_N) #Preallocate your resample datafile #
			for (i in 1:Resamples_N){#
				print(i)#
			stats.resample = resample(ET,StartTime,EndTime,StepSize)#
			recluster1 = find.clusters(stats.resample[[1]]$pval,stats.resample[[1]]$Stat,stats.resample[[1]]$Time,cluster.size = 1)#
			recluster2 = find.clusters(stats.resample[[2]]$pval,stats.resample[[2]]$Stat,stats.resample[[2]]$Time,cluster.size = 1)#
			recluster3 = find.clusters(stats.resample[[3]]$pval,stats.resample[[3]]$Stat,stats.resample[[3]]$Time,cluster.size = 1)#
			recluster4 = find.clusters(stats.resample[[4]]$pval,stats.resample[[4]]$Stat,stats.resample[[4]]$Time,cluster.size = 1)#
			recluster5 = find.clusters(stats.resample[[5]]$pval,stats.resample[[5]]$Stat,stats.resample[[5]]$Time,cluster.size = 1)#
			recluster6 = find.clusters(stats.resample[[6]]$pval,stats.resample[[6]]$Stat,stats.resample[[6]]$Time,cluster.size = 1)#
			recluster7 = find.clusters(stats.resample[[7]]$pval,stats.resample[[7]]$Stat,stats.resample[[7]]$Time,cluster.size = 1)#
			resample1.max = ifelse(is.numeric(recluster1$cluster.stat),max(recluster1$cluster.stat),0)#
			resample2.max = ifelse(is.numeric(recluster2$cluster.stat),max(recluster2$cluster.stat),0)#
			resample3.max = ifelse(is.numeric(recluster3$cluster.stat),max(recluster3$cluster.stat),0)#
			resample4.max = ifelse(is.numeric(recluster4$cluster.stat),max(recluster4$cluster.stat),0)#
			resample5.max = ifelse(is.numeric(recluster5$cluster.stat),max(recluster5$cluster.stat),0)#
			resample6.max = ifelse(is.numeric(recluster6$cluster.stat),max(recluster6$cluster.stat),0)#
			resample7.max = ifelse(is.numeric(recluster7$cluster.stat),max(recluster7$cluster.stat),0)#
			 #Find the largest cluster (this is what you will be comparing against - is your cluster > 95% of largest clusters)#
			print(resample1.max)#
			print(resample3.max)#
		#	print(recluster1[recluster1$cluster.stat == max(recluster1$cluster.stat),]$start)#
		#	print(recluster3[recluster3$cluster.stat == max(recluster3$cluster.stat),]$start )#
			resample1.large.cluster[i] = ifelse(resample1.max>0,resample1.max,0)#
			resample2.large.cluster[i] = ifelse(resample2.max>0,resample2.max,0)#
			print(resample3.max)#
			resample3.large.cluster[i] = ifelse(resample3.max>0,resample3.max,0)#
			resample4.large.cluster[i] = ifelse(resample4.max>0,resample3.max,0)#
			resample5.large.cluster[i] = ifelse(resample5.max>0,resample3.max,0)#
			resample6.large.cluster[i] = ifelse(resample6.max>0,resample3.max,0)#
			resample7.large.cluster[i] = ifelse(resample7.max>0,resample3.max,0)#
#
			}#
#
			sample.cluster1 = pval(sample.cluster1,resample1.large.cluster)#
			sample.cluster2 = pval(sample.cluster2,resample2.large.cluster)#
			sample.cluster3 = pval(sample.cluster3,resample3.large.cluster)#
			sample.cluster4 = pval(sample.cluster4,resample4.large.cluster)#
			sample.cluster5 = pval(sample.cluster5,resample5.large.cluster)#
			sample.cluster6 = pval(sample.cluster6,resample6.large.cluster)#
			sample.cluster7 = pval(sample.cluster7,resample7.large.cluster)
sample.cluster7
sample.cluster4
Data Analysis Scripts#
#
# Function to shuffle condition labels assuming that we hold groups of trials constant. i.e., does the same as shuffling averaged data.#
			# Function to shuffle the condition label then compute the same stats as above#
			# This does the resampling on your data.#
			resample = function(data_file,StartTime,EndTime,StepSize){#
#
				summaryBy(Trial~Subj+Trial+Cond+Strength+Pop, data = data_file ) -> Trials#
				shuf.fnc <- function(x){#
				NewCond <- x$Cond[sample.int(length(x$Cond))]#
				NewStrength <- x$Strength[sample.int(length(x$Strength))]#
				return(data.frame(x,NewCond,NewStrength))#
					}#
				Trials = ddply(Trials, .(Subj), shuf.fnc)#
				for (i in unique(data_file$Subj)){#
					data_file_S = data_file[data_file$Subj == i,]#
                                        data_file_S.prac = data_file_S#
					for (j in unique(data_file_S.prac$Trial)){#
                                           data_file_S[ data_file_S.prac$Trial == j,]$Cond =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewCond),length(data_file_S[ data_file_S.prac$Trial == j,]$Cond))#
                                          data_file_S[ data_file_S.prac$Trial == j,]$Strength =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewStrength),length(data_file_S[ data_file_S.prac$Trial == j,]$Strength))#
                                        }#
					data_file[data_file$Subj == i,] = data_file_S#
                                      }#
                                Trials <- summaryBy(Subj~Subj+Pop, data = Trials)#
                                Trials$Order = NA#
                                Trials$Order = sample.int(length(Trials$Order),length(Trials$Order))#
                                Trials$Pop = Trials[order(Trials$Order),]$Pop#
                                #print(Trials$Pop)#
#
                                for (i in unique(data_file$Subj)){ #
                                data_file[data_file$Subj == i,]$Pop = Trials[Trials$Subj == i,]$Pop#
                              }#
				data_file$Cond = as.factor(data_file$Cond)#
				data_file$Strength = as.factor(data_file$Strength)#
                                data_file$Pop = as.factor(data_file$Pop)#
				contrasts(data_file$Cond)[1] <- -1#
				contrasts(data_file$Cond)[2] <- 1#
				contrasts(data_file$Strength)[2] <- 1#
				contrasts(data_file$Strength)[1] <- -1#
				contrasts(data_file$Pop)[2] <- 1#
				contrasts(data_file$Pop)[1] <- -1#
			#	print(data_file[data_file$Subj == i,]$Pop[1:30])#
                        #       print(data_file[data_file$Subj == i,]$Trial[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Cond[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Strength[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Score[seq(300,1000, by = 25)])#
				stats.resample = calculate.statistics(data_file,StartTime,EndTime,StepSize)#
				return(stats.resample)#
				}#
# Cluster finding function and pval finding function#
			# Cluster finding script (written by Jon Brennan )#
			find.clusters <- function(pval.vector, tval.vector, latencies, alpha=.05, cluster.size=5,signed =FALSE, sign = "pos") {#
				binary.stat <- as.numeric(pval.vector < alpha)#
				tval.stat <- rep(0,length(binary.stat))#
				tval.stat[2:length(binary.stat)] = ((tval.vector[2:length(binary.stat)] * tval.vector[1:(length(binary.stat)-1)]) <0)#
				cluster.start <- c()#
				cluster.end <- c()#
				cluster.stat <- c()#
				in.cluster <- 0#
				found.clusters <- 0#
				new.end <- 0#
				new.start <- 0#
				end.cluster <- 0#
				for (n in 1:length(binary.stat)) {#
					if (signed == FALSE){#
						if (in.cluster == 0 && binary.stat[n] == 1 ) {#
							new.start = n#
							in.cluster = 1#
							}#
					}else#
					if (sign == "pos"){#
						if (in.cluster == 0 && binary.stat[n] == 1 && tval.vector[n] >= 0) {#
							new.start = n#
							in.cluster = 1#
							}#
					}else#
						if (in.cluster == 0 && binary.stat[n] == 1 && tval.vector[n] <= 0) {#
							new.start = n#
							in.cluster = 1#
								}#
					if (in.cluster == 1 && binary.stat[n] == 0) {#
						new.end = n#
						end.cluster = 1#
						in.cluster = 0			#
						}#
					if (in.cluster == 1 && tval.stat[n] == 1) {#
						new.end = n#
						end.cluster = 1#
						in.cluster = 0			#
						}				#
					# in case we reach the end and we are still "in" a cluster...#
					if (in.cluster == 1 && binary.stat[n] == 1 && n == length(binary.stat)) {#
						new.end = n#
						end.cluster = 1#
						in.cluster = 1#
						}		#
					if (end.cluster) {	#
						if ((new.end - new.start) >= cluster.size) {#
							found.clusters <- found.clusters + 1#
							cluster.start<- c(cluster.start, latencies[new.start])#
							cluster.end <- c(cluster.end, latencies[new.end])#
							cluster.stat <- c(cluster.stat, sum(abs(tval.vector[new.start:(new.end-1)])))#
							}#
						end.cluster = 0#
						}#
					}#
				cluster.out <- data.frame(start = cluster.start, end = cluster.end, cluster.stat = cluster.stat)#
				return(cluster.out)	#
				}#
			# Script for assigning pvals to clusters	#
			pval = function(sample.cluster,resample.large.cluster){#
			sample.cluster$pval = 1#
			for (i in 1:length(sample.cluster$cluster.stat)){#
				print(i)#
				sample.cluster$pval[i] = 1 - sum(as.numeric(sample.cluster$cluster.stat[i]>resample.large.cluster)/Resamples_N)#
					}#
					return(sample.cluster)#
			}#
# What analysis will we be doing at each time point?#
#
			calculate.statistics = function(data_file,StartTime,EndTime,StepSize){#
			#Load the relevant libraries#
			require("lme4") #
			require(multicore)#
			require(doMC)#
			require(foreach)#
			require(plyr)#
			#Start the multicore machine!#
#
			#Split the data frame into a list for each timepoint#
			a = split(data_file[data_file$Time >= StartTime & data_file$Time <= EndTime,],data_file[data_file$Time >= StartTime & data_file$Time <= EndTime,]$Time)#
			#Parallel application of lmer and coefficient extraction, outputs another list as above#
			mclapply(a,function(x) coef(summary(lmer(Score~Cond*Strength*Pop +(1+Cond+Strength|Subj) , data = x, family = "binomial")))[2:8,1:3]) -> a.co#
			# Evaluate the list to see whether t value meets a threshold (hard coded)#
			lapply(a.co,function(x) data.frame(x,pv = ifelse(abs(x[,3]) > 1.6,0.04,0.06), co = rownames(x))) -> k#
			# plyr that list into a dataframe#
			k.df = ldply(k)#
			k.df$.id = as.numeric(k.df$.id)#
			colnames(k.df) <- c("Time", "Estimate","SE", "Stat", "pval","Coef")#
			k.df$Coef = ordered(k.df$Coef,levels = c("CondU","Strengthweak","PopControl","CondU:Strengthweak","CondU:PopControl","Strengthweak:PopControl", "CondU:Strengthweak:PopControl"))#
			#Split that dataframe into a list based on the regression coefficients#
			stats.sample = split(k.df,k.df$Coef)#
			return(stats.sample)#
			}#
# What analysis will we be doing at each time point?#
#
			calculate.statistics.nopop = function(data_file,StartTime,EndTime,StepSize){#
			require("lme4") #
			require(multicore)#
			require(doMC)#
			require(foreach)#
			require(plyr)			#
			a = split(data_file[data_file$Time >= StartTime & data_file$Time <= EndTime,],data_file[data_file$Time >= 0 & data_file$Time <= 1500,]$Time)#
			mclapply(a,function(x) coef(summary(lmer(Score~Cond*Strength +(1+Cond+Strength|Subj) + (1+Cond+Strength|Trial), data = x)))[2:4,1:3]) -> a.co#
			lapply(a.co,function(x) data.frame(x,pv = ifelse(abs(x[,3]) > 1.6,0.04,0.06), co = rownames(x))) -> k#
			k.df = ldply(k)#
			k.df$.id = as.numeric(k.df$.id)#
			colnames(k.df) <- c("Time", "Estimate","SE", "Stat", "pval","Coef")#
			k.df$Coef = ordered(k.df$Coef,levels = c("CondU","Strengthweak","CondU:Strengthweak"))#
			stats.sample = split(k.df,k.df$Coef)#
			return(stats.sample)#
			}#
pval = function(sample.cluster,resample.large.cluster){#
			sample.cluster$pval = 1#
			for (i in 1:length(sample.cluster$cluster.stat)){#
				print(i)#
				sample.cluster$pval[i] = 1 - sum(as.numeric(sample.cluster$cluster.stat[i]>resample.large.cluster)/Resamples_N)#
					}#
					return(sample.cluster)#
			}#
#
# Data Analysis Scripts#
#
# Function to shuffle condition labels assuming that we hold groups of trials constant. i.e., does the same as shuffling averaged data.#
			# Function to shuffle the condition label then compute the same stats as above#
			# This does the resampling on your data.#
			resample.nopop = function(data_file,StartTime,EndTime,StepSize){#
				summaryBy(Trial~Subj+Trial+Cond+Strength+Pop, data = data_file ) -> Trials#
				Trials$Order = NA#
                                Trials$NewCond = Trials$Cond#
                                Trials$NewStrength = Trials$Strength#
                                Trials$NewPop = Trials$Pop#
			for (i in unique(Trials$Subj)){#
				Trials[Trials$Subj == i,]$Order = sample.int(length(Trials[Trials$Subj == i,]$Cond),length(Trials[Trials$Subj == i,]$Cond))	#
				Trials[Trials$Subj == i,]$NewCond = Trials[ order(Trials[Trials$Subj == i,]$Order),]$Cond#
                                #Trials[Trials$Subj == i,]$NewOrder = sample.int(length(Trials[Trials$Subj == i,]$Cond),length(Trials[Trials$Subj == i,]$Cond))	#
				Trials[Trials$Subj == i,]$NewStrength = Trials[ order(Trials[Trials$Subj == i,]$Order),]$Strength                                #
			}#
				for (i in unique(data_file$Subj)){#
					data_file_S = data_file[data_file$Subj == i,]#
                                        data_file_S.prac = data_file_S#
					for (j in unique(data_file_S.prac$Trial)){#
                                           data_file_S[ data_file_S.prac$Trial == j,]$Cond =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewCond),length(data_file_S[ data_file_S.prac$Trial == j,]$Cond))#
                                          data_file_S[ data_file_S.prac$Trial == j,]$Strength =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewStrength),length(data_file_S[ data_file_S.prac$Trial == j,]$Strength))#
                                        }#
					data_file[data_file$Subj == i,] = data_file_S#
                                      }#
                                Trials <- summaryBy(Subj~Subj+Pop, data = Trials)#
                                Trials$Order = NA#
                                Trials$Order = sample.int(length(Trials$Order),length(Trials$Order))#
                                Trials$Pop = Trials[order(Trials$Order),]$Pop#
                                #print(Trials$Pop)#
#
                                for (i in unique(data_file$Subj)){ #
                                data_file[data_file$Subj == i,]$Pop = Trials[Trials$Subj == i,]$Pop#
                              }#
				data_file$Cond = as.factor(data_file$Cond)#
				data_file$Strength = as.factor(data_file$Strength)#
                                data_file$Pop = as.factor(data_file$Pop)#
				contrasts(data_file$Cond)[1] <- -1#
				contrasts(data_file$Cond)[2] <- 1#
				contrasts(data_file$Strength)[2] <- 1#
				contrasts(data_file$Strength)[1] <- -1#
				#contrasts(data_file$Pop)[2] <- 1#
				#contrasts(data_file$Pop)[1] <- -1#
			#	print(data_file[data_file$Subj == i,]$Pop[1:30])#
                        #       print(data_file[data_file$Subj == i,]$Trial[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Cond[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Strength[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Score[seq(300,1000, by = 25)])#
				stats.resample = calculate.statistics.nopop(data_file,StartTime,EndTime,StepSize)#
				return(stats.resample)#
				}
Resamples_N = 25 # Number of samples (it will take a long time to do 1000, so set this to 10 your first time to make sure the script works)#
			resample1.large.cluster = rep(NA,Resamples_N) #Preallocate your resample datafile #
			resample2.large.cluster = rep(NA,Resamples_N) #Preallocate your resample datafile #
			resample3.large.cluster = rep(NA,Resamples_N) #Preallocate your resample datafile #
			resample4.large.cluster = rep(NA,Resamples_N) #Preallocate your resample datafile #
			resample5.large.cluster = rep(NA,Resamples_N) #Preallocate your resample datafile #
			resample6.large.cluster = rep(NA,Resamples_N) #Preallocate your resample datafile #
			resample7.large.cluster = rep(NA,Resamples_N) #Preallocate your resample datafile #
			for (i in 1:Resamples_N){#
				print(i)#
			stats.resample = resample(ET,StartTime,EndTime,StepSize)#
			recluster1 = find.clusters(stats.resample[[1]]$pval,stats.resample[[1]]$Stat,stats.resample[[1]]$Time,cluster.size = 1)#
			recluster2 = find.clusters(stats.resample[[2]]$pval,stats.resample[[2]]$Stat,stats.resample[[2]]$Time,cluster.size = 1)#
			recluster3 = find.clusters(stats.resample[[3]]$pval,stats.resample[[3]]$Stat,stats.resample[[3]]$Time,cluster.size = 1)#
			recluster4 = find.clusters(stats.resample[[4]]$pval,stats.resample[[4]]$Stat,stats.resample[[4]]$Time,cluster.size = 1)#
			recluster5 = find.clusters(stats.resample[[5]]$pval,stats.resample[[5]]$Stat,stats.resample[[5]]$Time,cluster.size = 1)#
			recluster6 = find.clusters(stats.resample[[6]]$pval,stats.resample[[6]]$Stat,stats.resample[[6]]$Time,cluster.size = 1)#
			recluster7 = find.clusters(stats.resample[[7]]$pval,stats.resample[[7]]$Stat,stats.resample[[7]]$Time,cluster.size = 1)#
			resample1.max = ifelse(is.numeric(recluster1$cluster.stat),max(recluster1$cluster.stat),0)#
			resample2.max = ifelse(is.numeric(recluster2$cluster.stat),max(recluster2$cluster.stat),0)#
			resample3.max = ifelse(is.numeric(recluster3$cluster.stat),max(recluster3$cluster.stat),0)#
			resample4.max = ifelse(is.numeric(recluster4$cluster.stat),max(recluster4$cluster.stat),0)#
			resample5.max = ifelse(is.numeric(recluster5$cluster.stat),max(recluster5$cluster.stat),0)#
			resample6.max = ifelse(is.numeric(recluster6$cluster.stat),max(recluster6$cluster.stat),0)#
			resample7.max = ifelse(is.numeric(recluster7$cluster.stat),max(recluster7$cluster.stat),0)#
			 #Find the largest cluster (this is what you will be comparing against - is your cluster > 95% of largest clusters)#
			print(resample1.max)#
			print(resample3.max)#
		#	print(recluster1[recluster1$cluster.stat == max(recluster1$cluster.stat),]$start)#
		#	print(recluster3[recluster3$cluster.stat == max(recluster3$cluster.stat),]$start )#
			resample1.large.cluster[i] = ifelse(resample1.max>0,resample1.max,0)#
			resample2.large.cluster[i] = ifelse(resample2.max>0,resample2.max,0)#
			print(resample3.max)#
			resample3.large.cluster[i] = ifelse(resample3.max>0,resample3.max,0)#
			resample4.large.cluster[i] = ifelse(resample4.max>0,resample3.max,0)#
			resample5.large.cluster[i] = ifelse(resample5.max>0,resample3.max,0)#
			resample6.large.cluster[i] = ifelse(resample6.max>0,resample3.max,0)#
			resample7.large.cluster[i] = ifelse(resample7.max>0,resample3.max,0)#
#
			}#
#
			sample.cluster1 = pval(sample.cluster1,resample1.large.cluster)#
			sample.cluster2 = pval(sample.cluster2,resample2.large.cluster)#
			sample.cluster3 = pval(sample.cluster3,resample3.large.cluster)#
			sample.cluster4 = pval(sample.cluster4,resample4.large.cluster)#
			sample.cluster5 = pval(sample.cluster5,resample5.large.cluster)#
			sample.cluster6 = pval(sample.cluster6,resample6.large.cluster)#
			sample.cluster7 = pval(sample.cluster7,resample7.large.cluster)
sample.cluster1
sample.cluster4
StartTime = 0#
			EndTime = 1500#
			StepSize = 100#
			# Get the relevant stats for your data file.#
			registerDoMC();#
#
			stats.sample = calculate.statistics(ET,StartTime,EndTime,StepSize)#
			sample.cluster1 = find.clusters(stats.sample[[1]]$pval,stats.sample[[1]]$Stat,stats.sample[[1]]$Time,cluster.size = 1)#
			sample.cluster2 = find.clusters(stats.sample[[2]]$pval,stats.sample[[2]]$Stat,stats.sample[[2]]$Time,cluster.size = 1)#
			sample.cluster3 = find.clusters(stats.sample[[3]]$pval,stats.sample[[3]]$Stat,stats.sample[[3]]$Time,cluster.size = 1)#
			sample.cluster4 = find.clusters(stats.sample[[4]]$pval,stats.sample[[4]]$Stat,stats.sample[[4]]$Time,cluster.size = 1)#
			sample.cluster5 = find.clusters(stats.sample[[5]]$pval,stats.sample[[5]]$Stat,stats.sample[[5]]$Time,cluster.size = 1)#
			sample.cluster6 = find.clusters(stats.sample[[6]]$pval,stats.sample[[6]]$Stat,stats.sample[[6]]$Time,cluster.size = 1)#
			sample.cluster7 = find.clusters(stats.sample[[7]]$pval,stats.sample[[7]]$Stat,stats.sample[[7]]$Time,cluster.size = 1)
summary(ET)
ET$Score <- ifelse(ET$Score <= -3.66, 0,1)
StartTime = 0#
			EndTime = 1500#
			StepSize = 100#
			# Get the relevant stats for your data file.#
			registerDoMC();#
#
			stats.sample = calculate.statistics(ET,StartTime,EndTime,StepSize)#
			sample.cluster1 = find.clusters(stats.sample[[1]]$pval,stats.sample[[1]]$Stat,stats.sample[[1]]$Time,cluster.size = 1)#
			sample.cluster2 = find.clusters(stats.sample[[2]]$pval,stats.sample[[2]]$Stat,stats.sample[[2]]$Time,cluster.size = 1)#
			sample.cluster3 = find.clusters(stats.sample[[3]]$pval,stats.sample[[3]]$Stat,stats.sample[[3]]$Time,cluster.size = 1)#
			sample.cluster4 = find.clusters(stats.sample[[4]]$pval,stats.sample[[4]]$Stat,stats.sample[[4]]$Time,cluster.size = 1)#
			sample.cluster5 = find.clusters(stats.sample[[5]]$pval,stats.sample[[5]]$Stat,stats.sample[[5]]$Time,cluster.size = 1)#
			sample.cluster6 = find.clusters(stats.sample[[6]]$pval,stats.sample[[6]]$Stat,stats.sample[[6]]$Time,cluster.size = 1)#
			sample.cluster7 = find.clusters(stats.sample[[7]]$pval,stats.sample[[7]]$Stat,stats.sample[[7]]$Time,cluster.size = 1)
warnings()
summary(ET)
summary(lmer(Score~Cond*Strength*Pop +(1+Cond+Strength|Subj) , data = subset(ET, Time == 900), family = "binomial"))
summary(lmer(Score~Cond*Strength*Pop +(1+Cond+Strength|Subj) , data = subset(ET, Time == 100), family = "binomial"))
summary(lmer(Score~Cond*Strength*Pop +(1+Cond+Strength|Subj) , data = subset(ET, Time == 200), family = "binomial"))
summary(lmer(Score~Cond*Strength*Pop +(1+Cond+Strength|Subj) , data = subset(ET, Time == 1400), family = "binomial"))
summary(glmer(Score~Cond*Strength*Pop +(1+Cond+Strength|Subj) , data = subset(ET, Time == 1400), family = "binomial"))
Data Analysis Scripts#
#
# Function to shuffle condition labels assuming that we hold groups of trials constant. i.e., does the same as shuffling averaged data.#
			# Function to shuffle the condition label then compute the same stats as above#
			# This does the resampling on your data.#
			resample = function(data_file,StartTime,EndTime,StepSize){#
#
				summaryBy(Trial~Subj+Trial+Cond+Strength+Pop, data = data_file ) -> Trials#
				shuf.fnc <- function(x){#
				NewCond <- x$Cond[sample.int(length(x$Cond))]#
				NewStrength <- x$Strength[sample.int(length(x$Strength))]#
				return(data.frame(x,NewCond,NewStrength))#
					}#
				Trials = ddply(Trials, .(Subj), shuf.fnc)#
				for (i in unique(data_file$Subj)){#
					data_file_S = data_file[data_file$Subj == i,]#
                                        data_file_S.prac = data_file_S#
					for (j in unique(data_file_S.prac$Trial)){#
                                           data_file_S[ data_file_S.prac$Trial == j,]$Cond =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewCond),length(data_file_S[ data_file_S.prac$Trial == j,]$Cond))#
                                          data_file_S[ data_file_S.prac$Trial == j,]$Strength =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewStrength),length(data_file_S[ data_file_S.prac$Trial == j,]$Strength))#
                                        }#
					data_file[data_file$Subj == i,] = data_file_S#
                                      }#
                                Trials <- summaryBy(Subj~Subj+Pop, data = Trials)#
                                Trials$Order = NA#
                                Trials$Order = sample.int(length(Trials$Order),length(Trials$Order))#
                                Trials$Pop = Trials[order(Trials$Order),]$Pop#
                                #print(Trials$Pop)#
#
                                for (i in unique(data_file$Subj)){ #
                                data_file[data_file$Subj == i,]$Pop = Trials[Trials$Subj == i,]$Pop#
                              }#
				data_file$Cond = as.factor(data_file$Cond)#
				data_file$Strength = as.factor(data_file$Strength)#
                                data_file$Pop = as.factor(data_file$Pop)#
				contrasts(data_file$Cond)[1] <- -1#
				contrasts(data_file$Cond)[2] <- 1#
				contrasts(data_file$Strength)[2] <- 1#
				contrasts(data_file$Strength)[1] <- -1#
				contrasts(data_file$Pop)[2] <- 1#
				contrasts(data_file$Pop)[1] <- -1#
			#	print(data_file[data_file$Subj == i,]$Pop[1:30])#
                        #       print(data_file[data_file$Subj == i,]$Trial[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Cond[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Strength[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Score[seq(300,1000, by = 25)])#
				stats.resample = calculate.statistics(data_file,StartTime,EndTime,StepSize)#
				return(stats.resample)#
				}#
# Cluster finding function and pval finding function#
			# Cluster finding script (written by Jon Brennan )#
			find.clusters <- function(pval.vector, tval.vector, latencies, alpha=.05, cluster.size=5,signed =FALSE, sign = "pos") {#
				binary.stat <- as.numeric(pval.vector < alpha)#
				tval.stat <- rep(0,length(binary.stat))#
				tval.stat[2:length(binary.stat)] = ((tval.vector[2:length(binary.stat)] * tval.vector[1:(length(binary.stat)-1)]) <0)#
				cluster.start <- c()#
				cluster.end <- c()#
				cluster.stat <- c()#
				in.cluster <- 0#
				found.clusters <- 0#
				new.end <- 0#
				new.start <- 0#
				end.cluster <- 0#
				for (n in 1:length(binary.stat)) {#
					if (signed == FALSE){#
						if (in.cluster == 0 && binary.stat[n] == 1 ) {#
							new.start = n#
							in.cluster = 1#
							}#
					}else#
					if (sign == "pos"){#
						if (in.cluster == 0 && binary.stat[n] == 1 && tval.vector[n] >= 0) {#
							new.start = n#
							in.cluster = 1#
							}#
					}else#
						if (in.cluster == 0 && binary.stat[n] == 1 && tval.vector[n] <= 0) {#
							new.start = n#
							in.cluster = 1#
								}#
					if (in.cluster == 1 && binary.stat[n] == 0) {#
						new.end = n#
						end.cluster = 1#
						in.cluster = 0			#
						}#
					if (in.cluster == 1 && tval.stat[n] == 1) {#
						new.end = n#
						end.cluster = 1#
						in.cluster = 0			#
						}				#
					# in case we reach the end and we are still "in" a cluster...#
					if (in.cluster == 1 && binary.stat[n] == 1 && n == length(binary.stat)) {#
						new.end = n#
						end.cluster = 1#
						in.cluster = 1#
						}		#
					if (end.cluster) {	#
						if ((new.end - new.start) >= cluster.size) {#
							found.clusters <- found.clusters + 1#
							cluster.start<- c(cluster.start, latencies[new.start])#
							cluster.end <- c(cluster.end, latencies[new.end])#
							cluster.stat <- c(cluster.stat, sum(abs(tval.vector[new.start:(new.end-1)])))#
							}#
						end.cluster = 0#
						}#
					}#
				cluster.out <- data.frame(start = cluster.start, end = cluster.end, cluster.stat = cluster.stat)#
				return(cluster.out)	#
				}#
			# Script for assigning pvals to clusters	#
			pval = function(sample.cluster,resample.large.cluster){#
			sample.cluster$pval = 1#
			for (i in 1:length(sample.cluster$cluster.stat)){#
				print(i)#
				sample.cluster$pval[i] = 1 - sum(as.numeric(sample.cluster$cluster.stat[i]>resample.large.cluster)/Resamples_N)#
					}#
					return(sample.cluster)#
			}#
# What analysis will we be doing at each time point?#
#
			calculate.statistics = function(data_file,StartTime,EndTime,StepSize){#
			#Load the relevant libraries#
			require("lme4") #
			require(multicore)#
			require(doMC)#
			require(foreach)#
			require(plyr)#
			#Start the multicore machine!#
#
			#Split the data frame into a list for each timepoint#
			a = split(data_file[data_file$Time >= StartTime & data_file$Time <= EndTime,],data_file[data_file$Time >= StartTime & data_file$Time <= EndTime,]$Time)#
			#Parallel application of lmer and coefficient extraction, outputs another list as above#
			mclapply(a,function(x) coef(summary(glmer(Score~Cond*Strength*Pop +(1+Cond+Strength|Subj) , data = x, family = "binomial")))[2:8,1:3]) -> a.co#
			# Evaluate the list to see whether t value meets a threshold (hard coded)#
			lapply(a.co,function(x) data.frame(x,pv = ifelse(abs(x[,3]) > 1.6,0.04,0.06), co = rownames(x))) -> k#
			# plyr that list into a dataframe#
			k.df = ldply(k)#
			k.df$.id = as.numeric(k.df$.id)#
			colnames(k.df) <- c("Time", "Estimate","SE", "Stat", "pval","Coef")#
			k.df$Coef = ordered(k.df$Coef,levels = c("CondU","Strengthweak","PopControl","CondU:Strengthweak","CondU:PopControl","Strengthweak:PopControl", "CondU:Strengthweak:PopControl"))#
			#Split that dataframe into a list based on the regression coefficients#
			stats.sample = split(k.df,k.df$Coef)#
			return(stats.sample)#
			}#
# What analysis will we be doing at each time point?#
#
			calculate.statistics.nopop = function(data_file,StartTime,EndTime,StepSize){#
			require("lme4") #
			require(multicore)#
			require(doMC)#
			require(foreach)#
			require(plyr)			#
			a = split(data_file[data_file$Time >= StartTime & data_file$Time <= EndTime,],data_file[data_file$Time >= 0 & data_file$Time <= 1500,]$Time)#
			mclapply(a,function(x) coef(summary(lmer(Score~Cond*Strength +(1+Cond+Strength|Subj) + (1+Cond+Strength|Trial), data = x)))[2:4,1:3]) -> a.co#
			lapply(a.co,function(x) data.frame(x,pv = ifelse(abs(x[,3]) > 1.6,0.04,0.06), co = rownames(x))) -> k#
			k.df = ldply(k)#
			k.df$.id = as.numeric(k.df$.id)#
			colnames(k.df) <- c("Time", "Estimate","SE", "Stat", "pval","Coef")#
			k.df$Coef = ordered(k.df$Coef,levels = c("CondU","Strengthweak","CondU:Strengthweak"))#
			stats.sample = split(k.df,k.df$Coef)#
			return(stats.sample)#
			}#
pval = function(sample.cluster,resample.large.cluster){#
			sample.cluster$pval = 1#
			for (i in 1:length(sample.cluster$cluster.stat)){#
				print(i)#
				sample.cluster$pval[i] = 1 - sum(as.numeric(sample.cluster$cluster.stat[i]>resample.large.cluster)/Resamples_N)#
					}#
					return(sample.cluster)#
			}#
#
# Data Analysis Scripts#
#
# Function to shuffle condition labels assuming that we hold groups of trials constant. i.e., does the same as shuffling averaged data.#
			# Function to shuffle the condition label then compute the same stats as above#
			# This does the resampling on your data.#
			resample.nopop = function(data_file,StartTime,EndTime,StepSize){#
				summaryBy(Trial~Subj+Trial+Cond+Strength+Pop, data = data_file ) -> Trials#
				Trials$Order = NA#
                                Trials$NewCond = Trials$Cond#
                                Trials$NewStrength = Trials$Strength#
                                Trials$NewPop = Trials$Pop#
			for (i in unique(Trials$Subj)){#
				Trials[Trials$Subj == i,]$Order = sample.int(length(Trials[Trials$Subj == i,]$Cond),length(Trials[Trials$Subj == i,]$Cond))	#
				Trials[Trials$Subj == i,]$NewCond = Trials[ order(Trials[Trials$Subj == i,]$Order),]$Cond#
                                #Trials[Trials$Subj == i,]$NewOrder = sample.int(length(Trials[Trials$Subj == i,]$Cond),length(Trials[Trials$Subj == i,]$Cond))	#
				Trials[Trials$Subj == i,]$NewStrength = Trials[ order(Trials[Trials$Subj == i,]$Order),]$Strength                                #
			}#
				for (i in unique(data_file$Subj)){#
					data_file_S = data_file[data_file$Subj == i,]#
                                        data_file_S.prac = data_file_S#
					for (j in unique(data_file_S.prac$Trial)){#
                                           data_file_S[ data_file_S.prac$Trial == j,]$Cond =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewCond),length(data_file_S[ data_file_S.prac$Trial == j,]$Cond))#
                                          data_file_S[ data_file_S.prac$Trial == j,]$Strength =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewStrength),length(data_file_S[ data_file_S.prac$Trial == j,]$Strength))#
                                        }#
					data_file[data_file$Subj == i,] = data_file_S#
                                      }#
                                Trials <- summaryBy(Subj~Subj+Pop, data = Trials)#
                                Trials$Order = NA#
                                Trials$Order = sample.int(length(Trials$Order),length(Trials$Order))#
                                Trials$Pop = Trials[order(Trials$Order),]$Pop#
                                #print(Trials$Pop)#
#
                                for (i in unique(data_file$Subj)){ #
                                data_file[data_file$Subj == i,]$Pop = Trials[Trials$Subj == i,]$Pop#
                              }#
				data_file$Cond = as.factor(data_file$Cond)#
				data_file$Strength = as.factor(data_file$Strength)#
                                data_file$Pop = as.factor(data_file$Pop)#
				contrasts(data_file$Cond)[1] <- -1#
				contrasts(data_file$Cond)[2] <- 1#
				contrasts(data_file$Strength)[2] <- 1#
				contrasts(data_file$Strength)[1] <- -1#
				#contrasts(data_file$Pop)[2] <- 1#
				#contrasts(data_file$Pop)[1] <- -1#
			#	print(data_file[data_file$Subj == i,]$Pop[1:30])#
                        #       print(data_file[data_file$Subj == i,]$Trial[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Cond[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Strength[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Score[seq(300,1000, by = 25)])#
				stats.resample = calculate.statistics.nopop(data_file,StartTime,EndTime,StepSize)#
				return(stats.resample)#
				}
StartTime = 0#
			EndTime = 1500#
			StepSize = 100#
			# Get the relevant stats for your data file.#
			registerDoMC();#
#
			stats.sample = calculate.statistics(ET,StartTime,EndTime,StepSize)#
			sample.cluster1 = find.clusters(stats.sample[[1]]$pval,stats.sample[[1]]$Stat,stats.sample[[1]]$Time,cluster.size = 1)#
			sample.cluster2 = find.clusters(stats.sample[[2]]$pval,stats.sample[[2]]$Stat,stats.sample[[2]]$Time,cluster.size = 1)#
			sample.cluster3 = find.clusters(stats.sample[[3]]$pval,stats.sample[[3]]$Stat,stats.sample[[3]]$Time,cluster.size = 1)#
			sample.cluster4 = find.clusters(stats.sample[[4]]$pval,stats.sample[[4]]$Stat,stats.sample[[4]]$Time,cluster.size = 1)#
			sample.cluster5 = find.clusters(stats.sample[[5]]$pval,stats.sample[[5]]$Stat,stats.sample[[5]]$Time,cluster.size = 1)#
			sample.cluster6 = find.clusters(stats.sample[[6]]$pval,stats.sample[[6]]$Stat,stats.sample[[6]]$Time,cluster.size = 1)#
			sample.cluster7 = find.clusters(stats.sample[[7]]$pval,stats.sample[[7]]$Stat,stats.sample[[7]]$Time,cluster.size = 1)
sample.cluster1 = pval(sample.cluster1,resample1.large.cluster)#
			sample.cluster2 = pval(sample.cluster2,resample2.large.cluster)#
			sample.cluster3 = pval(sample.cluster3,resample3.large.cluster)#
			sample.cluster4 = pval(sample.cluster4,resample4.large.cluster)#
			sample.cluster5 = pval(sample.cluster5,resample5.large.cluster)#
			sample.cluster6 = pval(sample.cluster6,resample6.large.cluster)#
			sample.cluster7 = pval(sample.cluster7,resample7.large.cluster)
sample.cluster1
sample.cluster3
sample.cluster4
Data Analysis Scripts#
#
# Function to shuffle condition labels assuming that we hold groups of trials constant. i.e., does the same as shuffling averaged data.#
			# Function to shuffle the condition label then compute the same stats as above#
			# This does the resampling on your data.#
			resample = function(data_file,StartTime,EndTime,StepSize){#
#
				summaryBy(Trial~Subj+Trial+Cond+Strength+Pop, data = data_file ) -> Trials#
				shuf.fnc <- function(x){#
				NewCond <- x$Cond[sample.int(length(x$Cond))]#
				NewStrength <- x$Strength[sample.int(length(x$Strength))]#
				return(data.frame(x,NewCond,NewStrength))#
					}#
				Trials = ddply(Trials, .(Subj), shuf.fnc)#
				for (i in unique(data_file$Subj)){#
					data_file_S = data_file[data_file$Subj == i,]#
                                        data_file_S.prac = data_file_S#
					for (j in unique(data_file_S.prac$Trial)){#
                                           data_file_S[ data_file_S.prac$Trial == j,]$Cond =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewCond),length(data_file_S[ data_file_S.prac$Trial == j,]$Cond))#
                                          data_file_S[ data_file_S.prac$Trial == j,]$Strength =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewStrength),length(data_file_S[ data_file_S.prac$Trial == j,]$Strength))#
                                        }#
					data_file[data_file$Subj == i,] = data_file_S#
                                      }#
                                Trials <- summaryBy(Subj~Subj+Pop, data = Trials)#
                                Trials$Order = NA#
                                Trials$Order = sample.int(length(Trials$Order),length(Trials$Order))#
                                Trials$Pop = Trials[order(Trials$Order),]$Pop#
                                #print(Trials$Pop)#
#
                                for (i in unique(data_file$Subj)){ #
                                data_file[data_file$Subj == i,]$Pop = Trials[Trials$Subj == i,]$Pop#
                              }#
				data_file$Cond = as.factor(data_file$Cond)#
				data_file$Strength = as.factor(data_file$Strength)#
                                data_file$Pop = as.factor(data_file$Pop)#
				contrasts(data_file$Cond)[1] <- -1#
				contrasts(data_file$Cond)[2] <- 1#
				contrasts(data_file$Strength)[2] <- 1#
				contrasts(data_file$Strength)[1] <- -1#
				contrasts(data_file$Pop)[2] <- 1#
				contrasts(data_file$Pop)[1] <- -1#
			#	print(data_file[data_file$Subj == i,]$Pop[1:30])#
                        #       print(data_file[data_file$Subj == i,]$Trial[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Cond[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Strength[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Score[seq(300,1000, by = 25)])#
				stats.resample = calculate.statistics(data_file,StartTime,EndTime,StepSize)#
				return(stats.resample)#
				}#
# Cluster finding function and pval finding function#
			# Cluster finding script (written by Jon Brennan )#
			find.clusters <- function(pval.vector, tval.vector, latencies, alpha=.05, cluster.size=5,signed =FALSE, sign = "pos") {#
				binary.stat <- as.numeric(pval.vector < alpha)#
				tval.stat <- rep(0,length(binary.stat))#
				tval.stat[2:length(binary.stat)] = ((tval.vector[2:length(binary.stat)] * tval.vector[1:(length(binary.stat)-1)]) <0)#
				cluster.start <- c()#
				cluster.end <- c()#
				cluster.stat <- c()#
				in.cluster <- 0#
				found.clusters <- 0#
				new.end <- 0#
				new.start <- 0#
				end.cluster <- 0#
				for (n in 1:length(binary.stat)) {#
					if (signed == FALSE){#
						if (in.cluster == 0 && binary.stat[n] == 1 ) {#
							new.start = n#
							in.cluster = 1#
							}#
					}else#
					if (sign == "pos"){#
						if (in.cluster == 0 && binary.stat[n] == 1 && tval.vector[n] >= 0) {#
							new.start = n#
							in.cluster = 1#
							}#
					}else#
						if (in.cluster == 0 && binary.stat[n] == 1 && tval.vector[n] <= 0) {#
							new.start = n#
							in.cluster = 1#
								}#
					if (in.cluster == 1 && binary.stat[n] == 0) {#
						new.end = n#
						end.cluster = 1#
						in.cluster = 0			#
						}#
					if (in.cluster == 1 && tval.stat[n] == 1) {#
						new.end = n#
						end.cluster = 1#
						in.cluster = 0			#
						}				#
					# in case we reach the end and we are still "in" a cluster...#
					if (in.cluster == 1 && binary.stat[n] == 1 && n == length(binary.stat)) {#
						new.end = n#
						end.cluster = 1#
						in.cluster = 1#
						}		#
					if (end.cluster) {	#
						if ((new.end - new.start) >= cluster.size) {#
							found.clusters <- found.clusters + 1#
							cluster.start<- c(cluster.start, latencies[new.start])#
							cluster.end <- c(cluster.end, latencies[new.end])#
							cluster.stat <- c(cluster.stat, sum(abs(tval.vector[new.start:(new.end-1)])))#
							}#
						end.cluster = 0#
						}#
					}#
				cluster.out <- data.frame(start = cluster.start, end = cluster.end, cluster.stat = cluster.stat)#
				return(cluster.out)	#
				}#
			# Script for assigning pvals to clusters	#
			pval = function(sample.cluster,resample.large.cluster){#
			sample.cluster$pval = 1#
			for (i in 1:length(sample.cluster$cluster.stat)){#
				print(i)#
				sample.cluster$pval[i] = 1 - sum(as.numeric(sample.cluster$cluster.stat[i]>resample.large.cluster)/Resamples_N)#
					}#
					return(sample.cluster)#
			}#
# What analysis will we be doing at each time point?#
#
			calculate.statistics = function(data_file,StartTime,EndTime,StepSize){#
			#Load the relevant libraries#
			require("lme4") #
			require(multicore)#
			require(doMC)#
			require(foreach)#
			require(plyr)#
			#Start the multicore machine!#
#
			#Split the data frame into a list for each timepoint#
			a = split(data_file[data_file$Time >= StartTime & data_file$Time <= EndTime,],data_file[data_file$Time >= StartTime & data_file$Time <= EndTime,]$Time)#
			#Parallel application of lmer and coefficient extraction, outputs another list as above#
			mclapply(a,function(x) coef(summary(lmer(Score~Cond*Strength*Pop +(1+Cond+Strength|Subj) , data = x)))[2:8,1:3]) -> a.co#
			# Evaluate the list to see whether t value meets a threshold (hard coded)#
			lapply(a.co,function(x) data.frame(x,pv = ifelse(abs(x[,3]) > 1.6,0.04,0.06), co = rownames(x))) -> k#
			# plyr that list into a dataframe#
			k.df = ldply(k)#
			k.df$.id = as.numeric(k.df$.id)#
			colnames(k.df) <- c("Time", "Estimate","SE", "Stat", "pval","Coef")#
			k.df$Coef = ordered(k.df$Coef,levels = c("CondU","Strengthweak","PopControl","CondU:Strengthweak","CondU:PopControl","Strengthweak:PopControl", "CondU:Strengthweak:PopControl"))#
			#Split that dataframe into a list based on the regression coefficients#
			stats.sample = split(k.df,k.df$Coef)#
			return(stats.sample)#
			}#
# What analysis will we be doing at each time point?#
#
			calculate.statistics.nopop = function(data_file,StartTime,EndTime,StepSize){#
			require("lme4") #
			require(multicore)#
			require(doMC)#
			require(foreach)#
			require(plyr)			#
			a = split(data_file[data_file$Time >= StartTime & data_file$Time <= EndTime,],data_file[data_file$Time >= 0 & data_file$Time <= 1500,]$Time)#
			mclapply(a,function(x) coef(summary(lmer(Score~Cond*Strength +(1+Cond+Strength|Subj) + (1+Cond+Strength|Trial), data = x)))[2:4,1:3]) -> a.co#
			lapply(a.co,function(x) data.frame(x,pv = ifelse(abs(x[,3]) > 1.6,0.04,0.06), co = rownames(x))) -> k#
			k.df = ldply(k)#
			k.df$.id = as.numeric(k.df$.id)#
			colnames(k.df) <- c("Time", "Estimate","SE", "Stat", "pval","Coef")#
			k.df$Coef = ordered(k.df$Coef,levels = c("CondU","Strengthweak","CondU:Strengthweak"))#
			stats.sample = split(k.df,k.df$Coef)#
			return(stats.sample)#
			}#
pval = function(sample.cluster,resample.large.cluster){#
			sample.cluster$pval = 1#
			for (i in 1:length(sample.cluster$cluster.stat)){#
				print(i)#
				sample.cluster$pval[i] = 1 - sum(as.numeric(sample.cluster$cluster.stat[i]>resample.large.cluster)/Resamples_N)#
					}#
					return(sample.cluster)#
			}#
#
# Data Analysis Scripts#
#
# Function to shuffle condition labels assuming that we hold groups of trials constant. i.e., does the same as shuffling averaged data.#
			# Function to shuffle the condition label then compute the same stats as above#
			# This does the resampling on your data.#
			resample.nopop = function(data_file,StartTime,EndTime,StepSize){#
				summaryBy(Trial~Subj+Trial+Cond+Strength+Pop, data = data_file ) -> Trials#
				Trials$Order = NA#
                                Trials$NewCond = Trials$Cond#
                                Trials$NewStrength = Trials$Strength#
                                Trials$NewPop = Trials$Pop#
			for (i in unique(Trials$Subj)){#
				Trials[Trials$Subj == i,]$Order = sample.int(length(Trials[Trials$Subj == i,]$Cond),length(Trials[Trials$Subj == i,]$Cond))	#
				Trials[Trials$Subj == i,]$NewCond = Trials[ order(Trials[Trials$Subj == i,]$Order),]$Cond#
                                #Trials[Trials$Subj == i,]$NewOrder = sample.int(length(Trials[Trials$Subj == i,]$Cond),length(Trials[Trials$Subj == i,]$Cond))	#
				Trials[Trials$Subj == i,]$NewStrength = Trials[ order(Trials[Trials$Subj == i,]$Order),]$Strength                                #
			}#
				for (i in unique(data_file$Subj)){#
					data_file_S = data_file[data_file$Subj == i,]#
                                        data_file_S.prac = data_file_S#
					for (j in unique(data_file_S.prac$Trial)){#
                                           data_file_S[ data_file_S.prac$Trial == j,]$Cond =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewCond),length(data_file_S[ data_file_S.prac$Trial == j,]$Cond))#
                                          data_file_S[ data_file_S.prac$Trial == j,]$Strength =  rep(as.character(Trials[Trials$Subj == i & Trials$Trial == j,]$NewStrength),length(data_file_S[ data_file_S.prac$Trial == j,]$Strength))#
                                        }#
					data_file[data_file$Subj == i,] = data_file_S#
                                      }#
                                Trials <- summaryBy(Subj~Subj+Pop, data = Trials)#
                                Trials$Order = NA#
                                Trials$Order = sample.int(length(Trials$Order),length(Trials$Order))#
                                Trials$Pop = Trials[order(Trials$Order),]$Pop#
                                #print(Trials$Pop)#
#
                                for (i in unique(data_file$Subj)){ #
                                data_file[data_file$Subj == i,]$Pop = Trials[Trials$Subj == i,]$Pop#
                              }#
				data_file$Cond = as.factor(data_file$Cond)#
				data_file$Strength = as.factor(data_file$Strength)#
                                data_file$Pop = as.factor(data_file$Pop)#
				contrasts(data_file$Cond)[1] <- -1#
				contrasts(data_file$Cond)[2] <- 1#
				contrasts(data_file$Strength)[2] <- 1#
				contrasts(data_file$Strength)[1] <- -1#
				#contrasts(data_file$Pop)[2] <- 1#
				#contrasts(data_file$Pop)[1] <- -1#
			#	print(data_file[data_file$Subj == i,]$Pop[1:30])#
                        #       print(data_file[data_file$Subj == i,]$Trial[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Cond[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Strength[seq(300,1000, by = 25)])#
                       #        print(data_file[data_file$Subj == i,]$Score[seq(300,1000, by = 25)])#
				stats.resample = calculate.statistics.nopop(data_file,StartTime,EndTime,StepSize)#
				return(stats.resample)#
				}
StartTime = 0#
			EndTime = 1500#
			StepSize = 100#
			# Get the relevant stats for your data file.#
			registerDoMC();#
#
			stats.sample = calculate.statistics(ET,StartTime,EndTime,StepSize)#
			sample.cluster1 = find.clusters(stats.sample[[1]]$pval,stats.sample[[1]]$Stat,stats.sample[[1]]$Time,cluster.size = 1)#
			sample.cluster2 = find.clusters(stats.sample[[2]]$pval,stats.sample[[2]]$Stat,stats.sample[[2]]$Time,cluster.size = 1)#
			sample.cluster3 = find.clusters(stats.sample[[3]]$pval,stats.sample[[3]]$Stat,stats.sample[[3]]$Time,cluster.size = 1)#
			sample.cluster4 = find.clusters(stats.sample[[4]]$pval,stats.sample[[4]]$Stat,stats.sample[[4]]$Time,cluster.size = 1)#
			sample.cluster5 = find.clusters(stats.sample[[5]]$pval,stats.sample[[5]]$Stat,stats.sample[[5]]$Time,cluster.size = 1)#
			sample.cluster6 = find.clusters(stats.sample[[6]]$pval,stats.sample[[6]]$Stat,stats.sample[[6]]$Time,cluster.size = 1)#
			sample.cluster7 = find.clusters(stats.sample[[7]]$pval,stats.sample[[7]]$Stat,stats.sample[[7]]$Time,cluster.size = 1)
sample.cluster4
stats.sample[[4]]
stats.sample[[1]]
dat<- data.frame(t=seq(0, 2*pi, by=0.1) )#
 xhrt <- function(t) 16*sin(t)^3#
 yhrt <- function(t) 13*cos(t)-5*cos(2*t)-2*cos(3*t)-cos(4*t)#
 dat$y=yhrt(dat$t)#
 dat$x=xhrt(dat$t)#
 with(dat, plot(x,y, type="l"))
with(dat, polygon(x,y, col="hotpink"))
points(c(10,-10, -15, 15), c(-10, -10, 10, 10), pch=169, font=5)
#values used for longdiff#
# s_n<-24 #how many subjects#
# switch_baseline<-.25 #probability of switching to target at baseline#
# switch_on<-.5 #probability of switching to target when effect is in effect#
# switch_off<-.1 #probability of switching off target when effect is in effect#
# items_n<-5 #how many items per condition? 2-condition experiment. items appear in both conditions, within subject#
# bins_n<-20 #how many bins?#
# first_bin<-7 #on average, what is the first bin to show an effect in condition with early effect?#
# time_diff<-2.5 #how many bins earlier is there an effect in condition 1 than condition 2?#
# noise<-2 #trial noise sd#
# sub_speeds<-rnorm(s_n,0,1) #how much faster or slower than typical is the subject?#
# sub_s_sd<-1 #sd for sub speed error#
# sub_effects<-rnorm(s_n,0,1.5) #degree to which effect size is larger or smaller for that subject#
# sub_e_sd<-1 #sd for sub effect error#
# item_effects<-rnorm(items_n,0,.5) #degree to which effect size is larger or smaller than typical for that item#
# item_sd<-1 #sd for item effect error#
#
#values used for shortdiff#
s_n<-24 #how many subjects#
switch_baseline<-.25 #probability of switching to target at baseline#
switch_on<-.9 #probability of switching to target when effect is in effect#
switch_off<-.2 #probability of switching off target when effect is in effect#
items_n<-5 #how many items per condition? 2-condition experiment. items appear in both conditions, within subject#
bins_n<-20 #how many bins?#
first_bin<-7 #on average, what is the first bin to show an effect in condition with early effect?#
time_diff<-0 #how many bins earlier is there an effect in condition 1 than condition 2?#
noise<-.25 #trial noise sd#
sub_speeds<-rnorm(s_n,0,.25) #how much faster or slower than typical is the subject?#
sub_s_sd<-.5 #sd for sub speed error#
sub_effects<-rnorm(s_n,0,2) #degree to which effect size is larger or smaller for that subject#
sub_e_sd<-.25 #sd for sub effect error#
item_effects<-rnorm(items_n,0,2) #degree to which effect size is larger or smaller than typical for that item#
item_sd<-.25 #sd for item effect error
#what's alpha?#
1-.95^(1/bins_n)#
#
mydata<-data.frame(subject=c(NA),condition=c(NA),item=c(NA),bin=c(NA),fixtarg=c(NA))#
for (sub in c(1:s_n)){#
	for (item in c(1:items_n)){#
		#do a item for each condition simultaneously (saves time)#
		#draw a bin for an effect#
		con1_bin<-first_bin+rnorm(1,sub_speeds[sub],sub_s_sd)+rnorm(1,0,noise)#
		con2_bin<-first_bin+rnorm(1,sub_speeds[sub],sub_s_sd)+rnorm(1,0,noise)#
			current_1<-rbinom(1,1,.5) #where am I looking in first bin for condition 1?#
			current_2<-rbinom(1,1,.5) #where am I looking in first bin for condition 2?#
			mydata<-rbind(mydata,c(sub,1,item,1,current_1))#
			mydata<-rbind(mydata,c(sub,2,item,1,current_2))#
			for (bin in c(2:bins_n)){#
				if (bin<con1_bin){#
						if (rbinom(1,1,switch_baseline)){current_1<-(1-current_1)}#
					}else{#
						if (current_1){#
							if (rbinom(1,1,switch_off)){current_1<-(1-current_1)}						#
						}else{#
							if (rbinom(1,1,switch_on)){current_1<-(1-current_1)}													#
						}#
				}#
				mydata<-rbind(mydata,c(sub,1,item,bin,current_1))#
				if (bin<con2_bin){#
						if (rbinom(1,1,switch_baseline)){current_2<-(1-current_2)}#
					}else{#
						if (current_2){#
							if (rbinom(1,1,switch_off)){current_2<-(1-current_2)}						#
						}else{#
							if (rbinom(1,1,switch_on)){current_2<-(1-current_2)}													#
						}#
				}#
				mydata<-rbind(mydata,c(sub,2,item,bin,current_2))#
			}#
	}#
}
summary(mydata)
#what's alpha?#
1-.95^(1/bins_n)#
#
mydata<-data.frame(subject=c(NA),condition=c(NA),item=c(NA),bin=c(NA),fixtarg=c(NA))#
for (sub in c(1:s_n)){#
	for (item in c(1:items_n)){#
		#do a item for each condition simultaneously (saves time)#
		#draw a bin for an effect#
		con1_bin<-first_bin+rnorm(1,sub_speeds[sub],sub_s_sd)+rnorm(1,0,noise)#
		con2_bin<-first_bin+rnorm(1,sub_speeds[sub],sub_s_sd)+rnorm(1,0,noise)#
			current_1<-rbinom(1,1,.5) #where am I looking in first bin for condition 1?#
			current_2<-rbinom(1,1,.5) #where am I looking in first bin for condition 2?#
			mydata<-rbind(mydata,c(sub,1,item,1,current_1))#
			mydata<-rbind(mydata,c(sub,2,item,1,current_2))#
			for (bin in c(2:bins_n)){#
				if (bin<con1_bin){#
						if (rbinom(1,1,switch_baseline)){current_1<-(1-current_1)}#
					}else{#
						if (current_1){#
							if (rbinom(1,1,switch_off)){current_1<-(1-current_1)}						#
						}else{#
							if (rbinom(1,1,switch_on)){current_1<-(1-current_1)}													#
						}#
				}#
				mydata<-rbind(mydata,c(sub,1,item,bin,current_1))#
				if (bin<con2_bin){#
						if (rbinom(1,1,switch_baseline)){current_2<-(1-current_2)}#
					}else{#
						if (current_2){#
							if (rbinom(1,1,switch_off)){current_2<-(1-current_2)}						#
						}else{#
							if (rbinom(1,1,switch_on)){current_2<-(1-current_2)}													#
						}#
				}#
				mydata<-rbind(mydata,c(sub,2,item,bin,current_2))#
			}#
	}#
}
summary(mydata)
#what's alpha?#
1-.95^(1/bins_n)#
#
mydata<-data.frame(subject=c(NA),condition=c(NA),item=c(NA),bin=c(NA),fixtarg=c(NA))#
for (sub in c(1:s_n)){#
	for (item in c(1:items_n)){#
		#do a item for each condition simultaneously (saves time)#
		#draw a bin for an effect#
		con1_bin<-first_bin+rnorm(1,sub_speeds[sub],sub_s_sd)+rnorm(1,0,noise)#
		con2_bin<-first_bin+rnorm(1,sub_speeds[sub],sub_s_sd)+rnorm(1,0,noise)#
			current_1<-rbinom(1,1,.5) #where am I looking in first bin for condition 1?#
			current_2<-rbinom(1,1,.5) #where am I looking in first bin for condition 2?#
			mydata<-rbind(mydata,c(sub,1,item,1,current_1))#
			mydata<-rbind(mydata,c(sub,2,item,1,current_2))#
			for (bin in c(2:bins_n)){#
				if (bin<con1_bin){#
						if (rbinom(1,1,switch_baseline)){current_1<-(1-current_1)}#
					}else{#
						if (current_1){#
							if (rbinom(1,1,switch_off)){current_1<-(1-current_1)}						#
						}else{#
							if (rbinom(1,1,switch_on)){current_1<-(1-current_1)}													#
						}#
				}#
				mydata<-rbind(mydata,c(sub,1,item,bin,current_1))#
				if (bin<con2_bin){#
						if (rbinom(1,1,switch_baseline)){current_2<-(1-current_2)}#
					}else{#
						if (current_2){#
							if (rbinom(1,1,switch_off)){current_2<-(1-current_2)}						#
						}else{#
							if (rbinom(1,1,switch_on)){current_2<-(1-current_2)}													#
						}#
				}#
				mydata<-rbind(mydata,c(sub,2,item,bin,current_2))#
			}#
	}#
}
createdata <- function(){#
mydata<-data.frame(subject=c(NA),condition=c(NA),item=c(NA),bin=c(NA),fixtarg=c(NA))#
for (sub in c(1:s_n)){#
	for (item in c(1:items_n)){#
		#do a item for each condition simultaneously (saves time)#
		#draw a bin for an effect#
		con1_bin<-first_bin+rnorm(1,sub_speeds[sub],sub_s_sd)+rnorm(1,0,noise)#
		con2_bin<-first_bin+rnorm(1,sub_speeds[sub],sub_s_sd)+rnorm(1,0,noise)+time_diff+rnorm(1,sub_effects[sub],sub_e_sd)+rnorm(1,item_effects[item],item_sd)#
			current_1<-rbinom(1,1,.5) #where am I looking in first bin for condition 1?#
			current_2<-rbinom(1,1,.5) #where am I looking in first bin for condition 2?#
			mydata<-rbind(mydata,c(sub,1,item,1,current_1))#
			mydata<-rbind(mydata,c(sub,2,item,1,current_2))#
			for (bin in c(2:bins_n)){#
				if (bin<con1_bin){#
						if (rbinom(1,1,switch_baseline)){current_1<-(1-current_1)}#
					}else{#
						if (current_1){#
							if (rbinom(1,1,switch_off)){current_1<-(1-current_1)}						#
						}else{#
							if (rbinom(1,1,switch_on)){current_1<-(1-current_1)}													#
						}#
				}#
				mydata<-rbind(mydata,c(sub,1,item,bin,current_1))#
				if (bin<con2_bin){#
						if (rbinom(1,1,switch_baseline)){current_2<-(1-current_2)}#
					}else{#
						if (current_2){#
							if (rbinom(1,1,switch_off)){current_2<-(1-current_2)}						#
						}else{#
							if (rbinom(1,1,switch_on)){current_2<-(1-current_2)}													#
						}#
				}#
				mydata<-rbind(mydata,c(sub,2,item,bin,current_2))#
			}#
	}#
}#
mydata<-mydata[is.na(mydata$subject)==FALSE,]#
}
createdata <- function(){#
mydata<-data.frame(subject=c(NA),condition=c(NA),item=c(NA),bin=c(NA),fixtarg=c(NA))#
for (sub in c(1:s_n)){#
	for (item in c(1:items_n)){#
		#do a item for each condition simultaneously (saves time)#
		#draw a bin for an effect#
		con1_bin<-first_bin+rnorm(1,sub_speeds[sub],sub_s_sd)+rnorm(1,0,noise)#
		con2_bin<-first_bin+rnorm(1,sub_speeds[sub],sub_s_sd)+rnorm(1,0,noise)+time_diff+rnorm(1,sub_effects[sub],sub_e_sd)+rnorm(1,item_effects[item],item_sd)#
			current_1<-rbinom(1,1,.5) #where am I looking in first bin for condition 1?#
			current_2<-rbinom(1,1,.5) #where am I looking in first bin for condition 2?#
			mydata<-rbind(mydata,c(sub,1,item,1,current_1))#
			mydata<-rbind(mydata,c(sub,2,item,1,current_2))#
			for (bin in c(2:bins_n)){#
				if (bin<con1_bin){#
						if (rbinom(1,1,switch_baseline)){current_1<-(1-current_1)}#
					}else{#
						if (current_1){#
							if (rbinom(1,1,switch_off)){current_1<-(1-current_1)}						#
						}else{#
							if (rbinom(1,1,switch_on)){current_1<-(1-current_1)}													#
						}#
				}#
				mydata<-rbind(mydata,c(sub,1,item,bin,current_1))#
				if (bin<con2_bin){#
						if (rbinom(1,1,switch_baseline)){current_2<-(1-current_2)}#
					}else{#
						if (current_2){#
							if (rbinom(1,1,switch_off)){current_2<-(1-current_2)}						#
						}else{#
							if (rbinom(1,1,switch_on)){current_2<-(1-current_2)}													#
						}#
				}#
				mydata<-rbind(mydata,c(sub,2,item,bin,current_2))#
			}#
	}#
}#
return(mydata<-mydata[is.na(mydata$subject)==FALSE,])#
}
a<- createdata()
summary(a)
#analyze with mixed effects model#
library(lme4)#
get_stats = function(thedata){#
	#assumes data is in the format of the actual data above. Easy to adjust for other datasets.#
	#returns a dataframe, where each row is c(bin#, z-score, p-value)#
	sigs_me<-data.frame(bin=c(1:bins_n),z=rep(0,bins_n),p=rep(0,bins_n))#
	for (bin in c(1:bins_n)){#
		#since our subjects and items aren't different from one another, no need for maximal random effects#
		m<-glmer(fixtarg~condition+(1|subject)+(1|item),data=thedata[thedata$bin==bin,],family="binomial") #
		sigs_me[sigs_me$bin==bin,]<-c(bin,coef(summary(m))[2,3],coef(summary(m))[2,4])#
	}#
	return(sigs_me)#
}
threshold=1.5 #cutoff (t value) for inclusion in a cluster. Lower thresholds get longer, weaker clusters. Choice doesn't effect on false positive rate ... unless you keep trying different thresholds until something "works"#
#
#define some useful functions#
cluster = function(somedata,cutoff){#
	#somedata is a vector of test statistics (not p-values)#
	#cutoff is a threshold for for those statistics. Anything below threshold won't be considered part of a cluster#
	#returns a vector of the same length, where 0 marks a value that is not part of a cluster, and counting numbers mark clusters. #
	#Every value with same # is in same cluster.#
	somedata<-abs(somedata) #will cause problems if there is a sudden, significant switch in sign. Unlikely in practice for eyetracking data.#
	clusters=c()#
	current_cluster=0#
	in_cluster=FALSE#
	for (i in c(1:length(somedata))){#
		if (somedata[i]>cutoff){#
			if (in_cluster){#
				clusters<-c(clusters,current_cluster)#
			}else{#
				in_cluster=TRUE#
				current_cluster<-current_cluster+1#
				clusters<-c(clusters,current_cluster)#
			}#
		}else{#
			clusters<-c(clusters,0)	#
			in_cluster=FALSE#
		}#
	}#
	return(clusters)#
}#
#
score_clusters = function(somedata,someclusters){#
	#somedata is a vector of test statistics (not p-values)#
	#someclusters is the output of cluster()#
	#returns dataframe with the size (sum of test stats) of each cluster#
	c<-data.frame(stat=somedata,cluster=someclusters)#
	scores<-c()#
	for (cluster in c(1:max(someclusters))){#
		scores<-c(scores,sum(abs(c$stat[c$cluster==cluster])))#
	}#
	return(data.frame(cluster=c(1:length(scores)),score=scores))	#
}#
#
resample_data = function(thedata){#
	#This function assumes data is structured like the data above, but should be easy to adapt.#
	##
	#The design of this study is fully crossed (every subject gets every item in every condition)#
	#So all we need to do is shuffle the condition codes for each item for each subject. #
	#If there were also a between-subjects condition, we would have to shuffle subjects between conditions. Etc.#
	#Note: Do NOT shuffle bins and do NOT shuffle condition codes independently for each bin. #
	#That would assume the data in each bin of a trial is independent of the data in the other bins, which it is not.#
	for (sub in c(1:s_n)){#
		for (item in c(1:items_n)){#
			#random coin flip. If heads, switch condition codes. If tails, don't.#
			#if (rbinom(1,1,.5)){#
				#heads. switch codes.#
				# I'm not sure that your analysis does a random partition, Josh. Rather, all the trials that were previously #
				# in one bin, are now assigned to another.#
				#thedata$condition[thedata$subject==sub & thedata$item==item & thedata$condition==1]<-3#
				#thedata$condition[thedata$subject==sub & thedata$item==item & thedata$condition==2]<-1#
				#thedata$condition[thedata$subject==sub & thedata$item==item & thedata$condition==3]<-2#
				#Making the partition random#
				new_cond <- sample(c(rep(c(1,2))),items_n, replace = TRUE)#
				thedata$condition[thedata$subject==sub & thedata$item==item & thedata$condition==1] <- 3#
				thedata$condition[thedata$subject==sub & thedata$item==item & thedata$condition==2] <- 4#
				thedata$condition[thedata$subject==sub & thedata$item==item & thedata$condition==3]<- new_cond[item]#
				#thedata$condition[thedata$subject==sub & thedata$item==item & thedata$condition==4]<- new_cond[item+items_n]#
				thedata$condition[thedata$subject==sub & thedata$item==item & thedata$condition==4] <- ifelse(new_cond[item] ==1,2,1)#
			#}else{#
				#tails. do nothing.#
			#}#
		}#
	}#
	return(thedata)#
}
sample_cluster = function(thedata,threshold){#
	#This function does not assume any particular structure to the data, but it calls resample_data and get_stats which do#
	##
	#thedata = the data that you want to resample#
	#print(thedata[1:3,])#
	print(1)#
	sampled_data<-resample_data(thedata)#
	#print(sampled_data[1:3,])#
	sigs_me<-get_stats(sampled_data)#
	sampled_clusters<-cluster(sigs_me$z,threshold)#
	sampled_cluster_scores<-score_clusters(sigs_me$z,sampled_clusters)#
	return(max(sampled_cluster_scores$score))#
}#
#
sample_clusters = function(thedata,n,multi,threshold){#
	#This function does not assume any particular structure to the data, but it calls resample_data and get_stats (via sample_cluster), which do#
	##
	#thedata = the data that you want to resample#
	#n = number of times to resample#
	#if multi==TRUE, use multiple processors (will need to have loaded the appropriate libraries)#
#
	require(multicore)#
	require(doMC)#
	require(foreach)#
#
	if (multi){#
		registerDoMC(cores=3) #how many processes to spawn?	was written for a computer with 4 processors. This keeps 1 free for other uses.#
		clusters<-foreach(i=iter(c(1:n)),.combine=rbind) %dopar% sample_cluster(thedata,threshold)#
	}else{#
		clusters<-foreach(i=iter(c(1:n)),.combine=rbind) %do% sample_cluster(thedata,threshold)#
	}#
	return(clusters)#
}
# This R script uses JoshH's scripts to create a set of fake datasets, and then analyzes#
# those datasets using three different threshold.#
# j is number of simulations#
#
threshold = c(1.6,2.0,2.4)#
real_score = matrix(NA,1,3)#
pval <- matrix(NA,1000,3)#
#
#cluster the data#
for (j in c(1:1000)){#
print(j)#
mydata <- createdata()#
sigs_me<-get_stats(mydata)#
#
for (k in c(1:length(threshold))){ # k is number of thresholds#
actual_clusters<-cluster(sigs_me$z,threshold[k]) #cluster the actual data#
actual_cluster_scores<-score_clusters(sigs_me$z,actual_clusters) #find the scores for the clusters in the actual data#
real_score[1,k] <- max(actual_cluster_scores$score)#
sampled_maxes<-sample_clusters(mydata,1000,TRUE,threshold[k])#
pval[j,k] = 1 - sum(as.numeric(max(actual_cluster_scores$score) > c(max(actual_cluster_scores$score),sampled_maxes[,1])))/(length(sampled_maxes[,1])+1)#
#
}#
}#
#for (k in c(1:length(threshold))){ # k is number of thresholds#
#	sampled_maxes<-sample_clusters(mydata,1000,TRUE,threshold[k])#
#	pval[j,k] = 1 - sum(as.numeric(max(actual_cluster_scores$score) > c(max(actual_cluster_scores$score),sampled_maxes[,1])))/(length(sampled_maxes[,1])+1)#
#	#
#	}#
#}
logit(0)
library(arm)
logit(0)
invlogit(0)
?setwd
#values used for longdiff#
# s_n<-24 #how many subjects#
# switch_baseline<-.25 #probability of switching to target at baseline#
# switch_on<-.5 #probability of switching to target when effect is in effect#
# switch_off<-.1 #probability of switching off target when effect is in effect#
# items_n<-5 #how many items per condition? 2-condition experiment. items appear in both conditions, within subject#
# bins_n<-20 #how many bins?#
# first_bin<-7 #on average, what is the first bin to show an effect in condition with early effect?#
# time_diff<-2.5 #how many bins earlier is there an effect in condition 1 than condition 2?#
# noise<-2 #trial noise sd#
# sub_speeds<-rnorm(s_n,0,1) #how much faster or slower than typical is the subject?#
# sub_s_sd<-1 #sd for sub speed error#
# sub_effects<-rnorm(s_n,0,1.5) #degree to which effect size is larger or smaller for that subject#
# sub_e_sd<-1 #sd for sub effect error#
# item_effects<-rnorm(items_n,0,.5) #degree to which effect size is larger or smaller than typical for that item#
# item_sd<-1 #sd for item effect error#
#
#values used for shortdiff#
s_n<-24 #how many subjects#
switch_baseline<-.25 #probability of switching to target at baseline#
switch_on<-.9 #probability of switching to target when effect is in effect#
switch_off<-.2 #probability of switching off target when effect is in effect#
items_n<-5 #how many items per condition? 2-condition experiment. items appear in both conditions, within subject#
bins_n<-20 #how many bins?#
first_bin<-7 #on average, what is the first bin to show an effect in condition with early effect?#
time_diff<-0 #how many bins earlier is there an effect in condition 1 than condition 2?#
noise<-.25 #trial noise sd#
sub_speeds<-rnorm(s_n,0,.25) #how much faster or slower than typical is the subject?#
sub_s_sd<-.5 #sd for sub speed error#
sub_effects<-rnorm(s_n,0,2) #degree to which effect size is larger or smaller for that subject#
sub_e_sd<-.25 #sd for sub effect error#
item_effects<-rnorm(items_n,0,2) #degree to which effect size is larger or smaller than typical for that item#
item_sd<-.25 #sd for item effect error#
#what's alpha?#
1-.95^(1/bins_n)#
#
createdata <- function(){#
mydata<-data.frame(subject=c(NA),condition=c(NA),item=c(NA),bin=c(NA),fixtarg=c(NA))#
for (sub in c(1:s_n)){#
	for (item in c(1:items_n)){#
		#do a item for each condition simultaneously (saves time)#
		#draw a bin for an effect#
		con1_bin<-first_bin+rnorm(1,sub_speeds[sub],sub_s_sd)+rnorm(1,0,noise)#
		con2_bin<-first_bin+rnorm(1,sub_speeds[sub],sub_s_sd)+rnorm(1,0,noise) #+time_diff+rnorm(1,sub_effects[sub],sub_e_sd)+rnorm(1,item_effects[item],item_sd)#
			current_1<-rbinom(1,1,.5) #where am I looking in first bin for condition 1?#
			current_2<-rbinom(1,1,.5) #where am I looking in first bin for condition 2?#
			mydata<-rbind(mydata,c(sub,1,item,1,current_1))#
			mydata<-rbind(mydata,c(sub,2,item,1,current_2))#
			for (bin in c(2:bins_n)){#
				if (bin<con1_bin){#
						if (rbinom(1,1,switch_baseline)){current_1<-(1-current_1)}#
					}else{#
						if (current_1){#
							if (rbinom(1,1,switch_off)){current_1<-(1-current_1)}						#
						}else{#
							if (rbinom(1,1,switch_on)){current_1<-(1-current_1)}													#
						}#
				}#
				mydata<-rbind(mydata,c(sub,1,item,bin,current_1))#
				if (bin<con2_bin){#
						if (rbinom(1,1,switch_baseline)){current_2<-(1-current_2)}#
					}else{#
						if (current_2){#
							if (rbinom(1,1,switch_off)){current_2<-(1-current_2)}						#
						}else{#
							if (rbinom(1,1,switch_on)){current_2<-(1-current_2)}													#
						}#
				}#
				mydata<-rbind(mydata,c(sub,2,item,bin,current_2))#
			}#
	}#
}#
return(mydata<-mydata[is.na(mydata$subject)==FALSE,])#
}#
mydata <- createdata()#
#
#calculate means#
submeans<-aggregate(mydata$fixtarg,by=list(mydata$subject,mydata$condition,mydata$bin),FUN=mean)#
colnames(submeans)<-c("subject","condition","bin","fixtarg")#
means<-aggregate(submeans$fixtarg,by=list(submeans$condition,submeans$bin),FUN=mean)#
colnames(means)<-c("condition","bin","fixtarg")#
temp<-aggregate(submeans$fixtarg,by=list(submeans$condition,submeans$bin),FUN=sd)#
means$se<-temp[,3]/(s_n^.5)
summary(mydata)
0.05/20
logit(1)
log((1/0))
log((0.95/0.05))
?names
require(plyr)#
require(longitudinalData)#
sac.process2 = function(pathway = "./", Pop = "NA"){#
	sac = c()#
	for (i in unique(Pop)){#
		for (j in c("Pre","Targ","Rew")){# Something is off with the reward section ,"Rew")){#
		file.list <- list.files(path = pathway,full.names = T,pattern = paste(i,".*","Sac",j, sep = ""))#
		sac.temp <- read.delim(file.list, header = T)#
		sac.temp$Period = ifelse(j == "Targ","Naming",j)#
		sac <- rbind(sac, sac.temp)	#
		}#
	}#
	names(sac)[names(sac) == "RECORDING_SESSION_LABEL"] <- "Subj"#
	names(sac)[names(sac) == "CURRENT_SAC_NEAREST_START_INTEREST_AREA_LABEL"] <- "SacStart"#
	names(sac)[names(sac) == "CURRENT_SAC_NEAREST_END_INTEREST_AREA_LABEL"] <- "SacEnd"#
	names(sac)[names(sac) == "CURRENT_SAC_END_TIME"] <- "SacEndTime"#
	sac$Subj <- as.factor(paste(sac$Subj,".edf", sep = ""))#
	sac$Sac <- 1#
	sac$SacSwitch <- ifelse(sac$SacStart == sac$SacEnd,0,1)#
	sac$SacToTarg <- 0#
	sac$SacFromTarg <- 0#
	sac[sac$SacStart == "Pre_Targ " & sac$SacEnd == "Pre_D1 ",]$SacFromTarg <- 1#
	sac[sac$SacStart == "Pre_D1 " & sac$SacEnd == "Pre_Targ ",]$SacToTarg <- 1#
	sac$SacTarg <- 0#
	sac[sac$SacStart == "Pre_Targ " & sac$SacEnd == "Pre_D1 ",]$SacTarg <- 1#
	sac[sac$SacStart == "Pre_D1 " & sac$SacEnd == "Pre_Targ ",]$SacTarg <- 1#
#
	sac$SacDist1 <- 0#
	sac[sac$SacStart == "Pre_D1 " & sac$SacEnd == "Pre_D2 ",]$SacDist1 <- 1#
	sac[sac$SacStart == "Pre_D2 " & sac$SacEnd == "Pre_D1 ",]$SacDist1 <- 1#
	sac$SacDist2 <- 0#
	sac[sac$SacStart == "Pre_Targ " & sac$SacEnd == "Pre_D2 ",]$SacDist2 <- 1#
	sac[sac$SacStart == "Pre_D2 " & sac$SacEnd == "Pre_Targ ",]$SacDist2 <- 1#
	#sac <- summaryBy(SacTarg + SacSwitch + Sac + SacDist1 + SacDist2 ~ Subj + trialnum + cond+Period, data = sac, keep.names = T)#
	sac <- sac[sac$type != "Filler",]#
	return(sac)#
}#
#
kid.sac <- sac.process2("./","Kids")#
kid.sac$order <- 1:length(kid.sac$SacToTarg)#
names <- read.delim("WriteNames-Times.txt")#
#Groups = read.delim("SubjNames.txt", header = T)#
#merge(kid.sac,Groups, all = T) -> kid.sac#
#kid.sac[is.na(kid.sac$AgeGroup),]$AgeGroup <- "Old"#
kid.sac <- merge(kid.sac,names, by = c("Subj","trialnum"), all.x = TRUE)#
kid.sac<- kid.sac[order(kid.sac$order),]#
names(kid.sac)[names(kid.sac) == "StartTime..ms."] <- "StartTime"#
kid.sac <- ddply(kid.sac, .(Subj,trialnum,Period), transform, CumFromTarg = cumsum(SacFromTarg),CumToTarg = cumsum(SacToTarg),CumTarg = cumsum(SacTarg),CumD1 = cumsum(SacDist1),CumD2 = cumsum(SacDist2), SacTime = SacEndTime - min(SacEndTime), SacBin = round((SacEndTime - min(SacEndTime))/100))#
# Create LabelCond variable; used for data analysis#
kid.sac$LabelCond <- NA#
kid.sac[kid.sac$cond == "Control" & kid.sac$Label %in% c(1,0),]$LabelCond <- "Control"#
kid.sac[kid.sac$cond == "Ambig" & kid.sac$Label %in% c(1),]$LabelCond <- "Test-Ambig"#
kid.sac[kid.sac$cond == "Ambig" & kid.sac$Label %in% c(0),]$LabelCond <- "Test-Unambig"#
kid.sac$LabelCond <- as.factor(kid.sac$LabelCond)#
ddply(kid.sac, .(Subj,trialnum,cond,Period,targname,LabelCond,Label,StartTime), summarize, SacBin = c(0:181)) -> kid.sac.s#
ddply(kid.sac[kid.sac$SacBin <182,], .(Subj,trialnum,cond,Period,targname,LabelCond,Label,SacBin), summarize, CumTarg = mean(CumTarg),CumD1 = mean(CumD1),CumD2 = mean(CumD2)) -> kid.sac.sum#
kid.sac.bin <- merge(kid.sac.s, kid.sac.sum, all = TRUE)#
kid.sac.bin$CumTarg <- t(imputation(matrix(kid.sac.bin$CumTarg, nrow = 1),method = "locf"))#
kid.sac.bin$CumD1 <- t(imputation(matrix(kid.sac.bin$CumD1, nrow = 1),method = "locf"))#
kid.sac.bin$CumD2 <- t(imputation(matrix(kid.sac.bin$CumD2, nrow = 1),method = "locf"))#
kid.sac.bin$Item <- as.factor(sapply(strsplit(as.character(kid.sac.bin$targname),"[.12]"), "[", 1))#
#
kid.sac.bin$SubjTrial <- paste(kid.sac.bin$Subj,kid.sac.bin$Item, sep = "") #
TrialTime <- summaryBy(TRIAL_DWELL_TIME~SubjTrial, data = subset(kid.ref.t, subset = Period == "Pre" & Picture == "Targ"), keep.names = T, na.rm = T)#
kid.sac.bin <- kid.sac.bin[kid.sac.bin$SubjTrial %in% TrialTime[TrialTime$TRIAL_DWELL_TIME > 1500,]$SubjTrial,]#
kid.sac.bin$StartTime <- kid.sac.bin$StartTime/100#
kid.sac.bin$StartTime <- round(kid.sac.bin$StartTime)#
kid.sac.bin$SacBin2 <- kid.sac.bin$SacBin - kid.sac.bin$StartTime#
#Change the SacBin2 above to SacBin to see this timelocked to naming onset.#
#
kid.sac.bin.naming <- subset(kid.sac.bin, SacBin2 >= -10 & SacBin2 <= 50)#
kid.sac.bin.naming$SacBin <- kid.sac.bin.naming$SacBin2#
kid.sac.bin.naming <- ddply(kid.sac.bin.naming, .(Subj,trialnum, Period), transform, CumTarg = CumTarg - min(CumTarg),CumD1 = CumD1 - min(CumD1),CumD2 = CumD2 - min(CumD2))#
#
# We don't have naming times currently#
summary(lmer(SacTarg~LabelCond+ (1|Subj), data = subset(Sac.sum, AgeGroup !="Excl" & Period == "Pre")))#
	 summaryBy(SacDist1+SacDist2+SacFromTarg+SacToTarg +SacTarg ~AgeGroup+Subj+trialnum+LabelCond+Period+Start, data = kid.sac, keep.names = T) -> Sac.sum#
	 na.omit(summaryBy(SacTarg +SacDist2 +SacDist1+SacFromTarg+SacToTarg ~AgeGroup+Period+Start+LabelCond, data = Sac.sum, keep.names = T))#
na.omit(summaryBy(SacTarg~Period+LabelCond+Subj, data = Sac.sum[Sac.sum$Period != "Rew",], FUN = c(mean,sd), keep.names = T)) -> Sac.graph#
na.omit(summaryBy(SacTarg.mean~Period+LabelCond, data = Sac.graph, FUN = c(mean,sd))) -> Sac.graph#
Sac.graph$Period <- factor(Sac.graph$Period, levels = c("Pre","Naming"),labels = c("Pre","Naming"), ordered = T)#
Sac.graph$SE = Sac.graph$SacTarg.mean.sd/sqrt(length(unique(Sac.sum$Subj)))#
#
Sac.graph$Time = "Naming"#
Sac.graph[Sac.graph$Period == "Pre" , ]$Time = "Preview"#
Sac.graph$Time <- factor(Sac.graph$Time, levels = c("Preview","Naming"),labels = c("Preview","Naming"), ordered = T)#
#
tapply(Sac.graph$SacTarg.mean.mean, list(Sac.graph$LabelCond,Sac.graph$Time), FUN = mean) -> o#
tapply(Sac.graph$SE, list(Sac.graph$LabelCond,Sac.graph$Time), FUN = mean) -> se#
#
barplot(o, beside =T , ylim = c(0,0.40),col = "white",  border = NA, ylab = "Critical Saccades", names.arg = c("Preview", "Naming"))#
 legend(1.2,0.15, legend = c("Control", "Detecting Ambiguity", "Not Detecting Ambiguity"), bty = "n", col = c("blue","grey","red"), pch = 20)#
 points(c(1.5,6), o[1,], pch = 20, cex = 2, col = "blue")#
 points(c(2.5,6.8), o[2,], pch = 20, cex = 2, col = "grey")#
  points(c(3.5,7.6), o[3,], pch = 20, cex = 2, col = "red")#
 grid(nx = NA, ny = NULL, col = "gray", lty = "dotted",lwd = par("lwd"), equilogs = TRUE)#
abline(v = c(4.5,8.5), col = "grey", lty = "dashed")#
  arrows(c(1.5,2.5,3.5,6,6.8,7.6), (c(o) + c(se)+0.01), c(1.5,2.5,3.5,6,6.8,7.6), (c(o) - c(se)-0.01), code = 0)
library(doBy)
require(plyr)#
require(longitudinalData)#
sac.process2 = function(pathway = "./", Pop = "NA"){#
	sac = c()#
	for (i in unique(Pop)){#
		for (j in c("Pre","Targ","Rew")){# Something is off with the reward section ,"Rew")){#
		file.list <- list.files(path = pathway,full.names = T,pattern = paste(i,".*","Sac",j, sep = ""))#
		sac.temp <- read.delim(file.list, header = T)#
		sac.temp$Period = ifelse(j == "Targ","Naming",j)#
		sac <- rbind(sac, sac.temp)	#
		}#
	}#
	names(sac)[names(sac) == "RECORDING_SESSION_LABEL"] <- "Subj"#
	names(sac)[names(sac) == "CURRENT_SAC_NEAREST_START_INTEREST_AREA_LABEL"] <- "SacStart"#
	names(sac)[names(sac) == "CURRENT_SAC_NEAREST_END_INTEREST_AREA_LABEL"] <- "SacEnd"#
	names(sac)[names(sac) == "CURRENT_SAC_END_TIME"] <- "SacEndTime"#
	sac$Subj <- as.factor(paste(sac$Subj,".edf", sep = ""))#
	sac$Sac <- 1#
	sac$SacSwitch <- ifelse(sac$SacStart == sac$SacEnd,0,1)#
	sac$SacToTarg <- 0#
	sac$SacFromTarg <- 0#
	sac[sac$SacStart == "Pre_Targ " & sac$SacEnd == "Pre_D1 ",]$SacFromTarg <- 1#
	sac[sac$SacStart == "Pre_D1 " & sac$SacEnd == "Pre_Targ ",]$SacToTarg <- 1#
	sac$SacTarg <- 0#
	sac[sac$SacStart == "Pre_Targ " & sac$SacEnd == "Pre_D1 ",]$SacTarg <- 1#
	sac[sac$SacStart == "Pre_D1 " & sac$SacEnd == "Pre_Targ ",]$SacTarg <- 1#
#
	sac$SacDist1 <- 0#
	sac[sac$SacStart == "Pre_D1 " & sac$SacEnd == "Pre_D2 ",]$SacDist1 <- 1#
	sac[sac$SacStart == "Pre_D2 " & sac$SacEnd == "Pre_D1 ",]$SacDist1 <- 1#
	sac$SacDist2 <- 0#
	sac[sac$SacStart == "Pre_Targ " & sac$SacEnd == "Pre_D2 ",]$SacDist2 <- 1#
	sac[sac$SacStart == "Pre_D2 " & sac$SacEnd == "Pre_Targ ",]$SacDist2 <- 1#
	#sac <- summaryBy(SacTarg + SacSwitch + Sac + SacDist1 + SacDist2 ~ Subj + trialnum + cond+Period, data = sac, keep.names = T)#
	sac <- sac[sac$type != "Filler",]#
	return(sac)#
}#
#
kid.sac <- sac.process2("./","Kids")#
kid.sac$order <- 1:length(kid.sac$SacToTarg)#
names <- read.delim("WriteNames-Times.txt")#
#Groups = read.delim("SubjNames.txt", header = T)#
#merge(kid.sac,Groups, all = T) -> kid.sac#
#kid.sac[is.na(kid.sac$AgeGroup),]$AgeGroup <- "Old"#
kid.sac <- merge(kid.sac,names, by = c("Subj","trialnum"), all.x = TRUE)#
kid.sac<- kid.sac[order(kid.sac$order),]#
names(kid.sac)[names(kid.sac) == "StartTime..ms."] <- "StartTime"#
kid.sac <- ddply(kid.sac, .(Subj,trialnum,Period), transform, CumFromTarg = cumsum(SacFromTarg),CumToTarg = cumsum(SacToTarg),CumTarg = cumsum(SacTarg),CumD1 = cumsum(SacDist1),CumD2 = cumsum(SacDist2), SacTime = SacEndTime - min(SacEndTime), SacBin = round((SacEndTime - min(SacEndTime))/100))#
# Create LabelCond variable; used for data analysis#
kid.sac$LabelCond <- NA#
kid.sac[kid.sac$cond == "Control" & kid.sac$Label %in% c(1,0),]$LabelCond <- "Control"#
kid.sac[kid.sac$cond == "Ambig" & kid.sac$Label %in% c(1),]$LabelCond <- "Test-Ambig"#
kid.sac[kid.sac$cond == "Ambig" & kid.sac$Label %in% c(0),]$LabelCond <- "Test-Unambig"#
kid.sac$LabelCond <- as.factor(kid.sac$LabelCond)#
ddply(kid.sac, .(Subj,trialnum,cond,Period,targname,LabelCond,Label,StartTime), summarize, SacBin = c(0:181)) -> kid.sac.s#
ddply(kid.sac[kid.sac$SacBin <182,], .(Subj,trialnum,cond,Period,targname,LabelCond,Label,SacBin), summarize, CumTarg = mean(CumTarg),CumD1 = mean(CumD1),CumD2 = mean(CumD2)) -> kid.sac.sum#
kid.sac.bin <- merge(kid.sac.s, kid.sac.sum, all = TRUE)#
kid.sac.bin$CumTarg <- t(imputation(matrix(kid.sac.bin$CumTarg, nrow = 1),method = "locf"))#
kid.sac.bin$CumD1 <- t(imputation(matrix(kid.sac.bin$CumD1, nrow = 1),method = "locf"))#
kid.sac.bin$CumD2 <- t(imputation(matrix(kid.sac.bin$CumD2, nrow = 1),method = "locf"))#
kid.sac.bin$Item <- as.factor(sapply(strsplit(as.character(kid.sac.bin$targname),"[.12]"), "[", 1))#
#
kid.sac.bin$SubjTrial <- paste(kid.sac.bin$Subj,kid.sac.bin$Item, sep = "") #
TrialTime <- summaryBy(TRIAL_DWELL_TIME~SubjTrial, data = subset(kid.ref.t, subset = Period == "Pre" & Picture == "Targ"), keep.names = T, na.rm = T)#
kid.sac.bin <- kid.sac.bin[kid.sac.bin$SubjTrial %in% TrialTime[TrialTime$TRIAL_DWELL_TIME > 1500,]$SubjTrial,]#
kid.sac.bin$StartTime <- kid.sac.bin$StartTime/100#
kid.sac.bin$StartTime <- round(kid.sac.bin$StartTime)#
kid.sac.bin$SacBin2 <- kid.sac.bin$SacBin - kid.sac.bin$StartTime#
#Change the SacBin2 above to SacBin to see this timelocked to naming onset.#
#
kid.sac.bin.naming <- subset(kid.sac.bin, SacBin2 >= -10 & SacBin2 <= 50)#
kid.sac.bin.naming$SacBin <- kid.sac.bin.naming$SacBin2#
kid.sac.bin.naming <- ddply(kid.sac.bin.naming, .(Subj,trialnum, Period), transform, CumTarg = CumTarg - min(CumTarg),CumD1 = CumD1 - min(CumD1),CumD2 = CumD2 - min(CumD2))#
#
# We don't have naming times currently#
summary(lmer(SacTarg~LabelCond+ (1|Subj), data = subset(Sac.sum, AgeGroup !="Excl" & Period == "Pre")))#
	 summaryBy(SacDist1+SacDist2+SacFromTarg+SacToTarg +SacTarg ~AgeGroup+Subj+trialnum+LabelCond+Period+Start, data = kid.sac, keep.names = T) -> Sac.sum#
	 na.omit(summaryBy(SacTarg +SacDist2 +SacDist1+SacFromTarg+SacToTarg ~AgeGroup+Period+Start+LabelCond, data = Sac.sum, keep.names = T))#
na.omit(summaryBy(SacTarg~Period+LabelCond+Subj, data = Sac.sum[Sac.sum$Period != "Rew",], FUN = c(mean,sd), keep.names = T)) -> Sac.graph#
na.omit(summaryBy(SacTarg.mean~Period+LabelCond, data = Sac.graph, FUN = c(mean,sd))) -> Sac.graph#
Sac.graph$Period <- factor(Sac.graph$Period, levels = c("Pre","Naming"),labels = c("Pre","Naming"), ordered = T)#
Sac.graph$SE = Sac.graph$SacTarg.mean.sd/sqrt(length(unique(Sac.sum$Subj)))#
#
Sac.graph$Time = "Naming"#
Sac.graph[Sac.graph$Period == "Pre" , ]$Time = "Preview"#
Sac.graph$Time <- factor(Sac.graph$Time, levels = c("Preview","Naming"),labels = c("Preview","Naming"), ordered = T)#
#
tapply(Sac.graph$SacTarg.mean.mean, list(Sac.graph$LabelCond,Sac.graph$Time), FUN = mean) -> o#
tapply(Sac.graph$SE, list(Sac.graph$LabelCond,Sac.graph$Time), FUN = mean) -> se#
#
barplot(o, beside =T , ylim = c(0,0.40),col = "white",  border = NA, ylab = "Critical Saccades", names.arg = c("Preview", "Naming"))#
 legend(1.2,0.15, legend = c("Control", "Detecting Ambiguity", "Not Detecting Ambiguity"), bty = "n", col = c("blue","grey","red"), pch = 20)#
 points(c(1.5,6), o[1,], pch = 20, cex = 2, col = "blue")#
 points(c(2.5,6.8), o[2,], pch = 20, cex = 2, col = "grey")#
  points(c(3.5,7.6), o[3,], pch = 20, cex = 2, col = "red")#
 grid(nx = NA, ny = NULL, col = "gray", lty = "dotted",lwd = par("lwd"), equilogs = TRUE)#
abline(v = c(4.5,8.5), col = "grey", lty = "dashed")#
  arrows(c(1.5,2.5,3.5,6,6.8,7.6), (c(o) + c(se)+0.01), c(1.5,2.5,3.5,6,6.8,7.6), (c(o) - c(se)-0.01), code = 0)
require(plyr)#
require(longitudinalData)#
sac.process2 = function(pathway = "./", Pop = "NA"){#
	sac = c()#
	for (i in unique(Pop)){#
		for (j in c("Pre","Targ","Rew")){# Something is off with the reward section ,"Rew")){#
		file.list <- list.files(path = pathway,full.names = T,pattern = paste(i,".*","Sac",j, sep = ""))#
		sac.temp <- read.delim(file.list, header = T)#
		sac.temp$Period = ifelse(j == "Targ","Naming",j)#
		sac <- rbind(sac, sac.temp)	#
		}#
	}#
	names(sac)[names(sac) == "RECORDING_SESSION_LABEL"] <- "Subj"#
	names(sac)[names(sac) == "CURRENT_SAC_NEAREST_START_INTEREST_AREA_LABEL"] <- "SacStart"#
	names(sac)[names(sac) == "CURRENT_SAC_NEAREST_END_INTEREST_AREA_LABEL"] <- "SacEnd"#
	names(sac)[names(sac) == "CURRENT_SAC_END_TIME"] <- "SacEndTime"#
	sac$Subj <- as.factor(paste(sac$Subj,".edf", sep = ""))#
	sac$Sac <- 1#
	sac$SacSwitch <- ifelse(sac$SacStart == sac$SacEnd,0,1)#
	sac$SacToTarg <- 0#
	sac$SacFromTarg <- 0#
	sac[sac$SacStart == "Pre_Targ " & sac$SacEnd == "Pre_D1 ",]$SacFromTarg <- 1#
	sac[sac$SacStart == "Pre_D1 " & sac$SacEnd == "Pre_Targ ",]$SacToTarg <- 1#
	sac$SacTarg <- 0#
	sac[sac$SacStart == "Pre_Targ " & sac$SacEnd == "Pre_D1 ",]$SacTarg <- 1#
	sac[sac$SacStart == "Pre_D1 " & sac$SacEnd == "Pre_Targ ",]$SacTarg <- 1#
#
	sac$SacDist1 <- 0#
	sac[sac$SacStart == "Pre_D1 " & sac$SacEnd == "Pre_D2 ",]$SacDist1 <- 1#
	sac[sac$SacStart == "Pre_D2 " & sac$SacEnd == "Pre_D1 ",]$SacDist1 <- 1#
	sac$SacDist2 <- 0#
	sac[sac$SacStart == "Pre_Targ " & sac$SacEnd == "Pre_D2 ",]$SacDist2 <- 1#
	sac[sac$SacStart == "Pre_D2 " & sac$SacEnd == "Pre_Targ ",]$SacDist2 <- 1#
	#sac <- summaryBy(SacTarg + SacSwitch + Sac + SacDist1 + SacDist2 ~ Subj + trialnum + cond+Period, data = sac, keep.names = T)#
	sac <- sac[sac$type != "Filler",]#
	return(sac)#
}#
#
kid.sac <- sac.process2("./","Kids")#
kid.sac$order <- 1:length(kid.sac$SacToTarg)#
names <- read.delim("WriteNames-Times.txt")#
#Groups = read.delim("SubjNames.txt", header = T)#
#merge(kid.sac,Groups, all = T) -> kid.sac#
#kid.sac[is.na(kid.sac$AgeGroup),]$AgeGroup <- "Old"#
kid.sac <- merge(kid.sac,names, by = c("Subj","trialnum"), all.x = TRUE)#
kid.sac<- kid.sac[order(kid.sac$order),]#
names(kid.sac)[names(kid.sac) == "StartTime..ms."] <- "StartTime"#
kid.sac <- ddply(kid.sac, .(Subj,trialnum,Period), transform, CumFromTarg = cumsum(SacFromTarg),CumToTarg = cumsum(SacToTarg),CumTarg = cumsum(SacTarg),CumD1 = cumsum(SacDist1),CumD2 = cumsum(SacDist2), SacTime = SacEndTime - min(SacEndTime), SacBin = round((SacEndTime - min(SacEndTime))/100))#
# Create LabelCond variable; used for data analysis#
kid.sac$LabelCond <- NA#
kid.sac[kid.sac$cond == "Control" & kid.sac$Label %in% c(1,0),]$LabelCond <- "Control"#
kid.sac[kid.sac$cond == "Ambig" & kid.sac$Label %in% c(0),]$LabelCond <- "Test-Unambig"#
kid.sac[kid.sac$cond == "Ambig" & kid.sac$Label %in% c(1),]$LabelCond <- "Test-Ambig"#
kid.sac$LabelCond <- as.factor(kid.sac$LabelCond)#
ddply(kid.sac, .(Subj,trialnum,cond,Period,targname,LabelCond,Label,StartTime), summarize, SacBin = c(0:181)) -> kid.sac.s#
ddply(kid.sac[kid.sac$SacBin <182,], .(Subj,trialnum,cond,Period,targname,LabelCond,Label,SacBin), summarize, CumTarg = mean(CumTarg),CumD1 = mean(CumD1),CumD2 = mean(CumD2)) -> kid.sac.sum#
kid.sac.bin <- merge(kid.sac.s, kid.sac.sum, all = TRUE)#
kid.sac.bin$CumTarg <- t(imputation(matrix(kid.sac.bin$CumTarg, nrow = 1),method = "locf"))#
kid.sac.bin$CumD1 <- t(imputation(matrix(kid.sac.bin$CumD1, nrow = 1),method = "locf"))#
kid.sac.bin$CumD2 <- t(imputation(matrix(kid.sac.bin$CumD2, nrow = 1),method = "locf"))#
kid.sac.bin$Item <- as.factor(sapply(strsplit(as.character(kid.sac.bin$targname),"[.12]"), "[", 1))#
#
kid.sac.bin$SubjTrial <- paste(kid.sac.bin$Subj,kid.sac.bin$Item, sep = "") #
TrialTime <- summaryBy(TRIAL_DWELL_TIME~SubjTrial, data = subset(kid.ref.t, subset = Period == "Pre" & Picture == "Targ"), keep.names = T, na.rm = T)#
kid.sac.bin <- kid.sac.bin[kid.sac.bin$SubjTrial %in% TrialTime[TrialTime$TRIAL_DWELL_TIME > 1500,]$SubjTrial,]#
kid.sac.bin$StartTime <- kid.sac.bin$StartTime/100#
kid.sac.bin$StartTime <- round(kid.sac.bin$StartTime)#
kid.sac.bin$SacBin2 <- kid.sac.bin$SacBin - kid.sac.bin$StartTime#
#Change the SacBin2 above to SacBin to see this timelocked to naming onset.#
#
kid.sac.bin.naming <- subset(kid.sac.bin, SacBin2 >= -10 & SacBin2 <= 50)#
kid.sac.bin.naming$SacBin <- kid.sac.bin.naming$SacBin2#
kid.sac.bin.naming <- ddply(kid.sac.bin.naming, .(Subj,trialnum, Period), transform, CumTarg = CumTarg - min(CumTarg),CumD1 = CumD1 - min(CumD1),CumD2 = CumD2 - min(CumD2))#
#
# We don't have naming times currently#
summary(lmer(SacTarg~LabelCond+ (1|Subj), data = subset(Sac.sum, AgeGroup !="Excl" & Period == "Pre")))#
	 summaryBy(SacDist1+SacDist2+SacFromTarg+SacToTarg +SacTarg ~AgeGroup+Subj+trialnum+LabelCond+Period+Start, data = kid.sac, keep.names = T) -> Sac.sum#
	 na.omit(summaryBy(SacTarg +SacDist2 +SacDist1+SacFromTarg+SacToTarg ~AgeGroup+Period+Start+LabelCond, data = Sac.sum, keep.names = T))#
na.omit(summaryBy(SacTarg~Period+LabelCond+Subj, data = Sac.sum[Sac.sum$Period != "Rew",], FUN = c(mean,sd), keep.names = T)) -> Sac.graph#
na.omit(summaryBy(SacTarg.mean~Period+LabelCond, data = Sac.graph, FUN = c(mean,sd))) -> Sac.graph#
Sac.graph$Period <- factor(Sac.graph$Period, levels = c("Pre","Naming"),labels = c("Pre","Naming"), ordered = T)#
Sac.graph$SE = Sac.graph$SacTarg.mean.sd/sqrt(length(unique(Sac.sum$Subj)))#
#
Sac.graph$Time = "Naming"#
Sac.graph[Sac.graph$Period == "Pre" , ]$Time = "Preview"#
Sac.graph$Time <- factor(Sac.graph$Time, levels = c("Preview","Naming"),labels = c("Preview","Naming"), ordered = T)#
#
tapply(Sac.graph$SacTarg.mean.mean, list(Sac.graph$LabelCond,Sac.graph$Time), FUN = mean) -> o#
tapply(Sac.graph$SE, list(Sac.graph$LabelCond,Sac.graph$Time), FUN = mean) -> se#
#
barplot(o, beside =T , ylim = c(0,0.40),col = "white",  border = NA, ylab = "Critical Saccades", names.arg = c("Preview", "Naming"))#
 legend(1.2,0.15, legend = c("Control", "Detecting Ambiguity", "Not Detecting Ambiguity"), bty = "n", col = c("blue","grey","red"), pch = 20)#
 points(c(1.5,6), o[1,], pch = 20, cex = 2, col = "blue")#
 points(c(2.5,6.8), o[2,], pch = 20, cex = 2, col = "grey")#
  points(c(3.5,7.6), o[3,], pch = 20, cex = 2, col = "red")#
 grid(nx = NA, ny = NULL, col = "gray", lty = "dotted",lwd = par("lwd"), equilogs = TRUE)#
abline(v = c(4.5,8.5), col = "grey", lty = "dashed")#
  arrows(c(1.5,2.5,3.5,6,6.8,7.6), (c(o) + c(se)+0.01), c(1.5,2.5,3.5,6,6.8,7.6), (c(o) - c(se)-0.01), code = 0)
require(plyr)#
require(longitudinalData)#
sac.process2 = function(pathway = "./", Pop = "NA"){#
	sac = c()#
	for (i in unique(Pop)){#
		for (j in c("Pre","Targ","Rew")){# Something is off with the reward section ,"Rew")){#
		file.list <- list.files(path = pathway,full.names = T,pattern = paste(i,".*","Sac",j, sep = ""))#
		sac.temp <- read.delim(file.list, header = T)#
		sac.temp$Period = ifelse(j == "Targ","Naming",j)#
		sac <- rbind(sac, sac.temp)	#
		}#
	}#
	names(sac)[names(sac) == "RECORDING_SESSION_LABEL"] <- "Subj"#
	names(sac)[names(sac) == "CURRENT_SAC_NEAREST_START_INTEREST_AREA_LABEL"] <- "SacStart"#
	names(sac)[names(sac) == "CURRENT_SAC_NEAREST_END_INTEREST_AREA_LABEL"] <- "SacEnd"#
	names(sac)[names(sac) == "CURRENT_SAC_END_TIME"] <- "SacEndTime"#
	sac$Subj <- as.factor(paste(sac$Subj,".edf", sep = ""))#
	sac$Sac <- 1#
	sac$SacSwitch <- ifelse(sac$SacStart == sac$SacEnd,0,1)#
	sac$SacToTarg <- 0#
	sac$SacFromTarg <- 0#
	sac[sac$SacStart == "Pre_Targ " & sac$SacEnd == "Pre_D1 ",]$SacFromTarg <- 1#
	sac[sac$SacStart == "Pre_D1 " & sac$SacEnd == "Pre_Targ ",]$SacToTarg <- 1#
	sac$SacTarg <- 0#
	sac[sac$SacStart == "Pre_Targ " & sac$SacEnd == "Pre_D1 ",]$SacTarg <- 1#
	sac[sac$SacStart == "Pre_D1 " & sac$SacEnd == "Pre_Targ ",]$SacTarg <- 1#
#
	sac$SacDist1 <- 0#
	sac[sac$SacStart == "Pre_D1 " & sac$SacEnd == "Pre_D2 ",]$SacDist1 <- 1#
	sac[sac$SacStart == "Pre_D2 " & sac$SacEnd == "Pre_D1 ",]$SacDist1 <- 1#
	sac$SacDist2 <- 0#
	sac[sac$SacStart == "Pre_Targ " & sac$SacEnd == "Pre_D2 ",]$SacDist2 <- 1#
	sac[sac$SacStart == "Pre_D2 " & sac$SacEnd == "Pre_Targ ",]$SacDist2 <- 1#
	#sac <- summaryBy(SacTarg + SacSwitch + Sac + SacDist1 + SacDist2 ~ Subj + trialnum + cond+Period, data = sac, keep.names = T)#
	sac <- sac[sac$type != "Filler",]#
	return(sac)#
}#
#
kid.sac <- sac.process2("./","Kids")#
kid.sac$order <- 1:length(kid.sac$SacToTarg)#
names <- read.delim("WriteNames-Times.txt")#
#Groups = read.delim("SubjNames.txt", header = T)#
#merge(kid.sac,Groups, all = T) -> kid.sac#
#kid.sac[is.na(kid.sac$AgeGroup),]$AgeGroup <- "Old"#
kid.sac <- merge(kid.sac,names, by = c("Subj","trialnum"), all.x = TRUE)#
kid.sac<- kid.sac[order(kid.sac$order),]#
names(kid.sac)[names(kid.sac) == "StartTime..ms."] <- "StartTime"#
kid.sac <- ddply(kid.sac, .(Subj,trialnum,Period), transform, CumFromTarg = cumsum(SacFromTarg),CumToTarg = cumsum(SacToTarg),CumTarg = cumsum(SacTarg),CumD1 = cumsum(SacDist1),CumD2 = cumsum(SacDist2), SacTime = SacEndTime - min(SacEndTime), SacBin = round((SacEndTime - min(SacEndTime))/100))#
# Create LabelCond variable; used for data analysis#
kid.sac$LabelCond <- NA#
kid.sac[kid.sac$cond == "Control" & kid.sac$Label %in% c(1,0),]$LabelCond <- "Control"#
kid.sac[kid.sac$cond == "Ambig" & kid.sac$Label %in% c(1),]$LabelCond <- "Test-Unambig"#
kid.sac[kid.sac$cond == "Ambig" & kid.sac$Label %in% c(0),]$LabelCond <- "Test-Ambig"#
kid.sac$LabelCond <- as.factor(kid.sac$LabelCond)#
ddply(kid.sac, .(Subj,trialnum,cond,Period,targname,LabelCond,Label,StartTime), summarize, SacBin = c(0:181)) -> kid.sac.s#
ddply(kid.sac[kid.sac$SacBin <182,], .(Subj,trialnum,cond,Period,targname,LabelCond,Label,SacBin), summarize, CumTarg = mean(CumTarg),CumD1 = mean(CumD1),CumD2 = mean(CumD2)) -> kid.sac.sum#
kid.sac.bin <- merge(kid.sac.s, kid.sac.sum, all = TRUE)#
kid.sac.bin$CumTarg <- t(imputation(matrix(kid.sac.bin$CumTarg, nrow = 1),method = "locf"))#
kid.sac.bin$CumD1 <- t(imputation(matrix(kid.sac.bin$CumD1, nrow = 1),method = "locf"))#
kid.sac.bin$CumD2 <- t(imputation(matrix(kid.sac.bin$CumD2, nrow = 1),method = "locf"))#
kid.sac.bin$Item <- as.factor(sapply(strsplit(as.character(kid.sac.bin$targname),"[.12]"), "[", 1))#
#
kid.sac.bin$SubjTrial <- paste(kid.sac.bin$Subj,kid.sac.bin$Item, sep = "") #
TrialTime <- summaryBy(TRIAL_DWELL_TIME~SubjTrial, data = subset(kid.ref.t, subset = Period == "Pre" & Picture == "Targ"), keep.names = T, na.rm = T)#
kid.sac.bin <- kid.sac.bin[kid.sac.bin$SubjTrial %in% TrialTime[TrialTime$TRIAL_DWELL_TIME > 1500,]$SubjTrial,]#
kid.sac.bin$StartTime <- kid.sac.bin$StartTime/100#
kid.sac.bin$StartTime <- round(kid.sac.bin$StartTime)#
kid.sac.bin$SacBin2 <- kid.sac.bin$SacBin - kid.sac.bin$StartTime#
#Change the SacBin2 above to SacBin to see this timelocked to naming onset.#
#
kid.sac.bin.naming <- subset(kid.sac.bin, SacBin2 >= -10 & SacBin2 <= 50)#
kid.sac.bin.naming$SacBin <- kid.sac.bin.naming$SacBin2#
kid.sac.bin.naming <- ddply(kid.sac.bin.naming, .(Subj,trialnum, Period), transform, CumTarg = CumTarg - min(CumTarg),CumD1 = CumD1 - min(CumD1),CumD2 = CumD2 - min(CumD2))#
#
# We don't have naming times currently#
summary(lmer(SacTarg~LabelCond+ (1|Subj), data = subset(Sac.sum, AgeGroup !="Excl" & Period == "Pre")))#
	 summaryBy(SacDist1+SacDist2+SacFromTarg+SacToTarg +SacTarg ~AgeGroup+Subj+trialnum+LabelCond+Period+Start, data = kid.sac, keep.names = T) -> Sac.sum#
	 na.omit(summaryBy(SacTarg +SacDist2 +SacDist1+SacFromTarg+SacToTarg ~AgeGroup+Period+Start+LabelCond, data = Sac.sum, keep.names = T))#
na.omit(summaryBy(SacTarg~Period+LabelCond+Subj, data = Sac.sum[Sac.sum$Period != "Rew",], FUN = c(mean,sd), keep.names = T)) -> Sac.graph#
na.omit(summaryBy(SacTarg.mean~Period+LabelCond, data = Sac.graph, FUN = c(mean,sd))) -> Sac.graph#
Sac.graph$Period <- factor(Sac.graph$Period, levels = c("Pre","Naming"),labels = c("Pre","Naming"), ordered = T)#
Sac.graph$SE = Sac.graph$SacTarg.mean.sd/sqrt(length(unique(Sac.sum$Subj)))#
#
Sac.graph$Time = "Naming"#
Sac.graph[Sac.graph$Period == "Pre" , ]$Time = "Preview"#
Sac.graph$Time <- factor(Sac.graph$Time, levels = c("Preview","Naming"),labels = c("Preview","Naming"), ordered = T)#
#
tapply(Sac.graph$SacTarg.mean.mean, list(Sac.graph$LabelCond,Sac.graph$Time), FUN = mean) -> o#
tapply(Sac.graph$SE, list(Sac.graph$LabelCond,Sac.graph$Time), FUN = mean) -> se#
#
barplot(o, beside =T , ylim = c(0,0.40),col = "white",  border = NA, ylab = "Critical Saccades", names.arg = c("Preview", "Naming"))#
 legend(1.2,0.15, legend = c("Control", "Detecting Ambiguity", "Not Detecting Ambiguity"), bty = "n", col = c("blue","grey","red"), pch = 20)#
 points(c(1.5,6), o[1,], pch = 20, cex = 2, col = "blue")#
 points(c(2.5,6.8), o[2,], pch = 20, cex = 2, col = "grey")#
  points(c(3.5,7.6), o[3,], pch = 20, cex = 2, col = "red")#
 grid(nx = NA, ny = NULL, col = "gray", lty = "dotted",lwd = par("lwd"), equilogs = TRUE)#
abline(v = c(4.5,8.5), col = "grey", lty = "dashed")#
  arrows(c(1.5,2.5,3.5,6,6.8,7.6), (c(o) + c(se)+0.01), c(1.5,2.5,3.5,6,6.8,7.6), (c(o) - c(se)-0.01), code = 0)
require(plyr)#
require(longitudinalData)#
sac.process2 = function(pathway = "./", Pop = "NA"){#
	sac = c()#
	for (i in unique(Pop)){#
		for (j in c("Pre","Targ","Rew")){# Something is off with the reward section ,"Rew")){#
		file.list <- list.files(path = pathway,full.names = T,pattern = paste(i,".*","Sac",j, sep = ""))#
		sac.temp <- read.delim(file.list, header = T)#
		sac.temp$Period = ifelse(j == "Targ","Naming",j)#
		sac <- rbind(sac, sac.temp)	#
		}#
	}#
	names(sac)[names(sac) == "RECORDING_SESSION_LABEL"] <- "Subj"#
	names(sac)[names(sac) == "CURRENT_SAC_NEAREST_START_INTEREST_AREA_LABEL"] <- "SacStart"#
	names(sac)[names(sac) == "CURRENT_SAC_NEAREST_END_INTEREST_AREA_LABEL"] <- "SacEnd"#
	names(sac)[names(sac) == "CURRENT_SAC_END_TIME"] <- "SacEndTime"#
	sac$Subj <- as.factor(paste(sac$Subj,".edf", sep = ""))#
	sac$Sac <- 1#
	sac$SacSwitch <- ifelse(sac$SacStart == sac$SacEnd,0,1)#
	sac$SacToTarg <- 0#
	sac$SacFromTarg <- 0#
	sac[sac$SacStart == "Pre_Targ " & sac$SacEnd == "Pre_D1 ",]$SacFromTarg <- 1#
	sac[sac$SacStart == "Pre_D1 " & sac$SacEnd == "Pre_Targ ",]$SacToTarg <- 1#
	sac$SacTarg <- 0#
	sac[sac$SacStart == "Pre_Targ " & sac$SacEnd == "Pre_D1 ",]$SacTarg <- 1#
	sac[sac$SacStart == "Pre_D1 " & sac$SacEnd == "Pre_Targ ",]$SacTarg <- 1#
#
	sac$SacDist1 <- 0#
	sac[sac$SacStart == "Pre_D1 " & sac$SacEnd == "Pre_D2 ",]$SacDist1 <- 1#
	sac[sac$SacStart == "Pre_D2 " & sac$SacEnd == "Pre_D1 ",]$SacDist1 <- 1#
	sac$SacDist2 <- 0#
	sac[sac$SacStart == "Pre_Targ " & sac$SacEnd == "Pre_D2 ",]$SacDist2 <- 1#
	sac[sac$SacStart == "Pre_D2 " & sac$SacEnd == "Pre_Targ ",]$SacDist2 <- 1#
	#sac <- summaryBy(SacTarg + SacSwitch + Sac + SacDist1 + SacDist2 ~ Subj + trialnum + cond+Period, data = sac, keep.names = T)#
	sac <- sac[sac$type != "Filler",]#
	return(sac)#
}#
#
kid.sac <- sac.process2("./","Kids")#
kid.sac$order <- 1:length(kid.sac$SacToTarg)#
names <- read.delim("WriteNames-Times.txt")#
#Groups = read.delim("SubjNames.txt", header = T)#
#merge(kid.sac,Groups, all = T) -> kid.sac#
#kid.sac[is.na(kid.sac$AgeGroup),]$AgeGroup <- "Old"#
kid.sac <- merge(kid.sac,names, by = c("Subj","trialnum"), all.x = TRUE)#
kid.sac<- kid.sac[order(kid.sac$order),]#
names(kid.sac)[names(kid.sac) == "StartTime..ms."] <- "StartTime"#
kid.sac <- ddply(kid.sac, .(Subj,trialnum,Period), transform, CumFromTarg = cumsum(SacFromTarg),CumToTarg = cumsum(SacToTarg),CumTarg = cumsum(SacTarg),CumD1 = cumsum(SacDist1),CumD2 = cumsum(SacDist2), SacTime = SacEndTime - min(SacEndTime), SacBin = round((SacEndTime - min(SacEndTime))/100))#
# Create LabelCond variable; used for data analysis#
kid.sac$LabelCond <- NA#
kid.sac[kid.sac$cond == "Control" & kid.sac$Label %in% c(1,0),]$LabelCond <- "Control"#
kid.sac[kid.sac$cond == "Ambig" & kid.sac$Label %in% c(1),]$LabelCond <- "Test-Unambig"#
kid.sac[kid.sac$cond == "Ambig" & kid.sac$Label %in% c(0),]$LabelCond <- "Test-Ambig"#
kid.sac$LabelCond <- as.factor(kid.sac$LabelCond)#
ddply(kid.sac, .(Subj,trialnum,cond,Period,targname,LabelCond,Label,StartTime), summarize, SacBin = c(0:181)) -> kid.sac.s#
ddply(kid.sac[kid.sac$SacBin <182,], .(Subj,trialnum,cond,Period,targname,LabelCond,Label,SacBin), summarize, CumTarg = mean(CumTarg),CumD1 = mean(CumD1),CumD2 = mean(CumD2)) -> kid.sac.sum#
kid.sac.bin <- merge(kid.sac.s, kid.sac.sum, all = TRUE)#
kid.sac.bin$CumTarg <- t(imputation(matrix(kid.sac.bin$CumTarg, nrow = 1),method = "locf"))#
kid.sac.bin$CumD1 <- t(imputation(matrix(kid.sac.bin$CumD1, nrow = 1),method = "locf"))#
kid.sac.bin$CumD2 <- t(imputation(matrix(kid.sac.bin$CumD2, nrow = 1),method = "locf"))#
kid.sac.bin$Item <- as.factor(sapply(strsplit(as.character(kid.sac.bin$targname),"[.12]"), "[", 1))#
#
kid.sac.bin$SubjTrial <- paste(kid.sac.bin$Subj,kid.sac.bin$Item, sep = "") #
TrialTime <- summaryBy(TRIAL_DWELL_TIME~SubjTrial, data = subset(kid.ref.t, subset = Period == "Pre" & Picture == "Targ"), keep.names = T, na.rm = T)#
kid.sac.bin <- kid.sac.bin[kid.sac.bin$SubjTrial %in% TrialTime[TrialTime$TRIAL_DWELL_TIME > 1500,]$SubjTrial,]#
kid.sac.bin$StartTime <- kid.sac.bin$StartTime/100#
kid.sac.bin$StartTime <- round(kid.sac.bin$StartTime)#
kid.sac.bin$SacBin2 <- kid.sac.bin$SacBin - kid.sac.bin$StartTime#
#Change the SacBin2 above to SacBin to see this timelocked to naming onset.#
#
kid.sac.bin.naming <- subset(kid.sac.bin, SacBin2 >= -10 & SacBin2 <= 50)#
kid.sac.bin.naming$SacBin <- kid.sac.bin.naming$SacBin2#
kid.sac.bin.naming <- ddply(kid.sac.bin.naming, .(Subj,trialnum, Period), transform, CumTarg = CumTarg - min(CumTarg),CumD1 = CumD1 - min(CumD1),CumD2 = CumD2 - min(CumD2))#
#
# We don't have naming times currently#
summary(lmer(SacTarg~LabelCond+ (1|Subj), data = subset(Sac.sum, AgeGroup !="Excl" & Period == "Pre")))#
	 summaryBy(SacDist1+SacDist2+SacFromTarg+SacToTarg +SacTarg ~AgeGroup+Subj+trialnum+LabelCond+Period+Start, data = kid.sac, keep.names = T) -> Sac.sum#
	 na.omit(summaryBy(SacTarg +SacDist2 +SacDist1+SacFromTarg+SacToTarg ~AgeGroup+Period+Start+LabelCond, data = Sac.sum, keep.names = T))#
na.omit(summaryBy(SacTarg~Period+LabelCond+Subj, data = Sac.sum[Sac.sum$Period != "Rew",], FUN = c(mean,sd), keep.names = T)) -> Sac.graph#
na.omit(summaryBy(SacTarg.mean~Period+LabelCond, data = Sac.graph, FUN = c(mean,sd))) -> Sac.graph#
Sac.graph$Period <- factor(Sac.graph$Period, levels = c("Pre","Naming"),labels = c("Pre","Naming"), ordered = T)#
Sac.graph$SE = Sac.graph$SacTarg.mean.sd/sqrt(length(unique(Sac.sum$Subj)))#
#
Sac.graph$Time = "Naming"#
Sac.graph[Sac.graph$Period == "Pre" , ]$Time = "Preview"#
Sac.graph$Time <- factor(Sac.graph$Time, levels = c("Preview","Naming"),labels = c("Preview","Naming"), ordered = T)#
#
tapply(Sac.graph$SacTarg.mean.mean, list(Sac.graph$LabelCond,Sac.graph$Time), FUN = mean) -> o#
tapply(Sac.graph$SE, list(Sac.graph$LabelCond,Sac.graph$Time), FUN = mean) -> se#
#
barplot(o, beside =T , ylim = c(0,0.40),col = "white",  border = NA, ylab = "Critical Saccades", names.arg = c("Preview", "Naming"))#
 legend(1.2,0.15, legend = c("Control","Not Detecting Ambiguity", "Detecting Ambiguity"), bty = "n", col = c("blue","grey","red"), pch = 20)#
 points(c(1.5,6), o[1,], pch = 20, cex = 2, col = "blue")#
 points(c(2.5,6.8), o[2,], pch = 20, cex = 2, col = "grey")#
  points(c(3.5,7.6), o[3,], pch = 20, cex = 2, col = "red")#
 grid(nx = NA, ny = NULL, col = "gray", lty = "dotted",lwd = par("lwd"), equilogs = TRUE)#
abline(v = c(4.5,8.5), col = "grey", lty = "dashed")#
  arrows(c(1.5,2.5,3.5,6,6.8,7.6), (c(o) + c(se)+0.01), c(1.5,2.5,3.5,6,6.8,7.6), (c(o) - c(se)-0.01), code = 0)
require(plyr)#
require(longitudinalData)#
sac.process2 = function(pathway = "./", Pop = "NA"){#
	sac = c()#
	for (i in unique(Pop)){#
		for (j in c("Pre","Targ","Rew")){# Something is off with the reward section ,"Rew")){#
		file.list <- list.files(path = pathway,full.names = T,pattern = paste(i,".*","Sac",j, sep = ""))#
		sac.temp <- read.delim(file.list, header = T)#
		sac.temp$Period = ifelse(j == "Targ","Naming",j)#
		sac <- rbind(sac, sac.temp)	#
		}#
	}#
	names(sac)[names(sac) == "RECORDING_SESSION_LABEL"] <- "Subj"#
	names(sac)[names(sac) == "CURRENT_SAC_NEAREST_START_INTEREST_AREA_LABEL"] <- "SacStart"#
	names(sac)[names(sac) == "CURRENT_SAC_NEAREST_END_INTEREST_AREA_LABEL"] <- "SacEnd"#
	names(sac)[names(sac) == "CURRENT_SAC_END_TIME"] <- "SacEndTime"#
	sac$Subj <- as.factor(paste(sac$Subj,".edf", sep = ""))#
	sac$Sac <- 1#
	sac$SacSwitch <- ifelse(sac$SacStart == sac$SacEnd,0,1)#
	sac$SacToTarg <- 0#
	sac$SacFromTarg <- 0#
	sac[sac$SacStart == "Pre_Targ " & sac$SacEnd == "Pre_D1 ",]$SacFromTarg <- 1#
	sac[sac$SacStart == "Pre_D1 " & sac$SacEnd == "Pre_Targ ",]$SacToTarg <- 1#
	sac$SacTarg <- 0#
	sac[sac$SacStart == "Pre_Targ " & sac$SacEnd == "Pre_D1 ",]$SacTarg <- 1#
	sac[sac$SacStart == "Pre_D1 " & sac$SacEnd == "Pre_Targ ",]$SacTarg <- 1#
#
	sac$SacDist1 <- 0#
	sac[sac$SacStart == "Pre_D1 " & sac$SacEnd == "Pre_D2 ",]$SacDist1 <- 1#
	sac[sac$SacStart == "Pre_D2 " & sac$SacEnd == "Pre_D1 ",]$SacDist1 <- 1#
	sac$SacDist2 <- 0#
	sac[sac$SacStart == "Pre_Targ " & sac$SacEnd == "Pre_D2 ",]$SacDist2 <- 1#
	sac[sac$SacStart == "Pre_D2 " & sac$SacEnd == "Pre_Targ ",]$SacDist2 <- 1#
	#sac <- summaryBy(SacTarg + SacSwitch + Sac + SacDist1 + SacDist2 ~ Subj + trialnum + cond+Period, data = sac, keep.names = T)#
	sac <- sac[sac$type != "Filler",]#
	return(sac)#
}#
#
kid.sac <- sac.process2("./","Kids")#
kid.sac$order <- 1:length(kid.sac$SacToTarg)#
names <- read.delim("WriteNames-Times.txt")#
#Groups = read.delim("SubjNames.txt", header = T)#
#merge(kid.sac,Groups, all = T) -> kid.sac#
#kid.sac[is.na(kid.sac$AgeGroup),]$AgeGroup <- "Old"#
kid.sac <- merge(kid.sac,names, by = c("Subj","trialnum"), all.x = TRUE)#
kid.sac<- kid.sac[order(kid.sac$order),]#
names(kid.sac)[names(kid.sac) == "StartTime..ms."] <- "StartTime"#
kid.sac <- ddply(kid.sac, .(Subj,trialnum,Period), transform, CumFromTarg = cumsum(SacFromTarg),CumToTarg = cumsum(SacToTarg),CumTarg = cumsum(SacTarg),CumD1 = cumsum(SacDist1),CumD2 = cumsum(SacDist2), SacTime = SacEndTime - min(SacEndTime), SacBin = round((SacEndTime - min(SacEndTime))/100))#
# Create LabelCond variable; used for data analysis#
kid.sac$LabelCond <- NA#
kid.sac[kid.sac$cond == "Control" & kid.sac$Label %in% c(1,0),]$LabelCond <- "Control"#
kid.sac[kid.sac$cond == "Ambig" & kid.sac$Label %in% c(1),]$LabelCond <- "Test-Unambig"#
kid.sac[kid.sac$cond == "Ambig" & kid.sac$Label %in% c(0),]$LabelCond <- "Test-Ambig"#
kid.sac$LabelCond <- as.factor(kid.sac$LabelCond)#
ddply(kid.sac, .(Subj,trialnum,cond,Period,targname,LabelCond,Label,StartTime), summarize, SacBin = c(0:181)) -> kid.sac.s#
ddply(kid.sac[kid.sac$SacBin <182,], .(Subj,trialnum,cond,Period,targname,LabelCond,Label,SacBin), summarize, CumTarg = mean(CumTarg),CumD1 = mean(CumD1),CumD2 = mean(CumD2)) -> kid.sac.sum#
kid.sac.bin <- merge(kid.sac.s, kid.sac.sum, all = TRUE)#
kid.sac.bin$CumTarg <- t(imputation(matrix(kid.sac.bin$CumTarg, nrow = 1),method = "locf"))#
kid.sac.bin$CumD1 <- t(imputation(matrix(kid.sac.bin$CumD1, nrow = 1),method = "locf"))#
kid.sac.bin$CumD2 <- t(imputation(matrix(kid.sac.bin$CumD2, nrow = 1),method = "locf"))#
kid.sac.bin$Item <- as.factor(sapply(strsplit(as.character(kid.sac.bin$targname),"[.12]"), "[", 1))#
#
kid.sac.bin$SubjTrial <- paste(kid.sac.bin$Subj,kid.sac.bin$Item, sep = "") #
TrialTime <- summaryBy(TRIAL_DWELL_TIME~SubjTrial, data = subset(kid.ref.t, subset = Period == "Pre" & Picture == "Targ"), keep.names = T, na.rm = T)#
kid.sac.bin <- kid.sac.bin[kid.sac.bin$SubjTrial %in% TrialTime[TrialTime$TRIAL_DWELL_TIME > 1500,]$SubjTrial,]#
kid.sac.bin$StartTime <- kid.sac.bin$StartTime/100#
kid.sac.bin$StartTime <- round(kid.sac.bin$StartTime)#
kid.sac.bin$SacBin2 <- kid.sac.bin$SacBin - kid.sac.bin$StartTime#
#Change the SacBin2 above to SacBin to see this timelocked to naming onset.#
#
kid.sac.bin.naming <- subset(kid.sac.bin, SacBin2 >= -10 & SacBin2 <= 50)#
kid.sac.bin.naming$SacBin <- kid.sac.bin.naming$SacBin2#
kid.sac.bin.naming <- ddply(kid.sac.bin.naming, .(Subj,trialnum, Period), transform, CumTarg = CumTarg - min(CumTarg),CumD1 = CumD1 - min(CumD1),CumD2 = CumD2 - min(CumD2))#
#
# We don't have naming times currently#
summary(lmer(SacTarg~LabelCond+ (1|Subj), data = subset(Sac.sum, AgeGroup !="Excl" & Period == "Pre")))#
	 summaryBy(SacDist1+SacDist2+SacFromTarg+SacToTarg +SacTarg ~AgeGroup+Subj+trialnum+LabelCond+Period+Start, data = kid.sac, keep.names = T) -> Sac.sum#
	 na.omit(summaryBy(SacTarg +SacDist2 +SacDist1+SacFromTarg+SacToTarg ~AgeGroup+Period+Start+LabelCond, data = Sac.sum, keep.names = T))#
na.omit(summaryBy(SacTarg~Period+LabelCond+Subj, data = Sac.sum[Sac.sum$Period != "Rew",], FUN = c(mean,sd), keep.names = T)) -> Sac.graph#
na.omit(summaryBy(SacTarg.mean~Period+LabelCond, data = Sac.graph, FUN = c(mean,sd))) -> Sac.graph#
Sac.graph$Period <- factor(Sac.graph$Period, levels = c("Pre","Naming"),labels = c("Pre","Naming"), ordered = T)#
Sac.graph$SE = Sac.graph$SacTarg.mean.sd/sqrt(length(unique(Sac.sum$Subj)))#
#
Sac.graph$Time = "Naming"#
Sac.graph[Sac.graph$Period == "Pre" , ]$Time = "Preview"#
Sac.graph$Time <- factor(Sac.graph$Time, levels = c("Preview","Naming"),labels = c("Preview","Naming"), ordered = T)#
#
tapply(Sac.graph$SacTarg.mean.mean, list(Sac.graph$LabelCond,Sac.graph$Time), FUN = mean) -> o#
tapply(Sac.graph$SE, list(Sac.graph$LabelCond,Sac.graph$Time), FUN = mean) -> se#
#
barplot(o, beside =T , ylim = c(0,0.40),col = "white",  border = NA, ylab = "Critical Saccades", names.arg = c("Preview", "Naming"))#
 legend(1.2,0.11, legend = c("Control","Not Detecting Ambiguity", "Detecting Ambiguity"), bty = "n", col = c("blue","grey","red"), pch = 20)#
 points(c(1.5,6), o[1,], pch = 20, cex = 2, col = "blue")#
 points(c(2.5,6.8), o[2,], pch = 20, cex = 2, col = "grey")#
  points(c(3.5,7.6), o[3,], pch = 20, cex = 2, col = "red")#
 grid(nx = NA, ny = NULL, col = "gray", lty = "dotted",lwd = par("lwd"), equilogs = TRUE)#
abline(v = c(4.5,8.5), col = "grey", lty = "dashed")#
  arrows(c(1.5,2.5,3.5,6,6.8,7.6), (c(o) + c(se)+0.01), c(1.5,2.5,3.5,6,6.8,7.6), (c(o) - c(se)-0.01), code = 0)
a = read.csv("TwoNames.csv", header = T)
summary(a)
summaryBy(Label.2~Condition)
a = read.csv("TwoNames.csv", header = T)
summary(a)
summaryBy(Label.2~Condition, data = a)
glmer(Label.2~Condition + (1+Condition|Participant.Name), data = a, )
library(lme4)
summary(glmer(Label.2~Condition + (1+Condition|Participant.Name), data = a, ))
summary(glmer(Label.2~Condition + (1+Condition|Participant.Name), data = a, link = "logit"))
?glmer
summary(glmer(Label.2~Condition + (1+Condition|Participant.Name), data = a, family = "binomial"))
summary(glmer(Label.2~Condition + (1|Participant.Name), data = a, family = "binomial"))
summary(glmer(Label.2~Condition*Condition.1 + (1|Participant.Name), data = a, family = "binomial"))
summary(glmer(Label.2~Condition + (1|Participant.Name), data = a, family = "binomial"))
summary(glmer(Label.1~Condition + (1|Participant.Name), data = a, family = "binomial"))
summaryBy(Label.1 + Label.2~Condition, data = a)
a = read.csv("TwoNames.csv", header = T)
summary(a)
summaryBy(Label~Condition+Order, data = a)
summary(glmer(Label~Condition*Order + (1|Participant.Name), data = a, family = "binomial"))
summary(glmer(Label~Condition*Order + (1+Order|Participant.Name), data = a, family = "binomial"))
summary(glmer(Label~Condition*Order + (1+Condition*Order|Participant.Name), data = a, family = "binomial"))
summary(glmer(Label~Condition*Order + (1+Order|Participant.Name) + (1|Target.Name), data = a, family = "binomial"))
summary(glmer(Label~Condition*Order + (1|Participant.Name) + (1|Target.Name), data = a, family = "binomial"))
summary(glmer(Label~Condition + (1|Participant.Name) + (1|Target.Name), data = a, family = "binomial"))
summary(glmer(Label~Order + (1|Participant.Name) + (1|Target.Name), data = a[a$Condition == "Ambiguous"], family = "binomial"))
summary(glmer(Label~Order + (1|Participant.Name) + (1|Target.Name), data = a[a$Condition == "Ambiguous",], family = "binomial"))
summary(glmer(Label~Order + (1|Participant.Name) + (1|Target.Name), data = a[a$Condition != "Control",], family = "binomial"))
summary(glmer(Label~Order + (1|Participant.Name) + (1|Target.Name), data = TwoNames[TwoNames$Condition != "Control",], family = "binomial"))
TwoNames <- read.csv("TwoNames.csv", header = T)#
summaryBy(Label~Condition+Order, data = a)#
#
summary(glmer(Label~Order + (1|Participant.Name) + (1|Target.Name), data = TwoNames[TwoNames$Condition != "Control",], family = "binomial"))
TwoNames <- read.csv("TwoNames.csv", header = T)#
summaryBy(Label~Condition+Order, data = a)#
#
summary(glmer(Label~Order + (1+Order|Participant.Name) + (1|Target.Name), data = TwoNames[TwoNames$Condition != "Control",], family = "binomial"))
TwoNames <- read.csv("TwoNames.csv", header = T)#
summaryBy(Label~Condition+Order, data = a)#
#
summary(glmer(Label~Order + (1|Participant.Name) + (1+Order|Target.Name), data = TwoNames[TwoNames$Condition != "Control",], family = "binomial"))
TwoNames$Ordering <- 1#
TwoNames[TwoNames$Condition == "Control" & TwoNames$Label == 1,]$Ordering <- NA#
TwoNames[TwoNames$Condition == "Ambig" & TwoNames$Label == 1,]$Ordering <- 2#
TwoNames[TwoNames$Condition == "Ambig" & TwoNames$Label == 2,]$Ordering <- 3#
#
summary(glmer(Label~Ordering + (1|Participant.Name) + (1|Target.Name), data = TwoNames[TwoNames$Condition != "Control",], family = "binomial"))
TwoNames$Ordering <- 1#
TwoNames[TwoNames$Condition == "Control" & TwoNames$Order == 1,]$Ordering <- NA#
TwoNames[TwoNames$Condition == "Ambig" & TwoNames$Order == 1,]$Ordering <- 2#
TwoNames[TwoNames$Condition == "Ambig" & TwoNames$Order == 2,]$Ordering <- 3#
#
summary(glmer(Label~Ordering + (1|Participant.Name) + (1|Target.Name), data = TwoNames[TwoNames$Condition != "Control",], family = "binomial"))
TwoNames$Ordering <- 1#
TwoNames[TwoNames$Condition == "Control" & TwoNames$Order == 1,]$Ordering <- NA#
TwoNames[TwoNames$Condition == "Ambig" & TwoNames$Order == 1,]$Ordering <- 2#
TwoNames[TwoNames$Condition == "Ambig" & TwoNames$Order == 2,]$Ordering <- 3#
#
summary(glmer(Label~Ordering + (1|Participant.Name) + (1|Target.Name), data = TwoNames, family = "binomial"))
TwoNames <- read.csv("TwoNames.csv", header = T)#
summaryBy(Label~Condition+Order, data = a)#
#
summary(glmer(Label~Order + (1|Participant.Name) + (1|Target.Name), data = TwoNames[TwoNames$Condition != "Control",], family = "binomial"))#
#
# Now run the analyses based on the hypothesis that Unambig (second name) should have less modification than#
# Ambiguous (first name), which should have less modification than Ambiguous (second name)#
#
TwoNames$Ordering <- 1#
TwoNames[TwoNames$Condition == "Control" & TwoNames$Order == 1,]$Ordering <- NA#
TwoNames[TwoNames$Condition == "Ambig" & TwoNames$Order == 1,]$Ordering <- 2#
TwoNames[TwoNames$Condition == "Ambig" & TwoNames$Order == 2,]$Ordering <- 3#
#
summary(glmer(Label~Ordering + (1|Participant.Name) + (1|Target.Name), data = TwoNames, family = "binomial"))
TwoNames <- read.csv("TwoNames.csv", header = T)#
summaryBy(Label~Condition+Order, data = a)#
#
summary(glmer(Label~Order + (1|Participant.Name) + (1|Target.Name), data = TwoNames[TwoNames$Condition != "Control",], family = "binomial"))#
#
# Now run the analyses based on the hypothesis that Unambig (second name) should have less modification than#
# Ambiguous (first name), which should have less modification than Ambiguous (second name)#
#
TwoNames$Ordering <- 1#
TwoNames[TwoNames$Condition == "Control" & TwoNames$Order == 1,]$Ordering <- NA#
TwoNames[TwoNames$Condition == "Ambig" & TwoNames$Order == 1,]$Ordering <- 2#
TwoNames[TwoNames$Condition == "Ambig" & TwoNames$Order == 2,]$Ordering <- 3#
#
summary(glmer(Label~as.factor(Ordering) + (1|Participant.Name) + (1|Target.Name), data = TwoNames, family = "binomial"))
contrasts(as.factor(TwoNames$Ordering))
forward_difference= function (n){#
  i = 1#
  x <- c( rep((n-i)/n, i), rep(-i/n,n-i))#
  y <- x#
  for (i in 2:(n-1)) {#
    x <- c( rep((n-i)/n, i), rep(-(i)/n,n-i))#
    y <- cbind(y,x)#
  }#
  return (y)#
}
forward_difference(3)
contrasts(as.factor(TwoNames$Ordering))#
 <- forward_difference(3)
contrasts(as.factor(TwoNames$Ordering))#
 <- forward_difference(3)
contrasts(as.factor(TwoNames$Ordering)) <- forward_difference(3)
contrasts(as.factor(TwoNames$Ordering))
contrasts(as.factor(TwoNames$Ordering))[1]
contrasts(as.factor(TwoNames$Ordering))
contrasts(as.factor(TwoNames$Ordering)) = forward_difference(3)
TwoNames$Ordering <- as.factor(TwoNames$Ordering)
contrasts(TwoNames$Ordering) = forward_difference(3)
summary(glmer(Label~Ordering + (1|Participant.Name) + (1|Target.Name), data = TwoNames, family = "binomial"))
contrasts(TwoNames$Ordering)
cbind(c(1,2,3), c(1,2,3))
is.matric(contrasts(TwoNames$Ordering))
is.matrix(contrasts(TwoNames$Ordering))
matrix(c(1,2,3), c(1,2,3))
matrix(NA, nrow =3, ncol = 2 )
?matrix
matrix(NA, nrow =3, ncol = 2 , dimnames = c(1:3,1:2))
matrix(NA, nrow =3, ncol = 2 , dimnames = list(1:3,1:2))
k = 3
fd <- matrix(NA, nrow =k, ncol = k-1 , dimnames = list(1:k,1:(k-1)))#
fd[1,]
fd
fd[,1]
j <- k-1
r = 1#
for (h in 1:j){#
	for (i in 1:k){#
		if (i <= r){#
			fd[i,h] <- (k-r)/k#
				}else{#
			fd[i,h] <- -r/k#
			}#
		}#
	r <- r+1#
}
fd
j <- k-1#
fd <- matrix(NA, nrow =k, ncol = j , dimnames = list(1:k,1:j))#
#
r = 1#
for (h in 1:j){#
	for (i in 1:k){#
		if (i <= r){#
			fd[i,h] <- (k-r)/k#
				}else{#
			fd[i,h] <- -r/k#
			}#
		}#
	r <- r+1#
}
fd <- 0
j <- k-1#
fd <- matrix(NA, nrow =k, ncol = j , dimnames = list(1:k,1:j))#
#
r = 1#
for (h in 1:j){#
	for (i in 1:k){#
		if (i <= r){#
			fd[i,h] <- (k-r)/k#
				}else{#
			fd[i,h] <- -r/k#
			}#
		}#
	r <- r+1#
}
fd
k <- 4
j <- k-1#
fd <- matrix(NA, nrow =k, ncol = j , dimnames = list(1:k,1:j))#
#
r = 1#
for (h in 1:j){#
	for (i in 1:k){#
		if (i <= r){#
			fd[i,h] <- (k-r)/k#
				}else{#
			fd[i,h] <- -r/k#
			}#
		}#
	r <- r+1#
}
fd
unique(TwoNames$Ordering)
length(unique(TwoNames$Ordering))
length(levels(TwoNames$Ordering))
TwoNames <- read.csv("TwoNames.csv", header = T)#
summaryBy(Label~Condition+Order, data = a)#
#
summary(glmer(Label~Order + (1|Participant.Name) + (1|Target.Name), data = TwoNames[TwoNames$Condition != "Control",], family = "binomial"))#
#
# Now run the analyses based on the hypothesis that Unambig (second name) should have less modification than#
# Ambiguous (first name), which should have less modification than Ambiguous (second name)#
#
TwoNames$Ordering <- 1#
TwoNames[TwoNames$Condition == "Control" & TwoNames$Order == 1,]$Ordering <- NA#
TwoNames[TwoNames$Condition == "Ambig" & TwoNames$Order == 1,]$Ordering <- 2#
TwoNames[TwoNames$Condition == "Ambig" & TwoNames$Order == 2,]$Ordering <- 3#
#
# Function to write Forward Difference Coding, comparing each level against the previous.#
forward_diff <- function(k){ # k = number of levels of the factor#
j <- k-1#
fd <- matrix(NA, nrow =k, ncol = j , dimnames = list(1:k,1:j))#
#
r = 1#
for (h in 1:j){#
	for (i in 1:k){#
		if (i <= r){#
			fd[i,h] <- (k-r)/k#
				}else{#
			fd[i,h] <- -r/k#
			}#
		}#
	r <- r+1#
}#
return(fd)#
}#
#
TwoNames$Ordering <- as.factor(TwoNames$Ordering)#
contrasts(TwoNames$Ordering) <- length(levels(TwoNames$Ordering))#
#
summary(glmer(Label~as.factor(Ordering) + (1|Participant.Name) + (1|Target.Name), data = TwoNames, family = "binomial"))
TwoNames <- read.csv("TwoNames.csv", header = T)#
summaryBy(Label~Condition+Order, data = a)#
#
summary(glmer(Label~Order + (1|Participant.Name) + (1|Target.Name), data = TwoNames[TwoNames$Condition != "Control",], family = "binomial"))#
#
# Now run the analyses based on the hypothesis that Unambig (second name) should have less modification than#
# Ambiguous (first name), which should have less modification than Ambiguous (second name)#
#
TwoNames$Ordering <- 1#
TwoNames[TwoNames$Condition == "Control" & TwoNames$Order == 1,]$Ordering <- NA#
TwoNames[TwoNames$Condition == "Ambig" & TwoNames$Order == 1,]$Ordering <- 2#
TwoNames[TwoNames$Condition == "Ambig" & TwoNames$Order == 2,]$Ordering <- 3#
#
# Function to write Forward Difference Coding, comparing each level against the previous.#
forward_diff <- function(k){ # k = number of levels of the factor#
j <- k-1#
fd <- matrix(NA, nrow =k, ncol = j , dimnames = list(1:k,1:j))#
#
r = 1#
for (h in 1:j){#
	for (i in 1:k){#
		if (i <= r){#
			fd[i,h] <- (k-r)/k#
				}else{#
			fd[i,h] <- -r/k#
			}#
		}#
	r <- r+1#
}#
return(fd)#
}#
#
TwoNames$Ordering <- as.factor(TwoNames$Ordering)#
contrasts(TwoNames$Ordering) <- forward_diff(length(levels(TwoNames$Ordering)))#
#
summary(glmer(Label~as.factor(Ordering) + (1|Participant.Name) + (1|Target.Name), data = TwoNames, family = "binomial"))
summary(TwoNames)
TwoNames <- read.csv("TwoNames.csv", header = T)#
summaryBy(Label+Age~Condition+Order, data = a)#
#
summary(glmer(Label~Order + (1|Participant.Name) + (1|Target.Name), data = TwoNames[TwoNames$Condition != "Control",], family = "binomial"))#
#
# Now run the analyses based on the hypothesis that Unambig (second name) should have less modification than#
# Ambiguous (first name), which should have less modification than Ambiguous (second name)#
#
TwoNames$Ordering <- 1#
TwoNames[TwoNames$Condition == "Control" & TwoNames$Order == 1,]$Ordering <- NA#
TwoNames[TwoNames$Condition == "Ambig" & TwoNames$Order == 1,]$Ordering <- 2#
TwoNames[TwoNames$Condition == "Ambig" & TwoNames$Order == 2,]$Ordering <- 3#
#
# Function to write Forward Difference Coding, comparing each level against the previous.#
forward_diff <- function(k){ # k = number of levels of the factor#
j <- k-1#
fd <- matrix(NA, nrow =k, ncol = j , dimnames = list(1:k,1:j))#
#
r = 1#
for (h in 1:j){#
	for (i in 1:k){#
		if (i <= r){#
			fd[i,h] <- (k-r)/k#
				}else{#
			fd[i,h] <- -r/k#
			}#
		}#
	r <- r+1#
}#
return(fd)#
}#
#
TwoNames$Ordering <- as.factor(TwoNames$Ordering)#
contrasts(TwoNames$Ordering) <- forward_diff(length(levels(TwoNames$Ordering)))#
#
summary(glmer(Label~as.factor(Ordering) + (1|Participant.Name) + (1|Target.Name), data = TwoNames, family = "binomial"))
